{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESCAPE - Explosiveness, Success, and Conference Adjusted Power Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__v1.0__ - Original Power Ratings System\n",
    "\n",
    "  - Now known as \"In House PR.\" Usage was weeks 5-8 in 2024.\n",
    "\n",
    "  - __v1.0 - v1.5__ - Incremental Improvements to \"In House PR\"  \n",
    "  \n",
    "    - Untracked changes leading to the current formula. Introduction of win probability, spread calculation, and home field advantage.\n",
    "\n",
    "__v2.0__ - Updated Power Ratings System\n",
    "\n",
    "  - Utilizing In House PR and 15 different team statistics optimized using Spearman correlation against SP+\n",
    " \n",
    "  - __v2.1__ - Expanded Team Statistics\n",
    "\n",
    "    - Added 6 new statistics, bringing the total up to 21. Applied for Week 9 in 2024.\n",
    "\n",
    "  - __v2.2__ - Using spearman correlation against ESPN FPI rather than the SP+ for the optimization weights.  \n",
    "\n",
    "    - Spearman correlation optimized against ESPN FPI instead of SP+.\n",
    "\n",
    "  - __v2.3__ - Combined Optimization Weights  \n",
    "\n",
    "    - Using an average of ESPN FPI rank and SP+ rank for the spearman correlation.  \n",
    "  \n",
    "    - __v2.3.1__ - Weighted Optimization Adjustment\n",
    "\n",
    "      - Incorporates both ESPN FPI and SP+ ranks as weights in optimization rather than averaging; updates now tracked.\n",
    "\n",
    "  - __v2.4__ - Introduction of Vegas Herding Adjustments   \n",
    "\n",
    "    - Implemented for teams with a spread difference over 10 for multiple weeks. Applied for Week 10 in 2024.\n",
    "\n",
    "  - __v2.5__ - Adjusted Power Ratings Range  \n",
    "\n",
    "    - Changed the power ratings range from 55 to 50. Applied for Week 11 in 2024.\n",
    "\n",
    "  - __v2.6__ - Adjusted Elo Effect for Spread\n",
    "\n",
    "    - For \"home_adjust_pr\" function, the max adjustment the elo can make is 5 instead of 7. Applied for Week 11, backwards applied for week 9 and 10.\n",
    "\n",
    "  - __v2.7__ - Updated GR&A's for Beginning of Season Data\n",
    "  \n",
    "    - Added GR&A's for how to handle the formula for pre-season through week 8 of the season. Still subject to change\n",
    "\n",
    "  - __v2.8__ - Updated Rounding Logic\n",
    "\n",
    "    - Replaced rounding to the nearest half with rounding to the first decimal place. This change reduces the likelihood of a zero-point difference between the ESCAPE spread and the Vegas spread.\n",
    "\n",
    "  - __v2.9__ - Home Field Advantage Adjustment\n",
    "\n",
    "    - Through backtesting weeks nine through fourteen, a home field advantage of 4.6 was the best in terms of MAE and ATS. Backwards applied for weeks 9 through 14. Reserve the right to adjust at a later date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v2.7 GR&A's:\n",
    "\n",
    "- Pre-Season: (Last Year Rating)\n",
    "- After Week 1: 1/3 * Last Year Rating + This Year Rating (0.2 Talent)\n",
    "- After Week 2: 1/8 * Last Year Rating + This Year Rating (0.2 Talent)\n",
    "- After Week 3: This Year Rating (0.2 Talent)\n",
    "- After Week 4: TYR (0.2 Talent)\n",
    "- After Week 5: TYR (.15 Talent)\n",
    "- After Week 6: TYR (.1 Talent)\n",
    "- After Week 7: TYR (.05 Talent)\n",
    "- Week 8-14: TYR (0 Talent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to Consider:\n",
    "\n",
    "- Remove Vegas Herding (feels like cheating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 1 Power Ratings and the \"Current Week\" being equal to 1 is for pre-season.  \n",
    "Week 2 Power Ratings and the \"Current Week\" being equal to 2 is after week 1 games are done, but before week 2 game begin.  \n",
    "\n",
    "Ex)  \n",
    "Week 1 games finish 8/30, Week 2 games start 9/7  \n",
    "\"current_week\" is equal to 1 on and before 8/30  \n",
    "\"current_week\" is equal to 2 on and before 9/7, but after 8/30  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating Power Rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grabbing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cfbd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "configuration = cfbd.Configuration()\n",
    "configuration.api_key['Authorization'] = '7vGedNNOrnl0NGcSvt92FcVahY602p7IroVBlCA1Tt+WI/dCwtT7Gj5VzmaHrrxS'\n",
    "configuration.api_key_prefix['Authorization'] = 'Bearer'\n",
    "api_client = cfbd.ApiClient(configuration)\n",
    "\n",
    "advanced_instance = cfbd.StatsApi(api_client)\n",
    "\n",
    "games_api = cfbd.GamesApi(api_client)\n",
    "\n",
    "betting_api = cfbd.BettingApi(api_client)\n",
    "\n",
    "ratings_api = cfbd.RatingsApi(api_client)\n",
    "\n",
    "teams_api = cfbd.TeamsApi(api_client)\n",
    "\n",
    "metrics_api = cfbd.MetricsApi(api_client)\n",
    "\n",
    "players_api = cfbd.PlayersApi(api_client)\n",
    "\n",
    "recruiting_api = cfbd.RecruitingApi(api_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 2024\n"
     ]
    }
   ],
   "source": [
    "week_start_list = [*games_api.get_calendar(year = 2024)]\n",
    "calendar_dict = [dict(\n",
    "    first_game_start = c.first_game_start,\n",
    "    last_game_start = c.last_game_start,\n",
    "    season = c.season,\n",
    "    season_type = c.season_type,\n",
    "    week = c.week\n",
    ") for c in week_start_list]\n",
    "calendar = pd.DataFrame(calendar_dict)\n",
    "calendar['first_game_start'] = pd.to_datetime(calendar['first_game_start'])\n",
    "calendar['last_game_start'] = pd.to_datetime(calendar['last_game_start'])\n",
    "current_year = int(calendar.loc[0, 'season'])\n",
    "\n",
    "import pytz\n",
    "import datetime\n",
    "\n",
    "current_time = datetime.datetime.now(pytz.UTC)\n",
    "first_game_start = calendar['first_game_start'].iloc[0]\n",
    "last_game_start = calendar['last_game_start'].iloc[-1]\n",
    "current_week = None\n",
    "if current_time < first_game_start:\n",
    "    current_week = 1\n",
    "    postseason = False\n",
    "elif current_time > last_game_start:\n",
    "    current_week = calendar.iloc[-2, -1] + 1\n",
    "    postseason = True\n",
    "else:\n",
    "    condition_1 = (calendar['first_game_start'] <= current_time) & (calendar['last_game_start'] >= current_time)\n",
    "    condition_2 = (calendar['last_game_start'].shift(1) < current_time) & (calendar['first_game_start'] > current_time)\n",
    "\n",
    "    # Combine conditions\n",
    "    result = calendar[condition_1 | condition_2].reset_index(drop=True)\n",
    "    if result['season_type'][0] == 'regular':\n",
    "        current_week = result['week'][0]\n",
    "        postseason = False\n",
    "    else:\n",
    "        current_week = calendar.iloc[-2, -1] + 1\n",
    "        postseason = True\n",
    "current_week = int(current_week)\n",
    "current_year = int(current_year)\n",
    "print(current_week, current_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_sort(game):\n",
    "    game_date = datetime.datetime.strptime(game['start_date'], \"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "    return game_date\n",
    "\n",
    "def ESCAPE_Win_Prob(home_power_rating, away_power_rating):\n",
    "    return round((1 / (1 + 10 ** ((away_power_rating - (home_power_rating)) / 20.5))) * 100, 2)\n",
    "\n",
    "def average_team_distribution(num_simulations, schedules, average, team_name):\n",
    "\n",
    "    def simulate_game_average(win_prob):\n",
    "        random_outcome = np.random.random() * 100  # Generates a number between 0 and 100\n",
    "        if random_outcome < win_prob:\n",
    "            return \"W\"  # Home team wins, Away team loses\n",
    "        else:\n",
    "            return \"L\"  # Away team wins, Home team loses\n",
    "        \n",
    "    def simulate_season_average(schedules, team_name, average):\n",
    "        wins = 0\n",
    "        losses = 0\n",
    "        for _, game in schedules.iterrows():\n",
    "            if game['home_team'] == team_name:\n",
    "                opponent_team = game['away_team']\n",
    "                opponent_pr = game['away_pr']\n",
    "                win_prob = ESCAPE_Win_Prob(average, opponent_pr)\n",
    "\n",
    "                # opponent_elo = game['away_elo']\n",
    "                # win_prob = round((10**((average-opponent_elo) / 400)) / ((10**((average-opponent_elo) / 400)) + 1)*100, 2)\n",
    "            else:\n",
    "                opponent_team = game['home_team']\n",
    "                opponent_pr = game['home_pr']\n",
    "                win_prob = 100 - ESCAPE_Win_Prob(opponent_pr, average)\n",
    "\n",
    "                # opponent_elo = game['home_elo']\n",
    "                # win_prob = 100 - round((10**((opponent_elo-average) / 400)) / ((10**((opponent_elo-average) / 400)) + 1)*100, 2)\n",
    "            \n",
    "            outcome = simulate_game_average(win_prob)\n",
    "            if outcome == \"W\":\n",
    "                wins += 1\n",
    "            else:\n",
    "                losses += 1\n",
    "\n",
    "        return wins, losses\n",
    "        \n",
    "    def monte_carlo_simulation_average(num_simulations, schedules, average, team_name):\n",
    "        \"\"\"Runs a Monte Carlo simulation for an average team over multiple seasons.\"\"\"\n",
    "        win_results = []\n",
    "        loss_results = []\n",
    "\n",
    "        for _ in range(num_simulations):\n",
    "            wins, losses = simulate_season_average(schedules, team_name, average)\n",
    "            win_results.append(wins)\n",
    "            loss_results.append(losses)\n",
    "        \n",
    "        return win_results, loss_results\n",
    "\n",
    "    import statistics\n",
    "    from collections import Counter\n",
    "    def analyze_simulation_average(win_results, loss_results, schedules):\n",
    "        games_played = len(schedules)\n",
    "        if games_played == 11:\n",
    "            win_results = [x + .948 for x in win_results]\n",
    "        elif games_played == 10:\n",
    "            win_results = [x + (2 * .948) for x in win_results]\n",
    "    \n",
    "        avg_wins = statistics.mean(win_results)\n",
    "        avg_loss = statistics.mean(loss_results)\n",
    "        most_common_win = statistics.mode(win_results)\n",
    "        most_common_loss = statistics.mode(loss_results)\n",
    "\n",
    "\n",
    "        win_counts = Counter(win_results)    \n",
    "        total_simulations = len(win_results)\n",
    "        win_percentages = {f\"win_{wins}\": (win_counts[wins] / total_simulations) for wins in range(13)}\n",
    "        win_thresholds = pd.DataFrame([win_percentages])\n",
    "        \n",
    "        # win_thresholds = {}\n",
    "        # for wins in range(13):  # 0 to 12 wins\n",
    "        #     win_thresholds[f'win_{wins}'] = win_df.apply(lambda x: (x == wins).sum() / len(x), axis=0)\n",
    "\n",
    "        win_thresholds['WIN6%'] = win_thresholds.loc[:, 'win_6':'win_12'].sum(axis=1)\n",
    "        win_thresholds['expected_wins'] = avg_wins\n",
    "        win_thresholds['expected_losses'] = avg_loss\n",
    "        win_thresholds['projected_wins'] = most_common_win\n",
    "        win_thresholds['projected_losses'] = most_common_loss\n",
    "\n",
    "        return win_thresholds\n",
    "    \n",
    "    avg_win, avg_loss = monte_carlo_simulation_average(num_simulations, schedules, average, team_name)\n",
    "    win_thresholds = analyze_simulation_average(avg_win, avg_loss,schedules)\n",
    "    return win_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if postseason:\n",
    "    elo_ratings_list = [*ratings_api.get_elo_ratings(year=current_year)]\n",
    "else:\n",
    "    elo_ratings_list = [*ratings_api.get_elo_ratings(year=current_year, week=current_week)]\n",
    "elo_ratings_dict = [dict(\n",
    "    team = e.team,\n",
    "    elo = e.elo\n",
    ") for e in elo_ratings_list]\n",
    "elo_ratings = pd.DataFrame(elo_ratings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_list = []\n",
    "\n",
    "response = players_api.get_returning_production(year = current_year)\n",
    "production_list = [*production_list, *response]\n",
    "\n",
    "production_dict = [dict(\n",
    "    season=r.season,\n",
    "    team=r.team,\n",
    "    returning_ppa=r.percent_ppa,\n",
    "    returning_usage=r.usage\n",
    ") for r in production_list]\n",
    "returning_production = pd.DataFrame(production_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_list = []\n",
    "response = games_api.get_team_records(year=current_year)\n",
    "records_list = [*records_list, *response]\n",
    "records_dict = [dict(\n",
    "    team = r.team,\n",
    "    games_played = r.total.games,\n",
    "    wins = r.total.wins,\n",
    "    losses = r.total.losses,\n",
    "    conference_games = r.conference_games.games,\n",
    "    conference_wins = r.conference_games.wins,\n",
    "    conference_losses = r.conference_games.losses\n",
    ") for r in records_list]\n",
    "records = pd.DataFrame(records_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_ppa_list = []\n",
    "response = metrics_api.get_player_season_ppa(year=current_year, position = 'QB', threshold = 10)\n",
    "qb_ppa_list = [*qb_ppa_list, *response]\n",
    "\n",
    "qb_ppa_dict = [dict(\n",
    "    team = q.team,\n",
    "    qb_average_ppa = q.average_ppa._pass,\n",
    "    qb_total_ppa = q.total_ppa._pass\n",
    ") for q in qb_ppa_list]\n",
    "qb_ppa = pd.DataFrame(qb_ppa_dict)\n",
    "qb_ppa = qb_ppa.groupby('team', as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_fpi_list = []\n",
    "response = ratings_api.get_fpi_ratings(year = current_year)\n",
    "team_fpi_list = [*team_fpi_list, *response]\n",
    "\n",
    "team_fpi_dict = [dict(\n",
    "    team = f.team,\n",
    "    fpi = f.fpi,\n",
    "    fpi_rank = f.resume_ranks.fpi,\n",
    "    fpi_sor = f.resume_ranks.strength_of_record,\n",
    "    fpi_sos = f.resume_ranks.strength_of_schedule,\n",
    "    def_eff = f.efficiencies.defense,\n",
    "    off_eff = f.efficiencies.offense,\n",
    "    special_eff = f.efficiencies.special_teams\n",
    ") for f in team_fpi_list]\n",
    "team_fpi = pd.DataFrame(team_fpi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_srs_list = []\n",
    "response = ratings_api.get_srs_ratings(year = current_year)\n",
    "team_srs_list = [*team_srs_list, *response]\n",
    "\n",
    "team_srs_dict = [dict(\n",
    "    team = f.team,\n",
    "    srs = f.rating,\n",
    "    srs_rank = f.ranking\n",
    ") for f in team_srs_list]\n",
    "team_srs = pd.DataFrame(team_srs_dict).dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_sp_list = []\n",
    "response = ratings_api.get_sp_ratings(year=current_year)\n",
    "team_sp_list = [*team_sp_list, *response]\n",
    "\n",
    "team_sp_dict = [dict(\n",
    "    team = t.team,\n",
    "    ranking = t.ranking,\n",
    "    sp_rating = t.rating\n",
    ") for t in team_sp_list]\n",
    "team_sp = pd.DataFrame(team_sp_dict).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logos_info_list = []\n",
    "response = teams_api.get_teams()\n",
    "logos_info_list = [*logos_info_list, *response]\n",
    "\n",
    "logos_info_dict = [dict(\n",
    "    team = l.school,\n",
    "    color = l.color,\n",
    "    alt_color = l.alt_color,\n",
    "    logo = l.logos\n",
    ") for l in logos_info_list]\n",
    "logos_info = pd.DataFrame(logos_info_dict)\n",
    "logos_info = logos_info.dropna(subset=['logo', 'color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_metrics_response_2024 = []\n",
    "response = advanced_instance.get_advanced_team_season_stats(year = current_year)\n",
    "advanced_metrics_response_2024 = [*advanced_metrics_response_2024, *response]\n",
    "advanced_metrics_2024 = pd.DataFrame()\n",
    "\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "for i in range(len(advanced_metrics_response_2024)):\n",
    "    data = advanced_metrics_response_2024[i].to_dict() if hasattr(advanced_metrics_response_2024[i], 'to_dict') else vars(advanced_metrics_response_2024[i])\n",
    "   \n",
    "    offense_stats = flatten_dict(data['offense'], parent_key='Offense')\n",
    "    defense_stats = flatten_dict(data['defense'], parent_key='Defense')\n",
    "    combined_data = {\n",
    "        'team':data['team'],\n",
    "        **offense_stats,\n",
    "        **defense_stats\n",
    "    }\n",
    "    df = pd.DataFrame([combined_data])\n",
    "    advanced_metrics_2024 = pd.concat([advanced_metrics_2024, df], ignore_index=True)\n",
    "\n",
    "columns_to_keep = ['team', 'Offense_success_rate', 'Defense_success_rate', \n",
    "                   'Offense_explosiveness', 'Defense_explosiveness', 'Offense_ppa', 'Offense_power_success', 'Offense_stuff_rate', 'Defense_power_success', 'Defense_stuff_rate',\n",
    "                   'Defense_ppa', 'Offense_points_per_opportunity', 'Defense_points_per_opportunity', 'Defense_havoc_total', \n",
    "                   'Offense_field_position_average_predicted_points', 'Defense_field_position_average_predicted_points',\n",
    "                   'Offense_field_position_average_start', 'Defense_field_position_average_start']\n",
    "metrics = advanced_metrics_2024[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives the SP rating for each conference for all years\n",
    "conference_sp = []\n",
    "response = ratings_api.get_conference_sp_ratings(year=current_year)\n",
    "conference_sp = [*conference_sp, *response]\n",
    "\n",
    "sp_conf = [dict(\n",
    "    conference=c.conference,\n",
    "    season=c.year,\n",
    "    sp_conf_rating=c.rating\n",
    ") for c in conference_sp]\n",
    "conference_sp_rating = pd.DataFrame(sp_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_team_stats = pd.DataFrame()\n",
    "# for team in metrics['team']:\n",
    "#     print(team)\n",
    "#     if team == 'Pittsburgh':\n",
    "#         team_stats_list = []\n",
    "#         response = advanced_instance.get_team_season_stats(year=current_year, team = team, end_week = 13)\n",
    "#         team_stats_list = [*team_stats_list, *response]\n",
    "#     else:\n",
    "#         team_stats_list = []\n",
    "#         response = advanced_instance.get_team_season_stats(year=current_year, team = team)\n",
    "#         team_stats_list = [*team_stats_list, *response]\n",
    "#     team_stats_dict = [dict(\n",
    "#         team = s.team,\n",
    "#         stat_name = s.stat_name,\n",
    "#         stat_value = s.stat_value\n",
    "#     ) for s in team_stats_list]\n",
    "#     team_stats = pd.DataFrame(team_stats_dict)\n",
    "#     team_stats = team_stats.pivot(index='team', columns='stat_name', values='stat_value').reset_index().fillna(0)\n",
    "#     team_stats['total_turnovers'] = team_stats['fumblesRecovered'] + team_stats['passesIntercepted'] - team_stats['turnovers']\n",
    "#     team_stats['thirdDownConversionRate'] = round(team_stats['thirdDownConversions'] / team_stats['thirdDowns'],4)\n",
    "#     team_stats['fourthDownConversionRate'] = round(team_stats['fourthDownConversions'] / team_stats['fourthDowns'], 4)\n",
    "#     team_stats['possessionTimeMinutes'] = round(team_stats['possessionTime'] / 60,2)\n",
    "#     all_team_stats = pd.concat([all_team_stats, team_stats])\n",
    "# team_stats = all_team_stats.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats_list = []\n",
    "response = advanced_instance.get_team_season_stats(year=current_year)\n",
    "team_stats_list = [*team_stats_list, *response]\n",
    "\n",
    "team_stats_dict = [dict(\n",
    "    team = s.team,\n",
    "    stat_name = s.stat_name,\n",
    "    stat_value = s.stat_value\n",
    ") for s in team_stats_list]\n",
    "team_stats = pd.DataFrame(team_stats_dict)\n",
    "team_stats = team_stats.pivot(index='team', columns='stat_name', values='stat_value').reset_index().fillna(0)\n",
    "team_stats['total_turnovers'] = team_stats['fumblesRecovered'] + team_stats['passesIntercepted'] - team_stats['turnovers']\n",
    "team_stats['thirdDownConversionRate'] = round(team_stats['thirdDownConversions'] / team_stats['thirdDowns'],4)\n",
    "team_stats['fourthDownConversionRate'] = round(team_stats['fourthDownConversions'] / team_stats['fourthDowns'], 4)\n",
    "team_stats['possessionTimeMinutes'] = round(team_stats['possessionTime'] / 60,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives each teams talent rating for each year\n",
    "talent_list = []\n",
    "for year in range(current_year-3, current_year+1):\n",
    "    response = teams_api.get_talent(year=year)\n",
    "    talent_list = [*talent_list, *response]\n",
    "\n",
    "talent_dict = [dict(\n",
    "    team=t.school,\n",
    "    season=t.year,\n",
    "    talent=t.talent\n",
    ") for t in talent_list]\n",
    "talent = pd.DataFrame(talent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_info_list = [*teams_api.get_fbs_teams()]\n",
    "team_dict = [dict(\n",
    "    team = t.school,\n",
    "    conference = t.conference\n",
    ") for t in team_info_list]\n",
    "team_info = pd.DataFrame(team_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "recruiting_info_list = []\n",
    "for year in range(current_year-3,current_year+1):\n",
    "    response = recruiting_api.get_recruiting_teams(year=year)\n",
    "    recruiting_info_list = [*recruiting_info_list, *response]\n",
    "\n",
    "recruiting_info_dict = [dict(\n",
    "    team = r.team,\n",
    "    year = r.year,\n",
    "    points = r.points\n",
    ") for r in recruiting_info_list]\n",
    "recruiting = pd.DataFrame(recruiting_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entire talent profile for the team over the last three years\n",
    "last_three_rows = talent.groupby('team').tail(3)\n",
    "avg_talent_per_team = last_three_rows.groupby('team')['talent'].mean().reset_index()\n",
    "avg_talent_per_team.columns = ['team', 'avg_talent']\n",
    "avg_talent_per_team.loc[avg_talent_per_team['team'] == 'Oregon State', 'avg_talent'] -= 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recruiting points over the last 4 years\n",
    "last_three = recruiting.groupby('team').tail(3)\n",
    "recruiting_per_team = last_three.groupby('team')['points'].sum().reset_index()\n",
    "recruiting_per_team.columns = ['team', 'avg_points']\n",
    "recruiting_per_team['avg_points'] = recruiting_per_team['avg_points'] + 150\n",
    "# recruiting_per_team.loc[recruiting_per_team['team'] == 'Air Force', 'avg_points'] /= 2\n",
    "recruiting_per_team.loc[recruiting_per_team['team'] == 'Army', 'avg_points'] += 150\n",
    "recruiting_per_team.loc[recruiting_per_team['team'] == 'Navy', 'avg_points'] += 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_1 = pd.merge(team_info, avg_talent_per_team, how='left', on='team')\n",
    "intermediate_2 = pd.merge(intermediate_1, conference_sp_rating, how='left', on='conference')\n",
    "intermediate_3 = pd.merge(intermediate_2, team_stats, how='left', on='team')\n",
    "intermediate_4 = pd.merge(intermediate_3, logos_info, how='left', on='team')\n",
    "intermediate_5 = pd.merge(intermediate_4, qb_ppa, how='left', on='team')\n",
    "intermediate_6 = pd.merge(intermediate_5, team_fpi, how='left', on='team')\n",
    "intermediate_7 = pd.merge(intermediate_6, records, how='left', on='team')\n",
    "team_data = pd.merge(intermediate_7, metrics, how='left', on='team')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For military schools and new FBS schools, use recruiting points instead of team talent\n",
    "target_teams = ['Air Force', 'Army', 'Navy', 'James Madison', 'Sam Houston', 'Kennesaw State', 'Jacksonville State', 'Boise State']\n",
    "mask = team_data['team'].isin(target_teams)\n",
    "team_data.loc[mask, 'avg_talent'] = team_data.loc[mask, 'team'].map(\n",
    "    recruiting_per_team.set_index('team')['avg_points']\n",
    ")\n",
    "team_data = team_data.dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESCAPE v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################################################\n",
    "\n",
    "# All the scalers used for the team data\n",
    "scaler100 = MinMaxScaler(feature_range=(1, 100))\n",
    "scaler60 = MinMaxScaler(feature_range=(40,98.8))\n",
    "scaler10 = MinMaxScaler(feature_range=(1,10))\n",
    "scalerTurnovers = MinMaxScaler(feature_range=(1, 100))\n",
    "scalerPenalties = MinMaxScaler(feature_range=(1, 100))\n",
    "scalerThirdDown = MinMaxScaler(feature_range=(1, 100))\n",
    "scalerTalent = MinMaxScaler(feature_range=(100,1000))\n",
    "scalerAvgFieldPosition = MinMaxScaler(feature_range=(-10,10))\n",
    "scalerPPO = MinMaxScaler(feature_range=(1,100))\n",
    "\n",
    "#################################################################################################################################################\n",
    "\n",
    "# scaling all the data based on the scaler\n",
    "team_data['sp_conf_scaled'] = scaler10.fit_transform(team_data[['sp_conf_rating']])\n",
    "team_data['total_turnovers_scaled'] = scalerTurnovers.fit_transform(team_data[['total_turnovers']])\n",
    "team_data['possession_scaled'] = scaler100.fit_transform(team_data[['possessionTimeMinutes']])\n",
    "team_data['third_down_scaled'] = scalerThirdDown.fit_transform(team_data[['thirdDownConversionRate']])\n",
    "team_data['offense_avg_field_position_scaled'] = -1*scalerAvgFieldPosition.fit_transform(team_data[['Offense_field_position_average_start']])\n",
    "team_data['defense_avg_field_position_scaled'] = scalerAvgFieldPosition.fit_transform(team_data[['Defense_field_position_average_start']])\n",
    "team_data['offense_ppo_scaled'] = scalerPPO.fit_transform(team_data[['Offense_points_per_opportunity']])\n",
    "team_data['offense_success_scaled'] = scaler100.fit_transform(team_data[['Offense_success_rate']])\n",
    "team_data['offense_explosive'] = scaler100.fit_transform(team_data[['Offense_explosiveness']])\n",
    "team_data['talent_scaled'] = scalerTalent.fit_transform(team_data[['avg_talent']])\n",
    "\n",
    "def_ppo_min = team_data['Defense_points_per_opportunity'].min()\n",
    "def_ppo_max = team_data['Defense_points_per_opportunity'].max()\n",
    "team_data['defense_ppo_scaled'] = 100 - (team_data['Defense_points_per_opportunity'] - def_ppo_min) * 99 / (def_ppo_max - def_ppo_min)\n",
    "\n",
    "pen_min = team_data['penaltyYards'].min()\n",
    "pen_max = team_data['penaltyYards'].max()\n",
    "team_data['penalties_scaled'] = 100 - (team_data['penaltyYards'] - pen_min) * 99 / (pen_max - pen_min)\n",
    "\n",
    "off_field_min = team_data['Offense_field_position_average_start'].min()\n",
    "off_field_max = team_data['Offense_field_position_average_start'].max()\n",
    "team_data['offense_avg_field_position_scaled'] = 100 - (team_data['Offense_field_position_average_start'] - off_field_min) * 99 / (off_field_max - off_field_min)\n",
    "\n",
    "team_data['offense_ppa_scaled'] = scaler100.fit_transform(team_data[['Offense_ppa']])\n",
    "ppa_min = team_data['Defense_ppa'].min()\n",
    "ppa_max = team_data['Defense_ppa'].max()\n",
    "team_data['defense_ppa_scaled'] = 100 - (team_data['Defense_ppa'] - ppa_min) * 99 / (ppa_max - ppa_min)\n",
    "\n",
    "success_min = team_data['Defense_success_rate'].min()\n",
    "success_max = team_data['Defense_success_rate'].max()\n",
    "team_data['defense_success_scaled'] = 100 - (team_data['Defense_success_rate'] - success_min) * 99 / (success_max - success_min)\n",
    "\n",
    "explosiveness_min = team_data['Defense_explosiveness'].min()\n",
    "explosiveness_max = team_data['Defense_explosiveness'].max()\n",
    "team_data['defense_explosive'] = 100 - (team_data['Defense_explosiveness'] - explosiveness_min) * 99 / (explosiveness_max - explosiveness_min)\n",
    "\n",
    "#################################################################################################################################################\n",
    "\n",
    "# calculating the adjusted metric as well as the power rating for each team\n",
    "alpha = .05\n",
    "team_data['adjusted_metric'] = (0.7 * (team_data['offense_success_scaled'] + team_data['defense_success_scaled']) +\n",
    "                                (alpha * team_data['sp_conf_scaled']**0.5) +\n",
    "                                0.25 * (team_data['offense_explosive'] + team_data['defense_explosive']) +\n",
    "                                (0.2*team_data['talent_scaled']) + (0.4*(team_data['total_turnovers_scaled'] + team_data['penalties_scaled'] + team_data['offense_ppo_scaled'])))\n",
    "\n",
    "team_data['average_metric'] = (team_data['offense_success_scaled'] + team_data['offense_explosive'] + team_data['offense_ppa_scaled'] + \n",
    "                               team_data['defense_success_scaled'] + team_data['defense_explosive'] + team_data['defense_ppa_scaled']) / 6\n",
    "\n",
    "team_data['power_rating'] = scaler60.fit_transform(team_data[['adjusted_metric']]).round(2)\n",
    "team_data['power_rating'] = round(team_data['power_rating'] - team_data['power_rating'].mean(), 1)\n",
    "team_data = team_data.sort_values(by='power_rating', ascending=False).reset_index(drop=True)\n",
    "team_data = team_data.drop_duplicates(subset='team')\n",
    "team_power_rankings = team_data[['team', 'power_rating', 'conference']]\n",
    "team_power_rankings = team_power_rankings.sort_values(by='power_rating', ascending=False).reset_index(drop=True)\n",
    "if (team_power_rankings.iloc[0, 1] - team_power_rankings.iloc[133, 1] > 55):\n",
    "    team_power_rankings.iloc[0, 1] = team_power_rankings.iloc[133, 1] + 55\n",
    "    team_data.loc[0, 'power_rating'] = team_power_rankings.iloc[0, 1]\n",
    "team_power_rankings.index = team_power_rankings.index + 1\n",
    "team_power_rankings['week'] = current_week\n",
    "team_power_rankings['year'] = current_year\n",
    "# team_data.to_csv(\"./ESCAPE Ratings/all_team_data.csv\")\n",
    "# team_power_rankings.to_csv(f'./ESCAPE Ratings/ESCAPE_week{current_week}_{current_year}.csv')\n",
    "\n",
    "#################################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESCAPE v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the scalers used for the team data\n",
    "scaler100 = MinMaxScaler(feature_range=(1, 100))\n",
    "scaler60 = MinMaxScaler(feature_range=(40,98.8))\n",
    "scaler10 = MinMaxScaler(feature_range=(1,10))\n",
    "scalerTurnovers = MinMaxScaler(feature_range=(1, 100))\n",
    "scalerPenalties = MinMaxScaler(feature_range=(1, 100))\n",
    "scalerThirdDown = MinMaxScaler(feature_range=(1, 100))\n",
    "scalerTalent = MinMaxScaler(feature_range=(100,1000))\n",
    "scalerAvgFieldPosition = MinMaxScaler(feature_range=(-10,10))\n",
    "scalerPPO = MinMaxScaler(feature_range=(1,100))\n",
    "\n",
    "#################################################################################################################################################\n",
    "\n",
    "# scaling all the data based on the scaler\n",
    "team_data['sp_conf_scaled'] = scaler10.fit_transform(team_data[['sp_conf_rating']])\n",
    "team_data['total_turnovers_scaled'] = scalerTurnovers.fit_transform(team_data[['total_turnovers']])\n",
    "team_data['possession_scaled'] = scaler100.fit_transform(team_data[['possessionTimeMinutes']])\n",
    "team_data['third_down_scaled'] = scalerThirdDown.fit_transform(team_data[['thirdDownConversionRate']])\n",
    "team_data['offense_avg_field_position_scaled'] = -1*scalerAvgFieldPosition.fit_transform(team_data[['Offense_field_position_average_start']])\n",
    "team_data['defense_avg_field_position_scaled'] = scalerAvgFieldPosition.fit_transform(team_data[['Defense_field_position_average_start']])\n",
    "team_data['offense_ppo_scaled'] = scalerPPO.fit_transform(team_data[['Offense_points_per_opportunity']])\n",
    "team_data['offense_success_scaled'] = scaler100.fit_transform(team_data[['Offense_success_rate']])\n",
    "team_data['offense_explosive'] = scaler100.fit_transform(team_data[['Offense_explosiveness']])\n",
    "team_data['talent_scaled'] = scalerTalent.fit_transform(team_data[['avg_talent']])\n",
    "\n",
    "def_ppo_min = team_data['Defense_points_per_opportunity'].min()\n",
    "def_ppo_max = team_data['Defense_points_per_opportunity'].max()\n",
    "team_data['defense_ppo_scaled'] = 100 - (team_data['Defense_points_per_opportunity'] - def_ppo_min) * 99 / (def_ppo_max - def_ppo_min)\n",
    "\n",
    "pen_min = team_data['penaltyYards'].min()\n",
    "pen_max = team_data['penaltyYards'].max()\n",
    "team_data['penalties_scaled'] = 100 - (team_data['penaltyYards'] - pen_min) * 99 / (pen_max - pen_min)\n",
    "\n",
    "off_field_min = team_data['Offense_field_position_average_start'].min()\n",
    "off_field_max = team_data['Offense_field_position_average_start'].max()\n",
    "team_data['offense_avg_field_position_scaled'] = 100 - (team_data['Offense_field_position_average_start'] - off_field_min) * 99 / (off_field_max - off_field_min)\n",
    "\n",
    "team_data['offense_ppa_scaled'] = scaler100.fit_transform(team_data[['Offense_ppa']])\n",
    "ppa_min = team_data['Defense_ppa'].min()\n",
    "ppa_max = team_data['Defense_ppa'].max()\n",
    "team_data['defense_ppa_scaled'] = 100 - (team_data['Defense_ppa'] - ppa_min) * 99 / (ppa_max - ppa_min)\n",
    "\n",
    "success_min = team_data['Defense_success_rate'].min()\n",
    "success_max = team_data['Defense_success_rate'].max()\n",
    "team_data['defense_success_scaled'] = 100 - (team_data['Defense_success_rate'] - success_min) * 99 / (success_max - success_min)\n",
    "\n",
    "explosiveness_min = team_data['Defense_explosiveness'].min()\n",
    "explosiveness_max = team_data['Defense_explosiveness'].max()\n",
    "team_data['defense_explosive'] = 100 - (team_data['Defense_explosiveness'] - explosiveness_min) * 99 / (explosiveness_max - explosiveness_min)\n",
    "\n",
    "#################################################################################################################################################\n",
    "\n",
    "# calculating the adjusted metric as well as the power rating for each team\n",
    "alpha = .05\n",
    "team_data['adjusted_metric'] = (0.7 * (team_data['offense_success_scaled'] + team_data['defense_success_scaled']) +\n",
    "                                (alpha * team_data['sp_conf_scaled']**0.5) +\n",
    "                                0.25 * (team_data['offense_explosive'] + team_data['defense_explosive']) +\n",
    "                                (0*team_data['talent_scaled']) + (0.4*(team_data['total_turnovers_scaled'] + team_data['penalties_scaled'] + team_data['offense_ppo_scaled'])))\n",
    "\n",
    "team_data['average_metric'] = (team_data['offense_success_scaled'] + team_data['offense_explosive'] + team_data['offense_ppa_scaled'] + \n",
    "                               team_data['defense_success_scaled'] + team_data['defense_explosive'] + team_data['defense_ppa_scaled']) / 6\n",
    "\n",
    "team_data['in_house_pr'] = scaler60.fit_transform(team_data[['adjusted_metric']]).round(2)\n",
    "team_data['in_house_pr'] = round(team_data['in_house_pr'] - team_data['in_house_pr'].mean(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 500/500 [21:39<00:00,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          team  power_ranking  combined_rank\n",
      "79  Ohio State      99.579849       3.577345\n",
      "2      Alabama      87.379540       7.219759\n",
      "86  Penn State      83.264130      12.736553\n",
      "77  Notre Dame      82.390372       7.953001\n",
      "84      Oregon      78.977485       7.154690\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from scipy.optimize import differential_evolution\n",
    "from tqdm import tqdm\n",
    "pbar = tqdm(total=500, desc=\"Optimization Progress\")\n",
    "def progress_callback(xk, convergence):\n",
    "    \"\"\"Callback to update the progress bar after each iteration.\"\"\"\n",
    "    pbar.update(1)\n",
    "    if convergence < 1e-4:  # Close bar if convergence is achieved early\n",
    "        pbar.close()\n",
    "\n",
    "######################################## SCALING THE EXTRA STATS #################################################\n",
    "\n",
    "offensive_columns = [\n",
    "    'Offense_success_rate', 'Offense_explosiveness', 'Offense_ppa', 'Offense_points_per_opportunity', 'Offense_field_position_average_predicted_points', 'Offense_power_success', 'Offense_stuff_rate'\n",
    "]\n",
    "defensive_columns = [\n",
    "    'Defense_success_rate', 'Defense_explosiveness', 'Defense_ppa', 'Defense_points_per_opportunity', 'Defense_field_position_average_predicted_points', 'Defense_power_success', 'Defense_stuff_rate'\n",
    "]\n",
    "other_columns = [\n",
    "    'avg_talent', 'sp_conf_rating', 'thirdDownConversionRate', 'total_turnovers', 'puntReturnTDs', 'kickReturnTDs', 'Defense_havoc_total', 'qb_average_ppa', 'qb_total_ppa'\n",
    "]\n",
    "\n",
    "# Function to scale columns between 1 and 100\n",
    "def scale_columns(df, columns, reverse=False):\n",
    "    scaler = MinMaxScaler(feature_range=(1, 100))\n",
    "    if reverse:\n",
    "        # For defensive stats, the lower value is better, so we reverse the scaling\n",
    "        scaled = scaler.fit_transform(-df[columns])\n",
    "    else:\n",
    "        scaled = scaler.fit_transform(df[columns])\n",
    "    return pd.DataFrame(scaled, columns=columns)\n",
    "\n",
    "team_data[offensive_columns] = scale_columns(team_data, offensive_columns)\n",
    "team_data[defensive_columns] = scale_columns(team_data, defensive_columns, reverse=True)\n",
    "team_data[['avg_talent', 'sp_conf_rating']] = scale_columns(team_data, ['avg_talent', 'sp_conf_rating'])\n",
    "team_data[['thirdDownConversionRate']] = scale_columns(team_data, ['thirdDownConversionRate'])\n",
    "team_data[['fourthDownConversionRate']] = scale_columns(team_data, ['fourthDownConversionRate'])\n",
    "team_data[['total_turnovers']] = scale_columns(team_data, ['total_turnovers'], reverse=True)  # Lower turnovers are better\n",
    "team_data[['puntReturnTDs', 'kickReturnTDs']] = scale_columns(team_data, ['puntReturnTDs', 'kickReturnTDs'])\n",
    "team_data[['Defense_havoc_total']] = scale_columns(team_data, ['Defense_havoc_total'])\n",
    "\n",
    "merged_data = pd.merge(team_data, team_sp[['team', 'ranking']], on='team')\n",
    "\n",
    "######################################## HERDING TO SP+ AND FPI #################################################\n",
    "\n",
    "def objective_function(weights):\n",
    "    (w_offense_sr, w_offense_expl, w_offense_ppa, w_offense_ppo,\n",
    "     w_defense_sr, w_defense_expl, w_defense_ppa, w_defense_ppo,\n",
    "     w_avg_talent, w_third_down, w_turnovers,\n",
    "     w_special_punt, w_special_kick, w_havoc, w_in_house, \n",
    "     w_avg_qb_ppa, w_total_qb_ppa, w_defense_fp_app, \n",
    "     w_off_power, w_def_power, w_off_stuff, w_def_stuff,\n",
    "     rank_weight_fpi, rank_weight_other) = weights\n",
    "    \n",
    "    merged_data['power_ranking'] = (\n",
    "        (w_offense_sr * merged_data['Offense_success_rate'] + \n",
    "        w_offense_expl * merged_data['Offense_explosiveness'] + \n",
    "        w_offense_ppa * merged_data['Offense_ppa'] + \n",
    "        w_offense_ppo * merged_data['Offense_points_per_opportunity'] +\n",
    "        w_off_power * merged_data['Offense_power_success'] +\n",
    "        w_off_stuff * merged_data['Offense_stuff_rate'])\n",
    "        - (w_defense_sr * merged_data['Defense_success_rate'] + \n",
    "        w_defense_expl * merged_data['Defense_explosiveness'] + \n",
    "        w_defense_ppa * merged_data['Defense_ppa'] + \n",
    "        w_defense_ppo * merged_data['Defense_points_per_opportunity'] +\n",
    "        w_defense_fp_app * merged_data['Defense_field_position_average_predicted_points'] +\n",
    "        w_def_power * merged_data['Defense_power_success'] +\n",
    "        w_def_stuff * merged_data['Defense_stuff_rate'])\n",
    "        + w_avg_talent * merged_data['avg_talent']\n",
    "        + (w_third_down * merged_data['thirdDownConversionRate']\n",
    "        + w_turnovers * merged_data['total_turnovers']\n",
    "        + w_special_punt * merged_data['puntReturnTDs'] \n",
    "        + w_special_kick * merged_data['kickReturnTDs']\n",
    "        + w_havoc * merged_data['Defense_havoc_total'])\n",
    "        + w_in_house * merged_data['in_house_pr']\n",
    "        + w_avg_qb_ppa * merged_data['qb_average_ppa']\n",
    "        + w_total_qb_ppa * merged_data['qb_total_ppa']\n",
    "    )\n",
    "\n",
    "    # My ranking\n",
    "    merged_data['calculated_rank'] = merged_data['power_ranking'].rank(ascending=False)\n",
    "    # SP+/FPI combined ranking\n",
    "    merged_data['combined_rank'] = (\n",
    "        rank_weight_fpi * merged_data['fpi_rank'] +\n",
    "        rank_weight_other * merged_data['ranking']\n",
    "    )\n",
    "    spearman_corr = merged_data[['calculated_rank', 'combined_rank']].corr(method='spearman').iloc[0, 1]\n",
    "    \n",
    "    return -spearman_corr\n",
    "\n",
    "# Define the bounds for each weight (allowing weights to vary more widely)\n",
    "bounds = [\n",
    "    (-1, 1),  # Offense Success Rate\n",
    "    (-1, 1),  # Offense Explosiveness\n",
    "    (-1, 1),  # Offense PPA\n",
    "    (-1, 1),  # Offense PPO\n",
    "    (-1, 1),  # Defense Success Rate\n",
    "    (-1, 1),  # Defense Explosiveness\n",
    "    (-1, 1),  # Defense PPA \n",
    "    (-1, 1),  # Defense PPO\n",
    "    (0, 0.5), # Avg Talent: Bound between 0 and 0.5\n",
    "    (-1, 1),  # Third Down Conversion\n",
    "    (-1, 1),  # Turnovers\n",
    "    (-1, 1),  # Special Teams Punt\n",
    "    (-1, 1),  # Special Teams Kick\n",
    "    (-1, 1),  # Havoc\n",
    "    (0, 0.5), # In House PR\n",
    "    (-1, 1),  # Average QB PPA\n",
    "    (-1, 1),  # Total QB PPA\n",
    "    (-1, 1),  # Defense FP APP\n",
    "    (-1, 1),  # Offense Power Success\n",
    "    (-1, 1),  # Defense Power Success\n",
    "    (-1, 1),  # Offense Stuff Rate\n",
    "    (-1, 1),  # Defense Stuff Rate\n",
    "    (0, 1),   # FPI Weight\n",
    "    (0, 1)    # SP+ Weight\n",
    "]\n",
    "\n",
    "result = differential_evolution(objective_function, bounds, strategy='best1bin', maxiter=500, tol=1e-4, seed=42, callback=progress_callback)\n",
    "optimized_weights = result.x\n",
    "\n",
    "######################################## USING OUTPUT FROM OPTIMIZATION TO CREATE POWER RANKING #################################################\n",
    "\n",
    "# Recalculate the power ranking using the optimized weights\n",
    "merged_data['power_ranking'] = (\n",
    "    (optimized_weights[0] * merged_data['Offense_success_rate'] + \n",
    "    optimized_weights[1] * merged_data['Offense_explosiveness'] + \n",
    "    optimized_weights[2] * merged_data['Offense_ppa'] + \n",
    "    optimized_weights[3] * merged_data['Offense_points_per_opportunity'] +\n",
    "    optimized_weights[18] * merged_data['Offense_power_success'] +\n",
    "    optimized_weights[20] * merged_data['Offense_stuff_rate'])\n",
    "    - (optimized_weights[4] * merged_data['Defense_success_rate'] + \n",
    "    optimized_weights[5] * merged_data['Defense_explosiveness'] + \n",
    "    optimized_weights[6] * merged_data['Defense_ppa'] + \n",
    "    optimized_weights[7] * merged_data['Defense_points_per_opportunity'] +\n",
    "    optimized_weights[17] * merged_data['Defense_field_position_average_predicted_points'] +\n",
    "    optimized_weights[19] * merged_data['Defense_power_success'] +\n",
    "    optimized_weights[21] * merged_data['Defense_stuff_rate'])\n",
    "    + optimized_weights[8] * merged_data['avg_talent']\n",
    "    + (optimized_weights[9] * merged_data['thirdDownConversionRate']\n",
    "    + optimized_weights[10] * merged_data['total_turnovers']\n",
    "    + optimized_weights[11] * merged_data['puntReturnTDs'] \n",
    "    + optimized_weights[12] * merged_data['kickReturnTDs']\n",
    "    + optimized_weights[13] * merged_data['Defense_havoc_total'])\n",
    "    + optimized_weights[14] * merged_data['in_house_pr']\n",
    "    + optimized_weights[15] * merged_data['qb_average_ppa']\n",
    "    + optimized_weights[16] * merged_data['qb_total_ppa']\n",
    ")\n",
    "\n",
    "output_model = merged_data.copy()\n",
    "# Sort by the power ranking to see the final order of teams\n",
    "final_ranking = merged_data[['team', 'power_ranking', 'combined_rank']].sort_values(by='power_ranking', ascending=False)\n",
    "print(final_ranking.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data = output_model.copy()\n",
    "\n",
    "######################################## TEAM STATS AND RANKINGS #################################################\n",
    "\n",
    "team_data['PBR'] = team_data['penaltyYards'] / team_data['talent_scaled']\n",
    "team_data['PBR_rank'] = team_data['PBR'].rank(method='min', ascending=True)\n",
    "\n",
    "team_data['STM'] = (\n",
    "    (team_data['kickReturnYards'] / team_data['kickReturns']) +\n",
    "    (team_data['puntReturnYards'] / team_data['puntReturns']) -\n",
    "    team_data['Offense_field_position_average_start'] +\n",
    "    team_data['Defense_field_position_average_start']\n",
    ")\n",
    "team_data['STM_rank'] = team_data['STM'].rank(method='min', ascending=False)\n",
    "\n",
    "team_data['DCE'] = (\n",
    "    (team_data['possessionTimeMinutes'] / team_data['games_played']) +\n",
    "    (10 * team_data['thirdDownConversionRate']) +\n",
    "    (20 * team_data['fourthDownConversionRate'])\n",
    ")\n",
    "team_data['DCE_rank'] = team_data['DCE'].rank(method='min', ascending=False)\n",
    "\n",
    "team_data['DefensivePossessionTime'] = (team_data['games_played'] * 60) - team_data['possessionTimeMinutes']\n",
    "team_data['DDE'] = ( \n",
    "    (0.6 * team_data['tacklesForLoss']) +\n",
    "    (4 * team_data['interceptions']) +\n",
    "    (6 * team_data['fumblesRecovered']) +\n",
    "    (1.6 * team_data['sacks'])\n",
    ")\n",
    "team_data['DDE_rank'] = team_data['DDE'].rank(method='min', ascending=False)\n",
    "\n",
    "team_data[\"offensive_total\"] = team_data[offensive_columns].sum(axis=1)\n",
    "team_data[\"offensive_rank\"] = team_data[\"offensive_total\"].rank(ascending=False, method=\"dense\").astype(int)\n",
    "team_data[\"defensive_total\"] = team_data[defensive_columns].sum(axis=1)\n",
    "team_data[\"defensive_rank\"] = team_data[\"defensive_total\"].rank(ascending=False, method=\"dense\").astype(int)\n",
    "\n",
    "team_data['talent_scaled_rank'] = team_data['talent_scaled'].rank(method='min', ascending=False)\n",
    "team_data['offense_success_rank'] = team_data['offense_success_scaled'].rank(method='min', ascending=False)\n",
    "team_data['defense_success_rank'] = team_data['defense_success_scaled'].rank(method='min', ascending=False)\n",
    "team_data['offense_explosive_rank'] = team_data['offense_explosive'].rank(method='min', ascending=False)\n",
    "team_data['defense_explosive_rank'] = team_data['defense_explosive'].rank(method='min', ascending=False)\n",
    "team_data['total_turnovers_rank'] = team_data['total_turnovers_scaled'].rank(method='min', ascending=False)\n",
    "team_data['penalties_rank'] = team_data['penalties_scaled'].rank(method='min', ascending=False)\n",
    "\n",
    "######################################## POWER RATING #################################################\n",
    "\n",
    "team_data['power_rating'] = team_data['power_ranking'] - team_data['power_ranking'].mean()\n",
    "current_range = team_data['power_rating'].max() - team_data['power_rating'].min()\n",
    "desired_range = 50  # The target range\n",
    "scaling_factor = desired_range / current_range\n",
    "team_data['power_rating'] = round(team_data['power_rating'] * scaling_factor,2)\n",
    "\n",
    "######################################## VEGAS HERDING #################################################\n",
    "\n",
    "adjustments = {\n",
    "    'Utah': -3,\n",
    "    'Tulane': -3,\n",
    "    'Florida Atlantic': -3,\n",
    "    'North Carolina': -3,\n",
    "    'Louisiana Tech': -3,\n",
    "    'Georgia Tech': -3,\n",
    "    'San José State': -3,\n",
    "    'Arkansas State': -3,\n",
    "    'BYU': -3,\n",
    "    'Minnesota': -3,\n",
    "    'North Carolina': -3,\n",
    "    'Alabama': -3,\n",
    "    'Clemson': -3,\n",
    "    'Army':-3,\n",
    "    'Miami': -3,\n",
    "    'UTEP': -3,\n",
    "    'San Diego State': -3,\n",
    "    'Virginia': 3,\n",
    "    'Cincinnati': 3,\n",
    "    'UCF': 3,\n",
    "    'Nebraska': 3,\n",
    "    'App State': 3,\n",
    "    'Stanford': 3,\n",
    "    'New Mexico': 3,\n",
    "    'Syracuse': 3,\n",
    "    'UCLA': 3\n",
    "}\n",
    "\n",
    "for team, adjustment in adjustments.items():\n",
    "    team_data.loc[team_data['team'] == team, 'power_rating'] += adjustment\n",
    "\n",
    "######################################## FINAL FORMATTING #################################################\n",
    "\n",
    "team_data = team_data.sort_values(by='power_rating', ascending=False).reset_index(drop=True)\n",
    "team_data['power_rating'] = round(team_data['power_rating'], 1)\n",
    "team_data = team_data.drop_duplicates(subset='team')\n",
    "team_power_rankings = team_data[['team', 'power_rating', 'conference']]\n",
    "team_power_rankings = team_power_rankings.sort_values(by='power_rating', ascending=False).reset_index(drop=True)\n",
    "team_power_rankings.iloc[0,1] = round(team_power_rankings.iloc[1,1] + round((team_power_rankings.iloc[0,1] - team_power_rankings.iloc[1,1]) / 2, 1),1)\n",
    "team_data.loc[0, 'power_rating'] = team_power_rankings.iloc[0, 1]\n",
    "team_power_rankings.index = team_power_rankings.index + 1\n",
    "team_power_rankings['week'] = current_week\n",
    "team_power_rankings['year'] = current_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_week = 1\n",
    "end_week = 15\n",
    "\n",
    "games_list = []\n",
    "for week in range(start_week,end_week):\n",
    "    response = games_api.get_games(year=current_year, week=week,division = 'fbs')\n",
    "    games_list = [*games_list, *response]\n",
    "if postseason:\n",
    "    response = games_api.get_games(year=current_year, division = 'fbs', season_type='postseason')\n",
    "    games_list = [*games_list, *response]\n",
    "games = [dict(\n",
    "            id=g.id,\n",
    "            season=g.season,\n",
    "            week=g.week,\n",
    "            start_date=g.start_date,\n",
    "            home_team=g.home_team,\n",
    "            home_elo=g.home_pregame_elo,\n",
    "            away_team=g.away_team,\n",
    "            away_elo=g.away_pregame_elo,\n",
    "            home_points = g.home_points,\n",
    "            away_points = g.away_points,\n",
    "            neutral = g.neutral_site\n",
    "            ) for g in games_list if g.home_pregame_elo is not None and g.away_pregame_elo is not None]\n",
    "games.sort(key=date_sort)\n",
    "year_long_schedule = pd.DataFrame(games)\n",
    "\n",
    "year_long_schedule = year_long_schedule.merge(team_data[['team', 'power_rating']], \n",
    "                                    left_on='home_team', \n",
    "                                    right_on='team', \n",
    "                                    how='left').rename(columns={'power_rating': 'home_pr'})\n",
    "year_long_schedule = year_long_schedule.drop(columns=['team'])\n",
    "year_long_schedule = year_long_schedule.merge(team_data[['team', 'power_rating']], \n",
    "                                    left_on='away_team', \n",
    "                                    right_on='team', \n",
    "                                    how='left').rename(columns={'power_rating': 'away_pr'})\n",
    "year_long_schedule = year_long_schedule.drop(columns=['team'])\n",
    "\n",
    "# Apply the ESCAPE_Win_Prob function to the schedule_info DataFrame\n",
    "year_long_schedule['escape_win_prob'] = year_long_schedule.apply(\n",
    "    lambda row: ESCAPE_Win_Prob(row['home_pr'], row['away_pr']), axis=1\n",
    ")\n",
    "year_long_schedule['home_win_prob'] = round((10**((year_long_schedule['home_elo'] - year_long_schedule['away_elo']) / 400)) / ((10**((year_long_schedule['home_elo'] - year_long_schedule['away_elo']) / 400)) + 1)*100,2)\n",
    "\n",
    "average_elo = elo_ratings['elo'].mean()\n",
    "average_pr = round(team_data['power_rating'].mean(), 2)\n",
    "good_team_pr = round(team_data['power_rating'].std() + team_data['power_rating'].mean(),2)\n",
    "elite_team_pr = round(2*team_data['power_rating'].std() + team_data['power_rating'].mean(),2)\n",
    "expected_wins_list = []\n",
    "for team in team_data['team']:\n",
    "    schedule = year_long_schedule[(year_long_schedule['home_team'] == team) | (year_long_schedule['away_team'] == team)]\n",
    "    df = average_team_distribution(1000, schedule, elite_team_pr, team)\n",
    "    expected_wins = df['expected_wins'].values[0] / len(schedule)\n",
    "    expected_wins_list.append(expected_wins)\n",
    "SOS = pd.DataFrame(zip(team_data['team'], expected_wins_list), columns=['team', 'avg_expected_wins'])\n",
    "SOS = SOS.sort_values('avg_expected_wins').reset_index(drop = True)\n",
    "SOS['SOS'] = SOS.index + 1\n",
    "\n",
    "completed_games = year_long_schedule[year_long_schedule['home_points'].notna()]\n",
    "current_xWins_list = []\n",
    "good_xWins_list = []\n",
    "elite_xWins_list = []\n",
    "for team in team_data['team']:\n",
    "    team_completed_games = completed_games[(completed_games['home_team'] == team) | (completed_games['away_team'] == team)]\n",
    "    games_played = records[records['team'] == team]['games_played'].values[0]\n",
    "    wins = records[records['team'] == team]['wins'].values[0]\n",
    "    team_completed_games['avg_win_prob'] = np.where(team_completed_games['home_team'] == team,\n",
    "                                                    ESCAPE_Win_Prob(average_pr, team_completed_games['away_pr']),\n",
    "                                                    100 - ESCAPE_Win_Prob(team_completed_games['home_pr'], average_pr))\n",
    "    team_completed_games['good_win_prob'] = np.where(team_completed_games['home_team'] == team,\n",
    "                                                    ESCAPE_Win_Prob(good_team_pr, team_completed_games['away_pr']),\n",
    "                                                    100 - ESCAPE_Win_Prob(team_completed_games['home_pr'], good_team_pr))\n",
    "    team_completed_games['elite_win_prob']  = np.where(team_completed_games['home_team'] == team,\n",
    "                                                    ESCAPE_Win_Prob(elite_team_pr, team_completed_games['away_pr']),\n",
    "                                                    100 - ESCAPE_Win_Prob(team_completed_games['home_pr'], elite_team_pr))\n",
    "\n",
    "    # team_completed_games['avg_win_prob'] = np.where(team_completed_games['home_team'] == team, \n",
    "    #                             round((10**((average_elo-team_completed_games['away_elo']) / 400)) / ((10**((average_elo-team_completed_games['away_elo']) / 400)) + 1)*100, 2), \n",
    "    #                             100 - round((10**((team_completed_games['home_elo'] - average_elo) / 400)) / ((10**((team_completed_games['home_elo']- average_elo) / 400)) + 1)*100, 2))\n",
    "    current_xWins = round(sum(team_completed_games['avg_win_prob']) / 100, 2)\n",
    "    good_xWins = round(sum(team_completed_games['good_win_prob']) / 100, 2)\n",
    "    elite_xWins = round(sum(team_completed_games['elite_win_prob']) / 100, 2)\n",
    "    if games_played != len(team_completed_games):\n",
    "        current_xWins += 1\n",
    "        good_xWins += 1\n",
    "        elite_xWins += 1\n",
    "    relative_current_xWins = round(wins - current_xWins, 2)\n",
    "    relative_good_xWins = round(wins - good_xWins, 2)\n",
    "    relative_elite_xWins = round(wins - elite_xWins, 2)\n",
    "    current_xWins_list.append(relative_current_xWins)\n",
    "    good_xWins_list.append(relative_good_xWins)\n",
    "    elite_xWins_list.append(relative_elite_xWins)\n",
    "SOR = pd.DataFrame(zip(team_data['team'], current_xWins_list, good_xWins_list, elite_xWins_list), columns=['team','wins_above_average','wins_above_good','wins_above_elite'])\n",
    "SOR = SOR.sort_values('wins_above_good', ascending=False).reset_index(drop=True)\n",
    "SOR['SOR'] = SOR.index + 1\n",
    "\n",
    "num_12_pr = team_data['power_rating'][11]\n",
    "\n",
    "# Ensure MOV is calculated in the completed_games DataFrame\n",
    "completed_games = year_long_schedule[year_long_schedule['home_points'].notna()]\n",
    "completed_games['margin_of_victory'] = completed_games['home_points'] - completed_games['away_points']\n",
    "\n",
    "# Function to scale MOV\n",
    "def f(mov):\n",
    "    return np.clip(np.log(abs(mov) + 1) * np.sign(mov), -10, 10)\n",
    "\n",
    "current_xWins_list = []\n",
    "\n",
    "for team in team_data['team']:\n",
    "    # Filter completed games for the current team\n",
    "    team_completed_games = completed_games[(completed_games['home_team'] == team) | (completed_games['away_team'] == team)]\n",
    "    \n",
    "    # Get the current team's record\n",
    "    games_played = records[records['team'] == team]['games_played'].values[0]\n",
    "    wins = records[records['team'] == team]['wins'].values[0]\n",
    "    \n",
    "    # Adjust win probability with MOV influence\n",
    "    team_completed_games['avg_win_prob'] = np.where(\n",
    "        team_completed_games['home_team'] == team,\n",
    "        ESCAPE_Win_Prob(num_12_pr, team_completed_games['away_pr']) + f(team_completed_games['margin_of_victory']),\n",
    "        100 - ESCAPE_Win_Prob(team_completed_games['home_pr'], num_12_pr) - f(-team_completed_games['margin_of_victory'])\n",
    "    )\n",
    "    \n",
    "    # Calculate expected wins (xWins)\n",
    "    current_xWins = round(sum(team_completed_games['avg_win_prob']) / 100, 3)\n",
    "    \n",
    "    # Adjust for incomplete games\n",
    "    if games_played != len(team_completed_games):\n",
    "        current_xWins += 1\n",
    "    \n",
    "    # Calculate relative xWins (wins vs. expected wins)\n",
    "    relative_current_xWins = round(wins - current_xWins, 3)\n",
    "    current_xWins_list.append(relative_current_xWins)\n",
    "\n",
    "# Create the \"most deserving\" DataFrame\n",
    "most_deserving = pd.DataFrame(zip(team_data['team'], current_xWins_list), columns=['team', 'most_deserving_wins'])\n",
    "most_deserving = most_deserving.sort_values('most_deserving_wins', ascending=False).reset_index(drop=True)\n",
    "most_deserving['most_deserving'] = most_deserving.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data = pd.merge(team_data, SOS, how='left', on='team')\n",
    "team_data = pd.merge(team_data, SOR, how='left', on='team')\n",
    "team_data = pd.merge(team_data, most_deserving, how='left', on='team')\n",
    "\n",
    "import os\n",
    "folder_path = f\"./ESCAPE Ratings/Data/y{current_year}\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "folder_path = f\"./ESCAPE Ratings/Ratings/y{current_year}\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "folder_path = f\"./ESCAPE Ratings/Spreads/y{current_year}\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "team_data.to_csv(f\"./ESCAPE Ratings/Data/y{current_year}/team_data_week{current_week}.csv\")\n",
    "team_power_rankings.to_csv(f'./ESCAPE Ratings/Ratings/y{current_year}/ESCAPE_week{current_week}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempting Pre-Season Power Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import cfbd\n",
    "current_year = 2024\n",
    "configuration = cfbd.Configuration()\n",
    "configuration.api_key['Authorization'] = '7vGedNNOrnl0NGcSvt92FcVahY602p7IroVBlCA1Tt+WI/dCwtT7Gj5VzmaHrrxS'\n",
    "configuration.api_key_prefix['Authorization'] = 'Bearer'\n",
    "api_client = cfbd.ApiClient(configuration)\n",
    "advanced_instance = cfbd.StatsApi(api_client)\n",
    "games_api = cfbd.GamesApi(api_client)\n",
    "betting_api = cfbd.BettingApi(api_client)\n",
    "ratings_api = cfbd.RatingsApi(api_client)\n",
    "teams_api = cfbd.TeamsApi(api_client)\n",
    "metrics_api = cfbd.MetricsApi(api_client)\n",
    "players_api = cfbd.PlayersApi(api_client)\n",
    "recruiting_api = cfbd.RecruitingApi(api_client)\n",
    "\n",
    "recruiting_info_list = []\n",
    "response = recruiting_api.get_recruiting_teams(year=current_year)\n",
    "recruiting_info_list = [*recruiting_info_list, *response]\n",
    "recruiting_info_dict = [dict(\n",
    "    team = r.team,\n",
    "    year = r.year,\n",
    "    points = r.points\n",
    ") for r in recruiting_info_list]\n",
    "recruiting = pd.DataFrame(recruiting_info_dict)\n",
    "\n",
    "production_list = []\n",
    "response = players_api.get_returning_production(year = current_year)\n",
    "production_list = [*production_list, *response]\n",
    "production_dict = [dict(\n",
    "    season=r.season,\n",
    "    team=r.team,\n",
    "    returning_ppa=r.percent_ppa,\n",
    "    returning_usage=r.usage\n",
    ") for r in production_list]\n",
    "returning_production = pd.DataFrame(production_dict)\n",
    "\n",
    "elo_ratings_list = [*ratings_api.get_elo_ratings(year=current_year)]\n",
    "elo_ratings_dict = [dict(\n",
    "    team = e.team,\n",
    "    elo = e.elo\n",
    ") for e in elo_ratings_list]\n",
    "elo_ratings = pd.DataFrame(elo_ratings_dict)\n",
    "\n",
    "end_ratings = pd.read_csv(\"./ESCAPE Ratings/Ratings/y2024/ESCAPE_week17.csv\").drop(columns=['Unnamed: 0'])\n",
    "top_rated_team = end_ratings.iloc[0,1]\n",
    "end_ratings[\"power_rating\"] = (100 - top_rated_team) + end_ratings[\"power_rating\"]\n",
    "\n",
    "scaler1000 = MinMaxScaler(feature_range=(10,1000))\n",
    "scaler50 = MinMaxScaler(feature_range=(0,50))\n",
    "recruiting['recruiting_scaled'] = scaler1000.fit_transform(recruiting[['points']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(end_ratings, recruiting[['team', 'recruiting_scaled']], how='left', on='team')\n",
    "data1 = pd.merge(data, returning_production[['team', 'returning_ppa']], how='left', on='team')\n",
    "team_data = pd.merge(data1, elo_ratings[['team', 'elo']], how='left', on='team')\n",
    "team_data['returning_ppa'].fillna(team_data['returning_ppa'].mean(), inplace = True)\n",
    "team_data['power_rating'].fillna(team_data['power_rating'].mean() - 2*team_data['power_rating'].std(), inplace=True)\n",
    "\n",
    "### these values can be applied as inputs to an optimization\n",
    "team_data['metric'] = 1 * (team_data['power_rating'] * team_data['returning_ppa']) + 0.5*team_data['recruiting_scaled'] + 0.1*team_data['elo']\n",
    "# team_data['metric'] = 0.5*team_data['recruiting_scaled'] + 0.1*team_data['elo']\n",
    "\n",
    "team_data['scaled_metric'] = scaler50.fit_transform(team_data[['metric']])\n",
    "team_data['power_rating'] = team_data['scaled_metric'] - team_data['scaled_metric'].mean()\n",
    "team_data['week'] = 0\n",
    "team_data['year'] = 2025\n",
    "team_data.sort_values('power_rating',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Ranking Visuals - run \"Updated Power Rankings\" first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prep work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from matplotlib.lines import Line2D\n",
    "import cfbd\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from matplotlib import gridspec\n",
    "import numpy as np\n",
    "import math\n",
    "np.random.seed(42)\n",
    "configuration = cfbd.Configuration()\n",
    "configuration.api_key['Authorization'] = '7vGedNNOrnl0NGcSvt92FcVahY602p7IroVBlCA1Tt+WI/dCwtT7Gj5VzmaHrrxS'\n",
    "configuration.api_key_prefix['Authorization'] = 'Bearer'\n",
    "api_client = cfbd.ApiClient(configuration)\n",
    "advanced_instance = cfbd.StatsApi(api_client)\n",
    "games_api = cfbd.GamesApi(api_client)\n",
    "betting_api = cfbd.BettingApi(api_client)\n",
    "ratings_api = cfbd.RatingsApi(api_client)\n",
    "teams_api = cfbd.TeamsApi(api_client)\n",
    "metrics_api = cfbd.MetricsApi(api_client)\n",
    "players_api = cfbd.PlayersApi(api_client)\n",
    "recruiting_api = cfbd.RecruitingApi(api_client)\n",
    "response = teams_api.get_teams()\n",
    "\n",
    "week_start_list = [*games_api.get_calendar(year = 2024)]\n",
    "calendar_dict = [dict(\n",
    "    first_game_start = c.first_game_start,\n",
    "    last_game_start = c.last_game_start,\n",
    "    season = c.season,\n",
    "    season_type = c.season_type,\n",
    "    week = c.week\n",
    ") for c in week_start_list]\n",
    "calendar = pd.DataFrame(calendar_dict)\n",
    "calendar['first_game_start'] = pd.to_datetime(calendar['first_game_start'])\n",
    "calendar['last_game_start'] = pd.to_datetime(calendar['last_game_start'])\n",
    "current_year = int(calendar.loc[0, 'season'])\n",
    "\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "current_time = datetime.now(pytz.UTC)\n",
    "first_game_start = calendar['first_game_start'].iloc[0]\n",
    "last_game_start = calendar['last_game_start'].iloc[-1]\n",
    "current_week = None\n",
    "if current_time < first_game_start:\n",
    "    current_week = 1\n",
    "elif current_time > last_game_start:\n",
    "    current_week = calendar.iloc[-2, -1] + 1\n",
    "else:\n",
    "    condition_1 = (calendar['first_game_start'] <= current_time) & (calendar['last_game_start'] >= current_time)\n",
    "    condition_2 = (calendar['last_game_start'].shift(1) < current_time) & (calendar['first_game_start'] > current_time)\n",
    "\n",
    "    # Combine conditions\n",
    "    result = calendar[condition_1 | condition_2].reset_index(drop=True)\n",
    "    if result['season_type'][0] == 'regular':\n",
    "        current_week = result['week'][0]\n",
    "        postseason = False\n",
    "    else:\n",
    "        current_week = calendar.iloc[-2, -1] + 1\n",
    "        postseason = True\n",
    "\n",
    "print(current_week, current_year)\n",
    "\n",
    "logos_info_list = []\n",
    "logos_info_list = [*logos_info_list, *response]\n",
    "logos_info_dict = [dict(\n",
    "    team = l.school,\n",
    "    color = l.color,\n",
    "    alt_color = l.alt_color,\n",
    "    logo = l.logos\n",
    ") for l in logos_info_list]\n",
    "logos = pd.DataFrame(logos_info_dict)\n",
    "logos = logos.dropna(subset=['logo', 'color'])\n",
    "all_data = pd.read_csv(f\"./ESCAPE Ratings/Data/y{current_year}/team_data_week{current_week}.csv\")\n",
    "\n",
    "def best_and_worst(all_data, logos, metric, title, subtitle):\n",
    "    if metric == 'average_metric_rank':\n",
    "        top_25_best = all_data.sort_values(metric, ascending=True)[:25].reset_index(drop=True)\n",
    "        top_25_worst = all_data.sort_values(metric, ascending=False)[:25].reset_index(drop=True)\n",
    "        top_25_worst = top_25_worst.sort_values(metric, ascending=True)[:25].reset_index(drop=True)\n",
    "    else:\n",
    "        top_25_best = all_data.sort_values(metric, ascending=False)[:25].reset_index(drop=True)\n",
    "        top_25_worst = all_data.sort_values(metric, ascending=True)[:25].reset_index(drop=True)\n",
    "        top_25_worst = top_25_worst.sort_values(metric, ascending=False)[:25].reset_index(drop=True)\n",
    "\n",
    "    # Create a figure with 5 rows and 10 columns\n",
    "    fig, axs = plt.subplots(5, 10, figsize=(20, 10), dpi=125)\n",
    "\n",
    "    # Adjust space between subplots\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "    fig.patch.set_facecolor('#5fa391')\n",
    "\n",
    "    # Title and description\n",
    "    plt.suptitle(title, fontsize=20, fontweight='bold', color='black')\n",
    "    plt.text(0.505, 0.935, subtitle, ha='center', fontsize=14, color='black', transform=fig.transFigure)\n",
    "\n",
    "    # Fill the grid alternating Best and Worst Defenses\n",
    "    for i in range(5):  # There are 5 rows\n",
    "        # Best defenses: Columns 0-4 for each row (Best in every odd index)\n",
    "        for j in range(5):  \n",
    "            ax = axs[i, j]\n",
    "            team = top_25_best.loc[i*5 + j, 'team']\n",
    "            logo_url = logos[logos['team'] == team]['logo'].values[0][0]\n",
    "            response = requests.get(logo_url)\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            ax.imshow(img)\n",
    "            ax.set_facecolor('#f0f0f0')\n",
    "            # ax.set_title(f\"#{i*5 + j + 1} {team} \\n{round(top_25_best.loc[i*5 + j, metric], 1)}\", fontsize=8, fontweight='bold')\n",
    "            ax.set_title(f\"#{i*5 + j + 1} \\n{round(top_25_best.loc[i*5 + j, metric], 1)}\", fontsize=14, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "\n",
    "        # Worst defenses: Columns 5-9 for each row (Worst in every even index after 5)\n",
    "        for j in range(5, 10):  \n",
    "            ax = axs[i, j]\n",
    "            team = top_25_worst.loc[i*5 + (j-5), 'team']\n",
    "            logo_url = logos[logos['team'] == team]['logo'].values[0][0]\n",
    "            response = requests.get(logo_url)\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            ax.imshow(img)\n",
    "            ax.set_facecolor('#f0f0f0')\n",
    "            \n",
    "            # Start counting for Worst from 134 and decrement\n",
    "            worst_rank = 110 + (i*5 + (j-5)) \n",
    "            ax.set_title(f\"#{worst_rank} \\n{round(top_25_worst.loc[i*5 + (j-5), metric], 1)}\", fontsize=14, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "\n",
    "    fig.add_artist(Line2D([0.512, 0.512], [0.12, 0.92], color='black', lw=5))\n",
    "    fig.text(0.13, 0.96, \"Best\", ha='left', va='center', fontsize=20, fontweight='bold', color='black')\n",
    "    fig.text(0.89, 0.96, \"Worst\", ha='right', va='center', fontsize=20, fontweight='bold', color='black')\n",
    "\n",
    "    # Show the final figure\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot the bar chart for a given dataset\n",
    "def plot_bar_charts(ax, data, logos, metric, title, top_or_bottom):\n",
    "    if top_or_bottom == 'Top':\n",
    "        top_or_bottom = True\n",
    "    else:\n",
    "        top_or_bottom = False\n",
    "    # Data\n",
    "    teams = data['team']\n",
    "    scores = data[metric]\n",
    "    \n",
    "    team_colors = {row['team']: row['color'] for _, row in logos.iterrows()}\n",
    "    colors = [team_colors[team] for team in teams]\n",
    "\n",
    "    bar_spacing = 5  # This factor increases the spacing between the bars\n",
    "    y_pos = range(len(teams))\n",
    "    y_pos = [y * bar_spacing for y in y_pos]\n",
    "\n",
    "    # Plot bars\n",
    "    bars = ax.barh(y_pos, scores, color=colors, align='center', height=4)\n",
    "\n",
    "    for i, (y, team, bar) in enumerate(zip(y_pos, teams, bars)):\n",
    "        logo_url = logos[logos['team'] == team]['logo'].values[0][0]\n",
    "        response = requests.get(logo_url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "\n",
    "        xy = [bar.get_width() + 3, y]\n",
    "        img = OffsetImage(img, zoom=0.05)\n",
    "        img.image.axes = ax\n",
    "        ab = AnnotationBbox(img, xy, xycoords='data', frameon=False, pad=0)\n",
    "        ax.add_artist(ab)\n",
    "\n",
    "    if top_or_bottom:\n",
    "        # Add labels inside bars\n",
    "        i = 1\n",
    "        for bar, score in zip(bars, scores):\n",
    "            ax.text(bar.get_width() - 3, bar.get_y() + bar.get_height() / 2, \n",
    "                    f\"#{i} - {score:.1f}\", va='center', ha='right', fontsize=8, color='white', fontweight='bold')\n",
    "            i = i + 1\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.tick_params(axis='y', length=0)\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_yticks([])\n",
    "        # Tidy up the axis\n",
    "        ax.invert_yaxis() \n",
    "        ax.set_xlim([0, 105])  # Adjust as per your score range\n",
    "        ax.set_xticks([])  # Remove x-ticks\n",
    "        ax.set_xticklabels([])  # Remove x-labels\n",
    "    else:\n",
    "        i = 110\n",
    "        for bar, score in zip(bars, scores):\n",
    "            ax.text(bar.get_width() - bar.get_width() - 1, bar.get_y() + bar.get_height() / 2, \n",
    "                    f\"#{i} - {score:.1f}\", va='center', ha='right', fontsize=8, color='white', fontweight='bold')\n",
    "            i = i + 1\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.tick_params(axis='y', length=0)\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_yticks([])\n",
    "        # Tidy up the axis\n",
    "        ax.invert_yaxis() \n",
    "        ax.set_xlim([0, 100])  # Adjust as per your score range\n",
    "        ax.set_xticks([])  # Remove x-ticks\n",
    "        ax.set_xticklabels([])  # Remove x-labels\n",
    "\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold', color='black')\n",
    "\n",
    "    # Remove axes spines\n",
    "    for spine in ['top', 'left', 'bottom', 'right']:\n",
    "        ax.spines[spine].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "top_25 = all_data[:25]\n",
    "last_week_data = pd.read_csv(f\"./ESCAPE Ratings/ESCAPE_week{current_week-1}_{current_year}.csv\")\n",
    "\n",
    "fig, axs = plt.subplots(5, 5, figsize=(7, 7),dpi=125)\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "fig.patch.set_facecolor('#5fa391')\n",
    "plt.suptitle(f\"Week {current_week} ESCAPE Ratings\", fontsize=20, fontweight='bold', color='black')\n",
    "fig.text(0.5, 0.93, \"Power Rating (Position Change)\", fontsize=8, ha='center', color='black')\n",
    "\n",
    "for i, ax in enumerate(axs.ravel()):\n",
    "    team = top_25.loc[i, 'team']\n",
    "    logo_url = logos[logos['team'] == team]['logo'].values[0][0]\n",
    "    response = requests.get(logo_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    ax.imshow(img)\n",
    "    ax.set_facecolor('#f0f0f0')\n",
    "    power_rating = top_25.loc[i, 'power_rating']\n",
    "    last_week_index = last_week_data[last_week_data['team'] == team].index[0]\n",
    "    #  ({round(power_rating-last_week_pr, 1)}) <- shows change from last week. Currently irrelevant\n",
    "    ax.set_title(f\"#{i+1} {team} \\n{round(power_rating,1)} ({round(last_week_index - i, 1)})\", fontsize=8)\n",
    "    ax.axis('off')\n",
    "plt.savefig(f\"./ESCAPE Ratings/Visuals/Top 25/top25_week{current_week}\", bbox_inches='tight',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### group of 5 Top 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "group_of_5 = ['Conference USA', 'Mid-American', 'Sun Belt', 'American Athletic', 'Mountain West']\n",
    "filtered_data = all_data[all_data['conference'].isin(group_of_5)]\n",
    "top_25 = filtered_data.head(25).reset_index(drop=True)\n",
    "\n",
    "fig, axs = plt.subplots(5, 5, figsize=(7, 7),dpi=125)\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "fig.patch.set_facecolor('#5fa391')\n",
    "plt.suptitle(f\"Week {current_week} GO5 ESCAPE Ratings\", fontsize=20, fontweight='bold', color='black')\n",
    "\n",
    "for i, ax in enumerate(axs.ravel()):\n",
    "    team = top_25.loc[i, 'team']\n",
    "    logo_url = logos[logos['team'] == team]['logo'].values[0][0]\n",
    "    response = requests.get(logo_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    ax.imshow(img)\n",
    "    ax.set_facecolor('#f0f0f0')\n",
    "    ax.set_title(f\"#{i+1} {team} \\n{round(top_25.loc[i, 'power_rating'],1)}\", fontsize=8, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "plt.savefig(f\"./ESCAPE Ratings/Visuals/GO5 Top 25/go5_top25_week{current_week}\", bbox_inches='tight',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all teams graphed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "# Define the number of rows and columns\n",
    "n_teams = len(all_data)\n",
    "n_columns = (n_teams // 20) + (1 if n_teams % 20 != 0 else 0)\n",
    "\n",
    "# Plot configuration\n",
    "fig, axes = plt.subplots(nrows=20, ncols=n_columns, figsize=(20, 10),dpi=125)\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "fig.patch.set_facecolor('#5fa391')\n",
    "plt.suptitle(f'Week {current_week} ESCAPE Ratings. 0.0 is the average FBS team.', fontsize=14, y=0.92, x=0.55)\n",
    "\n",
    "min_rating = all_data['power_rating'].min()\n",
    "max_rating = all_data['power_rating'].max()\n",
    "rating_range = max_rating-min_rating\n",
    "\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list('dark_gradient_orange', ['#660000', '#8B0000', '#CC5500', '#2C5E00', '#1D4D00'], N=rating_range)\n",
    "\n",
    "def get_color(value, vmin=min_rating, vmax=max_rating):\n",
    "    norm_value = (value - vmin) / (vmax - vmin)  # Normalize the value between 0 and 1\n",
    "    return cmap(norm_value)  # Get the color from the colormap\n",
    "\n",
    "# Define a colormap from red to green\n",
    "cmap = plt.get_cmap('RdYlGn')\n",
    "\n",
    "def get_color(power_rating):\n",
    "    \"\"\"Return a color based on the power rating normalized to a range between 0 and 1.\"\"\"\n",
    "    norm_rating = (power_rating - min_rating) / (max_rating - min_rating)\n",
    "    return cmap(norm_rating)\n",
    "\n",
    "# Iterate through the data to plot\n",
    "for idx, team in all_data.iterrows():\n",
    "    power_rating = team['power_rating']\n",
    "    team_name = team['team']\n",
    "    logo_url = logos[logos['team'] == team_name]['logo'].values[0][0]\n",
    "    row = idx % 20\n",
    "    col = idx // 20\n",
    "    \n",
    "    ax = axes[row, col]\n",
    "    ax.axis('off')  # Turn off the axis\n",
    "    \n",
    "    # Fetch the logo image from URL and display it\n",
    "    response = requests.get(logo_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    ax.imshow(img)\n",
    "\n",
    "    # Get the color for the current power rating\n",
    "    color = get_color(power_rating)\n",
    "\n",
    "    text_ax = ax.inset_axes([0.2, 0.3, 0.75, 0.5])  # Move the text box to the right of the logo\n",
    "    text_ax.axis('off')  # Turn off the text axis\n",
    "\n",
    "    # Get the color for the current power rating\n",
    "    color = get_color(power_rating)\n",
    "\n",
    "    # Display the rank\n",
    "    text_ax.text(-1.2, 0.5, f\"#{idx + 1}\", ha='center', va='center', fontsize=8, color='black', transform=text_ax.transAxes, fontweight='bold')\n",
    "\n",
    "    # Display the team name to the right of the logo\n",
    "    text_ax.text(1.5, 0.5, f\"{team_name}\", ha='left', va='center', fontsize=6, color='black', transform=text_ax.transAxes)\n",
    "\n",
    "    # Display the power rating in a separate line with its color\n",
    "    text_ax.text(6.5, 0.5, f\"{power_rating:.2f}\", ha='left', va='center', fontsize=8, color='black', transform=text_ax.transAxes, fontweight='bold')\n",
    "\n",
    "    text_ax.text(9, 0.9, \"|\", ha='left', va='center', fontsize=14, color='black', transform=text_ax.transAxes, fontweight='bold')\n",
    "    text_ax.text(9, -0.6, \"|\", ha='left', va='center', fontsize=14, color='black', transform=text_ax.transAxes, fontweight='bold')\n",
    "    \n",
    "\n",
    "if n_teams % 20 != 0:\n",
    "    for empty_row in range(n_teams % 20, 20):\n",
    "        axes[empty_row, n_columns - 1].axis('off')\n",
    "plt.savefig(f'./ESCAPE Ratings/Visuals/Visual PR/team_pr_week{current_week}', bbox_inches='tight', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fill in missing colors with black\n",
    "all_data['color'] = all_data['color'].fillna('#000000')\n",
    "\n",
    "# Calculate the average power rating\n",
    "average_power_rating = all_data['power_rating'].mean()\n",
    "\n",
    "plt.figure(figsize=(20, 10),dpi=125)\n",
    "plt.bar(all_data['team'], all_data['power_rating'], color=all_data['color'])\n",
    "plt.title('Team Power Ratings', fontsize=16, fontweight='bold', color='black')\n",
    "plt.xlabel('Team', fontsize=12, color='black')\n",
    "plt.ylabel('Power Rating', fontsize=12, color='black')\n",
    "plt.gca().set_facecolor('#5fa391')\n",
    "plt.gcf().set_facecolor('#5fa391')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=8, color='black')\n",
    "plt.ylim(-25, 35)\n",
    "\n",
    "# Add a horizontal line for the average power rating\n",
    "plt.axhline(y=0, color='white', linestyle='--', linewidth=2, alpha=1)\n",
    "\n",
    "# Add vertical lines every 25 teams\n",
    "for i in range(25, len(all_data), 25):\n",
    "    plt.axvline(x=i - 0.5, color='black', linestyle='--', linewidth=0.8, alpha=1)\n",
    "plt.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'./ESCAPE Ratings/Visuals/Visual PR/bar_chart_pr_week{current_week}', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### individual conference ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# Set the current week\n",
    "current_week = 6\n",
    "conference_figures = []\n",
    "# Loop through each unique conference and create a plot for all teams in that conference\n",
    "unique_conferences = all_data['conference'].unique()\n",
    "\n",
    "for conference in unique_conferences:\n",
    "    # Filter all teams in the current conference\n",
    "    conference_teams = all_data[all_data['conference'] == conference].reset_index(drop=True)\n",
    "    num_teams = len(conference_teams)\n",
    "    \n",
    "    # Set up the figure with a fixed number of spaces (5 columns and 5 rows)\n",
    "    cols = 5\n",
    "    rows = 4  # Fixed number of rows to accommodate 25 spaces\n",
    "    \n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(5, 5),dpi=125)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    fig.patch.set_facecolor('#5fa391')  # Background color for the entire figure\n",
    "    plt.suptitle(f\"Week {current_week} ESCAPE Ratings - {conference}\", fontsize=10, fontweight='bold', color='black')\n",
    "\n",
    "    # Flatten the axes array\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    # Plot each team's logo\n",
    "    plot_index = 0  # Index for keeping track of where to plot\n",
    "    for i in range(num_teams):\n",
    "        \n",
    "        ax = axs[plot_index]  # Get the next available axis for plotting\n",
    "        \n",
    "        # if conference_teams.loc[i, 'team'] == \"Charlotte\":\n",
    "        #     # Set the background color from team_data['color']\n",
    "        #     ax.set_facecolor(conference_teams.loc[i, 'color'] if pd.notna(conference_teams.loc[i, 'color']) else '#f0f0f0')\n",
    "            \n",
    "        #     # Set title as the team name with rank\n",
    "        #     ax.set_title(f\"#{plot_index + 1} {conference_teams.loc[i, 'team']}\", fontsize=5, fontweight='bold')\n",
    "        #     ax.axis('off')\n",
    "            \n",
    "        #     plot_index += 1  # Increment the plot index\n",
    "        #     continue  # Skip \"Charlotte\"\n",
    "\n",
    "        # Fetch team logo\n",
    "        if conference_teams.loc[i, 'logo'] is not None:\n",
    "            logo_url = logos[logos['team'] == conference_teams.loc[i, 'team']]['logo'].values[0][0]\n",
    "            response = requests.get(logo_url)\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            ax.imshow(img)\n",
    "        else:\n",
    "            # Set the background color from team_data['color']\n",
    "            ax.set_facecolor(conference_teams.loc[i, 'color'] if pd.notna(conference_teams.loc[i, 'color']) else '#f0f0f0')\n",
    "        \n",
    "            # Set title as the team name with rank\n",
    "            ax.set_title(f\"#{plot_index + 1} {conference_teams.loc[i, 'team']}\", fontsize=5, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "        \n",
    "            plot_index += 1  # Increment the plot index\n",
    "            ax.axis('off')  # Turn off axis if no logo available\n",
    "            continue\n",
    "        \n",
    "        # Set the background color from team_data['color']\n",
    "        ax.set_facecolor(conference_teams.loc[i, 'color'] if pd.notna(conference_teams.loc[i, 'color']) else '#f0f0f0')\n",
    "        \n",
    "        # Set title as the team name with rank\n",
    "        ax.set_title(f\"#{plot_index + 1} {conference_teams.loc[i, 'team']}\", fontsize=5, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        plot_index += 1  # Increment the plot index\n",
    "\n",
    "        # If we reach 25 spaces, we stop plotting\n",
    "        if plot_index >= len(axs):\n",
    "            break\n",
    "    \n",
    "    # Hide any remaining subplots that weren't used\n",
    "    for j in range(plot_index, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "    \n",
    "    # Save the figure to the conference_figures list\n",
    "    conference_figures.append(fig)\n",
    "\n",
    "# Optional: Display all the figures at once (if needed)\n",
    "for fig in conference_figures:\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conference average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conference_stats = all_data.groupby('conference')['power_rating'].agg(['mean', 'min', 'max']).reset_index()\n",
    "conference_stats = conference_stats.sort_values(by='mean', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 4), facecolor='#5fa391',dpi=125)\n",
    "bars = plt.bar(conference_stats['conference'], conference_stats['mean'], \n",
    "                color='#A74C54', \n",
    "                yerr=[conference_stats['mean'] - conference_stats['min'], \n",
    "                      conference_stats['max'] - conference_stats['mean']], \n",
    "                capsize=5)\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('#5fa391')\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_color('#5fa391')  # Set the border color\n",
    "    spine.set_linewidth(2)  # Adjust the border thickness if needed\n",
    "ax.xaxis.set_tick_params(color='black')  # X-axis ticks\n",
    "ax.yaxis.set_tick_params(color='black')  # Y-axis ticks\n",
    "ax.spines['bottom'].set_color('black')  # Bottom spine\n",
    "ax.spines['left'].set_color('black')  # Left spine\n",
    "ax.spines['top'].set_color('none')  # Top spine\n",
    "ax.spines['right'].set_color('none')  # Right spine\n",
    "\n",
    "plt.axhline(y=0, color = 'black', linestyle='--')\n",
    "plt.xlabel('Conference', fontsize=12, color='black')\n",
    "plt.ylabel('Average Power Rating', fontsize=12, color='black')\n",
    "plt.title('Average Power Rating by Conference', fontsize=14, fontweight='bold', color='black')\n",
    "plt.xticks(rotation=45, ha='right', color='black', fontsize=8)\n",
    "plt.yticks(color='black', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./ESCAPE Ratings/Visuals/Average Conference Rating/average_power_conference_week{current_week}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all conferences on one viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "# Loop through each unique conference and create a plot for all teams in that conference\n",
    "unique_conferences = all_data['conference'].unique()\n",
    "conference_figures = []  # List to store figures\n",
    "\n",
    "for conference in unique_conferences:\n",
    "    # Filter all teams in the current conference\n",
    "    conference_teams = all_data[all_data['conference'] == conference].reset_index(drop=True)\n",
    "    num_teams = len(conference_teams)\n",
    "    \n",
    "    # Set up the figure with a larger size and fewer rows/columns\n",
    "    cols = 4  # Adjusted number of columns\n",
    "    rows = math.ceil(num_teams / cols)  # Calculate rows based on number of teams\n",
    "\n",
    "    # Increase figure size\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(12, 10),dpi=125)  # Adjusted figure size\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4)  # Adjusted spacing\n",
    "    fig.patch.set_facecolor('#5fa391')  # Background color for the entire figure\n",
    "    plt.suptitle(f\"Week {current_week} ESCAPE Ratings - {conference}\", fontsize=25, fontweight='bold', color='black')\n",
    "\n",
    "    # Flatten the axes array\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    # Plot each team's logo\n",
    "    plot_index = 0  # Index for keeping track of where to plot\n",
    "    for i in range(num_teams):\n",
    "        \n",
    "        ax = axs[plot_index]  # Get the next available axis for plotting\n",
    "        \n",
    "        # if conference_teams.loc[i, 'team'] == \"Charlotte\":\n",
    "        #     # Set the background color from team_data['color']\n",
    "        #     ax.set_facecolor(conference_teams.loc[i, 'color'] if pd.notna(conference_teams.loc[i, 'color']) else '#f0f0f0')\n",
    "            \n",
    "        #     # Set title as the team name with rank\n",
    "        #     ax.set_title(f\"#{plot_index + 1} {conference_teams.loc[i, 'team']}\", fontsize=16, fontweight='bold')\n",
    "        #     ax.axis('off')\n",
    "            \n",
    "        #     plot_index += 1  # Increment the plot index\n",
    "        #     continue  # Skip \"Charlotte\"\n",
    "\n",
    "        # Fetch team logo\n",
    "        if conference_teams.loc[i, 'logo'] is not None:\n",
    "            logo_url = logos[logos['team'] == conference_teams.loc[i, 'team']]['logo'].values[0][0]\n",
    "            response = requests.get(logo_url)\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            ax.imshow(img)\n",
    "        else:\n",
    "            # Set the background color from team_data['color']\n",
    "            ax.set_facecolor(conference_teams.loc[i, 'color'] if pd.notna(conference_teams.loc[i, 'color']) else '#f0f0f0')\n",
    "        \n",
    "            # Set title as the team name with rank\n",
    "            ax.set_title(f\"#{plot_index + 1} {conference_teams.loc[i, 'team']}\", fontsize=16, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "        \n",
    "            plot_index += 1  # Increment the plot index\n",
    "            ax.axis('off')  # Turn off axis if no logo available\n",
    "            continue\n",
    "        \n",
    "        # Set the background color from team_data['color']\n",
    "        ax.set_facecolor(conference_teams.loc[i, 'color'] if pd.notna(conference_teams.loc[i, 'color']) else '#f0f0f0')\n",
    "        \n",
    "        # Set title as the team name with rank\n",
    "        ax.set_title(f\"#{plot_index + 1} {conference_teams.loc[i, 'team']}\", fontsize=16, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        plot_index += 1  # Increment the plot index\n",
    "\n",
    "        # If we reach the maximum number of plots, we stop plotting\n",
    "        if plot_index >= len(axs):\n",
    "            break\n",
    "    \n",
    "    # Hide any remaining subplots that weren't used\n",
    "    for j in range(plot_index, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "    \n",
    "    # Save the plot for this conference to the list\n",
    "    conference_figures.append(fig)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Create a list to hold the paths of saved images\n",
    "image_paths = []\n",
    "\n",
    "# Save each conference figure to a temporary image\n",
    "for idx, conf_fig in enumerate(conference_figures):\n",
    "    temp_image_path = f\"temp_conference_fig_{idx}.png\"\n",
    "    conf_fig.savefig(temp_image_path, bbox_inches='tight', dpi=300)\n",
    "    image_paths.append(temp_image_path)\n",
    "\n",
    "# Determine the number of figures\n",
    "num_figures = len(image_paths)\n",
    "\n",
    "# Define the number of rows and columns for the new display figure\n",
    "cols = 3  # Number of columns you want\n",
    "rows = (num_figures + cols - 1) // cols  # Calculate number of rows needed\n",
    "\n",
    "# Create a new figure for displaying all conference figures\n",
    "display_fig, display_axs = plt.subplots(rows, cols, figsize=(10, 3 * rows))\n",
    "display_fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "display_fig.patch.set_facecolor('#5fa391') \n",
    "\n",
    "# Flatten the axes array for easier indexing\n",
    "display_axs = display_axs.ravel()\n",
    "\n",
    "# Loop through each image path and display it in the display axes\n",
    "for i in range(num_figures):\n",
    "    ax = display_axs[i]  # Get the corresponding subplot axis\n",
    "    img = Image.open(image_paths[i])  # Open the saved image\n",
    "    ax.imshow(img)  # Display the image\n",
    "    ax.axis('off')  # Turn off the axis\n",
    "\n",
    "# Hide any remaining subplots that weren't used\n",
    "for j in range(num_figures, len(display_axs)):\n",
    "    display_axs[j].axis('off')\n",
    "\n",
    "# Show the final display figure\n",
    "display_fig.savefig(f'./ESCAPE RATINGS/Visuals/Conference Ratings/conference_ratings_week{current_week}.png', bbox_inches='tight', dpi=300)\n",
    "plt.show(display_fig)\n",
    "\n",
    "# Optional: Clean up the temporary images after displaying\n",
    "for image_path in image_paths:\n",
    "    os.remove(image_path)  # Delete the temporary image files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playoff Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "conference_list = ['SEC', 'Big Ten', 'Big 12', 'ACC', 'Pac-12', 'Conference USA', 'Mid-American', 'Sun Belt', 'American Athletic', 'Mountain West']\n",
    "top_4_seeds = all_data[all_data['conference'].isin(conference_list)].groupby('conference').first().sort_values('power_rating', ascending=False).reset_index()[0:4]\n",
    "autobid_5 = all_data[all_data['conference'].isin(conference_list)].groupby('conference').first().sort_values('power_rating', ascending=False).reset_index()[4:5]\n",
    "excluded_teams = list(top_4_seeds['team']) + list(autobid_5['team'])\n",
    "at_large_bids = all_data[~all_data['team'].isin(excluded_teams)].head(7).reset_index(drop=True)\n",
    "at_large_bids = pd.concat([at_large_bids, autobid_5]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary for at_large_bids starting from seed 5\n",
    "at_large_dict = {i + 5: team for i, team in enumerate(at_large_bids['team'])}\n",
    "power_5_dict = {i + 1: team for i, team in enumerate(top_4_seeds['team'])}\n",
    "seeding = {**power_5_dict, **at_large_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "# Function to fetch the logo image for a team\n",
    "def fetch_logo_image(logo_url):\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    from io import BytesIO\n",
    "\n",
    "    response = requests.get(logo_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    return img\n",
    "\n",
    "def draw_playoff_bracket(seeding, team_data):\n",
    "    fig, ax = plt.subplots(figsize=(12, 12),dpi=125)\n",
    "    \n",
    "    # Round 1 matchups and byes for teams 1-4\n",
    "    first_round_matchups = [\n",
    "        (8, 9), (5, 12), (7, 10), (6, 11) \n",
    "    ]\n",
    "    \n",
    "    # Mapping teams to their matchup in round 1\n",
    "    matchups_text = [\n",
    "        f\"#{match[0]} {seeding[match[0]]} vs #{match[1]} {seeding[match[1]]}\" for match in first_round_matchups\n",
    "    ]\n",
    "    \n",
    "    # Round 2 (quarterfinals): top seeds (1-4) vs winners of round 1\n",
    "    top_seeds = [1, 4, 3, 2]\n",
    "\n",
    "    # Positions for round 1 (y coordinates for matches)\n",
    "    y_round_1 = [0.90, 0.65, 0.4, 0.15]\n",
    "    \n",
    "    # Positions for round 2 (y coordinates for top 4 seeds)\n",
    "    y_round_2 = [0.90, 0.65, 0.4, 0.15]\n",
    "\n",
    "    top_seed_locations = [0.8, 0.55, 0.3, 0.05]\n",
    "    \n",
    "    # Adding matchups from the first round\n",
    "    for i, (y, text) in enumerate(zip(y_round_1, matchups_text)):\n",
    "        ax.text(0.05, y+0.05, text, fontsize=10, verticalalignment='center')\n",
    "        # Fetch logos for both teams in the matchup from team_data\n",
    "        team1_logo_url = logos[logos['team'] == seeding[first_round_matchups[i][0]]]['logo'].values[0][0]\n",
    "        team2_logo_url = logos[logos['team'] == seeding[first_round_matchups[i][1]]]['logo'].values[0][0]\n",
    "        \n",
    "        # Display team 1 logo\n",
    "        team1_logo = fetch_logo_image(team1_logo_url)\n",
    "        imagebox1 = OffsetImage(team1_logo, zoom=0.1)\n",
    "        ab1 = AnnotationBbox(imagebox1, (0.1, y), frameon=False)\n",
    "        ax.add_artist(ab1)\n",
    "        \n",
    "        # Display team 2 logo\n",
    "        team2_logo = fetch_logo_image(team2_logo_url)\n",
    "        imagebox2 = OffsetImage(team2_logo, zoom=0.1)\n",
    "        ab2 = AnnotationBbox(imagebox2, (0.2, y), frameon=False)\n",
    "        ax.add_artist(ab2)\n",
    "\n",
    "    # Adding the top 4 seeds (bye teams)\n",
    "    for i, seed in enumerate(top_seeds):\n",
    "        # Fetch and display logo for the top seed (bye team)\n",
    "        ax.text(0.25, top_seed_locations[i]+0.05, f\"#{seed} {seeding[seed]}\", fontsize=10, verticalalignment='center')\n",
    "        bye_team_logo_url = logos[logos['team'] == seeding[seed]]['logo'].values[0][0]\n",
    "        bye_team_logo = fetch_logo_image(bye_team_logo_url)\n",
    "        imagebox_bye = OffsetImage(bye_team_logo, zoom=0.1)\n",
    "        ab_bye = AnnotationBbox(imagebox_bye, (0.3, top_seed_locations[i]), frameon=False)\n",
    "        ax.add_artist(ab_bye)\n",
    "    \n",
    "    # Drawing lines connecting round 1 winners to the top 4 seeds\n",
    "    for i in range(4):\n",
    "        ax.add_patch(patches.ConnectionPatch((0.15, y_round_1[i]-0.05), (0.15, top_seed_locations[i]), 'data', 'data', arrowstyle=\"-\"))\n",
    "        ax.add_patch(patches.ConnectionPatch((0.15, top_seed_locations[i]), (0.25, top_seed_locations[i]), 'data', 'data', arrowstyle=\"-\"))\n",
    "        ax.add_patch(patches.ConnectionPatch((0.35, top_seed_locations[i]), (0.5, top_seed_locations[i]), 'data', 'data', arrowstyle='-'))\n",
    "        \n",
    "\n",
    "    ax.add_patch(patches.ConnectionPatch((0.5, top_seed_locations[0]), (0.5, top_seed_locations[1]), 'data', 'data', arrowstyle='-'))\n",
    "    ax.add_patch(patches.ConnectionPatch((0.5, top_seed_locations[2]), (0.5, top_seed_locations[3]), 'data', 'data', arrowstyle='-'))\n",
    "    ax.add_patch(patches.ConnectionPatch((0.5, (top_seed_locations[0]+top_seed_locations[1])/2), (0.7, (top_seed_locations[0]+top_seed_locations[1])/2), 'data', 'data', arrowstyle='-'))\n",
    "    ax.add_patch(patches.ConnectionPatch((0.5, (top_seed_locations[2]+top_seed_locations[3])/2), (0.7, (top_seed_locations[2]+top_seed_locations[3])/2), 'data', 'data', arrowstyle='-'))\n",
    "    ax.add_patch(patches.ConnectionPatch((0.7, (top_seed_locations[0]+top_seed_locations[1])/2), (0.7, (top_seed_locations[2]+top_seed_locations[3])/2), 'data', 'data', arrowstyle='-'))\n",
    "    ax.add_patch(patches.ConnectionPatch((0.7, (top_seed_locations[1]+top_seed_locations[2])/2), (0.9, (top_seed_locations[1]+top_seed_locations[2])/2), 'data', 'data', arrowstyle='-'))\n",
    "\n",
    "\n",
    "    # Final formatting\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axis('off')\n",
    "    plt.gca().set_facecolor('#5fa391')\n",
    "    plt.gcf().set_facecolor('#5fa391')\n",
    "    plt.title(\"Projected Playoff Bracket\", fontweight='bold', fontsize=20)\n",
    "    plt.savefig(f\"./ESCAPE Ratings/Visuals/Projected Playoff/projected_playoff_week{current_week}.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Assuming team_data is a DataFrame with columns ['team', 'logo'], where 'logo' is the URL to each team's logo\n",
    "draw_playoff_bracket(seeding, team_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turnovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_and_worst(all_data, logos, 'total_turnovers_scaled', \"Turnover Margin Percentiles\", \"Percentile Based: 100 is best, 1 is worst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Offenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler100 = MinMaxScaler(feature_range=(1, 100))\n",
    "all_data['offensive_total'] = scaler100.fit_transform(all_data[['offensive_total']])\n",
    "\n",
    "best_and_worst(all_data, logos, 'offensive_total', \"ESCAPE Raw Offenses: Best and Worst 25\", \"Percentile Based: 100 is best, 1 is worst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Defenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler100 = MinMaxScaler(feature_range=(1, 100))\n",
    "all_data['defensive_total'] = scaler100.fit_transform(all_data[['defensive_total']])\n",
    "top_25 = all_data.sort_values('defensive_total', ascending=False)[:25].reset_index(drop=True)\n",
    "bottom_25 = all_data.sort_values('defensive_total', ascending=False)[-25:].reset_index(drop=True)\n",
    "\n",
    "# Create figure and axes for two plots (top 25 on the left, bottom 25 on the right)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8), dpi=125)\n",
    "fig.patch.set_facecolor('#5fa391')  # Set figure background color\n",
    "ax1.set_facecolor('#5fa391')  # Set background color for the left plot\n",
    "ax2.set_facecolor('#5fa391')  # Set background color for the right plot\n",
    "\n",
    "# Title and description\n",
    "fig.suptitle(\"ESCAPE Raw Defenses: Top and Bottom 25\", fontsize=20, fontweight='bold', color='black')\n",
    "plot_bar_charts(ax1, top_25, logos, 'defensive_total', \"Top 25 Raw Defenses\", 'Top')\n",
    "plot_bar_charts(ax2, bottom_25, logos, 'defensive_total', \"Bottom 25 Raw Defenses\", 'Bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler100 = MinMaxScaler(feature_range=(1, 100))\n",
    "all_data['defensive_total'] = scaler100.fit_transform(all_data[['defensive_total']])\n",
    "\n",
    "best_and_worst(all_data, logos, 'defensive_total', \"ESCAPE Raw Defenses: Best and Worst 25\", \"100 is the best raw defense, 1 is the worst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offense vs. Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from io import BytesIO\n",
    "import requests\n",
    "configuration = cfbd.Configuration()\n",
    "configuration.api_key['Authorization'] = '7vGedNNOrnl0NGcSvt92FcVahY602p7IroVBlCA1Tt+WI/dCwtT7Gj5VzmaHrrxS'\n",
    "configuration.api_key_prefix['Authorization'] = 'Bearer'\n",
    "api_client = cfbd.ApiClient(configuration)\n",
    "advanced_instance = cfbd.StatsApi(api_client)\n",
    "games_api = cfbd.GamesApi(api_client)\n",
    "betting_api = cfbd.BettingApi(api_client)\n",
    "ratings_api = cfbd.RatingsApi(api_client)\n",
    "teams_api = cfbd.TeamsApi(api_client)\n",
    "metrics_api = cfbd.MetricsApi(api_client)\n",
    "players_api = cfbd.PlayersApi(api_client)\n",
    "recruiting_api = cfbd.RecruitingApi(api_client)\n",
    "\n",
    "logos_info_list = []\n",
    "response = teams_api.get_teams()\n",
    "logos_info_list = [*logos_info_list, *response]\n",
    "logos_info_dict = [dict(\n",
    "    team = l.school,\n",
    "    color = l.color,\n",
    "    alt_color = l.alt_color,\n",
    "    logo = l.logos\n",
    ") for l in logos_info_list]\n",
    "logos = pd.DataFrame(logos_info_dict)\n",
    "logos = logos.dropna(subset=['logo', 'color'])\n",
    "all_data = pd.read_csv(f\"./ESCAPE Ratings/Data/y{current_year}/team_data_week{current_week}.csv\")\n",
    "scaler100 = MinMaxScaler(feature_range=(1, 100))\n",
    "all_data['offensive_total'] = scaler100.fit_transform(all_data[['offensive_total']])\n",
    "all_data['offensive_total'] = all_data['offensive_total'] - all_data['offensive_total'].mean()\n",
    "all_data['defensive_total'] = scaler100.fit_transform(all_data[['defensive_total']])\n",
    "all_data['defensive_total'] = all_data['defensive_total'] - all_data['defensive_total'].mean()\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(15, 9),dpi=125)\n",
    "plt.gca().set_facecolor('#5fa391')\n",
    "plt.gcf().set_facecolor('#5fa391')\n",
    "# Set the size of the logos (adjust the numbers to make logos smaller or larger)\n",
    "logo_size = 2  # Half the size of the logo to create spacing\n",
    "\n",
    "# Loop through the team_data DataFrame to plot logos\n",
    "for i in range(len(all_data)):\n",
    "    # Get the logo image from the URL\n",
    "    logo_url = logos[logos['team'] == all_data.loc[i,'team']]['logo'].values[0][0]\n",
    "    response = requests.get(logo_url)\n",
    "    img = mpimg.imread(BytesIO(response.content), format='png')\n",
    "\n",
    "    # Calculate the extent for the logo\n",
    "    # Here we use logo_size for both sides to center the logo at the specific coordinates\n",
    "    ax.imshow(img, aspect='auto', \n",
    "              extent=(all_data['defensive_total'].iloc[i] - (logo_size-0.5),\n",
    "                      all_data['defensive_total'].iloc[i] + (logo_size-0.5),\n",
    "                      all_data['offensive_total'].iloc[i] - logo_size,\n",
    "                      all_data['offensive_total'].iloc[i] + logo_size))\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xlabel('Total Defense')\n",
    "ax.set_ylabel('Total Offense')\n",
    "ax.set_title('Team Offense vs Defense', fontweight='bold', fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.xlim(all_data['defensive_total'].min() - 5, all_data['defensive_total'].max() + 5)  # Adjust x-axis limits for visibility\n",
    "plt.ylim(all_data['offensive_total'].min() - 5, all_data['offensive_total'].max() + 5)  # Adjust y-axis limits for visibility\n",
    "plt.grid(False)  # Turn off the grid\n",
    "plt.axhline(0, linestyle='--', color='black', alpha = 0.3)\n",
    "plt.axvline(0, linestyle='--', color='black', alpha = 0.3)\n",
    "plt.text(45, 50, \"Good Offense, Good Defense\", fontsize=10, fontweight='bold', ha='center')\n",
    "plt.text(-30, 50, \"Good Offense, Bad Defense\", fontsize=10, fontweight='bold', ha='center')\n",
    "plt.text(45, -50, \"Bad Offense, Good Defense\", fontsize=10, fontweight='bold', ha='center')\n",
    "plt.text(-30, -50, \"Bad Offense, Bad Defense\", fontsize=10, fontweight='bold', ha='center')\n",
    "plt.figure(dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler100 = MinMaxScaler(feature_range=(1, 100))\n",
    "all_data['STM_scaled'] = scaler100.fit_transform(all_data[['STM']])\n",
    "\n",
    "best_and_worst(all_data, logos, 'STM_scaled', \"ESCAPE Special Teams\", \"Percentile Based: 100 is best, 1 is worst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalty Burden Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbr_min = all_data['PBR'].min()\n",
    "pbr_max = all_data['PBR'].max()\n",
    "all_data['PBR_scaled'] = 100 - (all_data['PBR'] - pbr_min) * (99 / (pbr_max - pbr_min))\n",
    "\n",
    "best_and_worst(all_data, logos, 'PBR_scaled', \"ESCAPE Penalty Burden Ratio\", \"How Penalties Impact Success - 100 is best, 1 is worst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drive Control Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler100 = MinMaxScaler(feature_range=(1, 100))\n",
    "all_data['DCE_scaled'] = scaler100.fit_transform(all_data[['DCE']])\n",
    "\n",
    "best_and_worst(all_data, logos, 'DCE_scaled', \"ESCAPE Drive Control Efficiency\", \"How Well You Control the Ball - 100 is best, 1 is worst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drive Disruption Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler100 = MinMaxScaler(feature_range=(1, 100))\n",
    "all_data['DDE_scaled'] = scaler100.fit_transform(all_data[['DDE']])\n",
    "\n",
    "best_and_worst(all_data, logos, 'DDE_scaled', \"ESCAPE Drive Disruption Efficiency\", \"How Well You Disrupt the Offense - 100 is best, 1 is worst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCE vs. DDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cfbd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "configuration = cfbd.Configuration()\n",
    "configuration.api_key['Authorization'] = '7vGedNNOrnl0NGcSvt92FcVahY602p7IroVBlCA1Tt+WI/dCwtT7Gj5VzmaHrrxS'\n",
    "configuration.api_key_prefix['Authorization'] = 'Bearer'\n",
    "api_client = cfbd.ApiClient(configuration)\n",
    "advanced_instance = cfbd.StatsApi(api_client)\n",
    "games_api = cfbd.GamesApi(api_client)\n",
    "betting_api = cfbd.BettingApi(api_client)\n",
    "ratings_api = cfbd.RatingsApi(api_client)\n",
    "teams_api = cfbd.TeamsApi(api_client)\n",
    "metrics_api = cfbd.MetricsApi(api_client)\n",
    "players_api = cfbd.PlayersApi(api_client)\n",
    "recruiting_api = cfbd.RecruitingApi(api_client)\n",
    "\n",
    "logos_info_list = []\n",
    "response = teams_api.get_teams()\n",
    "logos_info_list = [*logos_info_list, *response]\n",
    "logos_info_dict = [dict(\n",
    "    team = l.school,\n",
    "    color = l.color,\n",
    "    alt_color = l.alt_color,\n",
    "    logo = l.logos\n",
    ") for l in logos_info_list]\n",
    "logos = pd.DataFrame(logos_info_dict)\n",
    "logos = logos.dropna(subset=['logo', 'color'])\n",
    "all_data = pd.read_csv(f\"./ESCAPE Ratings/Data/y{current_year}/team_data_week{current_week}.csv\")\n",
    "scaler100 = MinMaxScaler(feature_range=(1, 100))\n",
    "all_data['DCE'] = scaler100.fit_transform(all_data[['DCE']])\n",
    "all_data['DCE'] = all_data['DCE'] - all_data['DCE'].mean()\n",
    "all_data['DDE'] = scaler100.fit_transform(all_data[['DDE']])\n",
    "all_data['DDE'] = all_data['DDE'] - all_data['DDE'].mean()\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(15, 9),dpi=125)\n",
    "plt.gca().set_facecolor('#5fa391')\n",
    "plt.gcf().set_facecolor('#5fa391')\n",
    "# Set the size of the logos (adjust the numbers to make logos smaller or larger)\n",
    "logo_size = 2  # Half the size of the logo to create spacing\n",
    "\n",
    "# Loop through the team_data DataFrame to plot logos\n",
    "for i in range(len(all_data)):\n",
    "    # Get the logo image from the URL\n",
    "    logo_url = logos[logos['team'] == all_data.loc[i,'team']]['logo'].values[0][0]\n",
    "    response = requests.get(logo_url)\n",
    "    img = mpimg.imread(BytesIO(response.content), format='png')\n",
    "\n",
    "    # Calculate the extent for the logo\n",
    "    # Here we use logo_size for both sides to center the logo at the specific coordinates\n",
    "    ax.imshow(img, aspect='auto', \n",
    "              extent=(all_data['DDE'].iloc[i] - (logo_size-0.5),\n",
    "                      all_data['DDE'].iloc[i] + (logo_size-0.5),\n",
    "                      all_data['DCE'].iloc[i] - logo_size,\n",
    "                      all_data['DCE'].iloc[i] + logo_size))\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xlabel('Drive Disruption Efficiency')\n",
    "ax.set_ylabel('Drive Control Efficiency')\n",
    "ax.set_title('DCE vs. DDE', fontweight='bold', fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.xlim(all_data['DDE'].min() - 5, all_data['DDE'].max() + 5)  # Adjust x-axis limits for visibility\n",
    "plt.ylim(all_data['DCE'].min() - 5, all_data['DCE'].max() + 5)  # Adjust y-axis limits for visibility\n",
    "plt.grid(False)  # Turn off the grid\n",
    "plt.axhline(0, linestyle='--', color='black', alpha = 0.3)\n",
    "plt.axvline(0, linestyle='--', color='black', alpha = 0.3)\n",
    "plt.text(45, 50, \"Good DCE, Good DDE\", fontsize=10, fontweight='bold', ha='center')\n",
    "plt.text(-30, 50, \"Good DCE, Bad DDE\", fontsize=10, fontweight='bold', ha='center')\n",
    "plt.text(45, -50, \"Bad DCE, Good DDE\", fontsize=10, fontweight='bold', ha='center')\n",
    "plt.text(-30, -50, \"Bad DCE, Bad DDE\", fontsize=10, fontweight='bold', ha='center')\n",
    "plt.figure(dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Metric Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_average = [\"offensive_rank\", \"defensive_rank\", \"STM_rank\", \"PBR_rank\", \"DCE_rank\", \"DDE_rank\"]\n",
    "all_data[\"average_metric_rank\"] = round(all_data[columns_to_average].mean(axis=1),1)\n",
    "best_and_worst(all_data, logos, 'average_metric_rank', \"ESCAPE Average Metric Ranking\", \"Average OFF, DEF, ST, PBR, DCE, DDE Ranking - Lower is Better\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume vs Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(15, 9),dpi=125)\n",
    "plt.gca().set_facecolor('#5fa391')\n",
    "plt.gcf().set_facecolor('#5fa391')\n",
    "# Set the size of the logos (adjust the numbers to make logos smaller or larger)\n",
    "logo_size = 0.9  # Half the size of the logo to create spacing\n",
    "# Loop through the team_data DataFrame to plot logos\n",
    "for i in range(len(all_data)):\n",
    "    # Get the logo image from the URL\n",
    "    logo_url = logos[logos['team'] == all_data.loc[i,'team']]['logo'].values[0][0]\n",
    "    response = requests.get(logo_url)\n",
    "    img = mpimg.imread(BytesIO(response.content), format='png')\n",
    "\n",
    "    # Calculate the extent for the logo\n",
    "    # Here we use logo_size for both sides to center the logo at the specific coordinates\n",
    "    ax.imshow(img, aspect='auto', \n",
    "              extent=(all_data['most_deserving_wins'].iloc[i] - (logo_size-0.7),\n",
    "                      all_data['most_deserving_wins'].iloc[i] + (logo_size-0.7),\n",
    "                      all_data['power_rating'].iloc[i] - logo_size,\n",
    "                      all_data['power_rating'].iloc[i] + logo_size))\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xlabel('Resume (Record Strength)', fontweight='bold')\n",
    "ax.set_ylabel('Ratings (Team Strength)', fontweight='bold')\n",
    "ax.set_title('Resume vs. Ratings', fontweight='bold', fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.xlim(all_data['most_deserving_wins'].min() - 1, all_data['most_deserving_wins'].max() + 1)  # Adjust x-axis limits for visibility\n",
    "plt.ylim(all_data['power_rating'].min() - 3, all_data['power_rating'].max() + 3)  # Adjust y-axis limits for visibility\n",
    "plt.grid(False)  # Turn off the grid\n",
    "\n",
    "elite_team_pr = all_data['power_rating'].mean() + (2*all_data['power_rating'].std())\n",
    "elite_team_resume = all_data['most_deserving_wins'].mean() + (2*all_data['most_deserving_wins'].std())\n",
    "good_team_pr = all_data['power_rating'].mean() + (1*all_data['power_rating'].std())\n",
    "good_team_resume = all_data['most_deserving_wins'].mean() + (1*all_data['most_deserving_wins'].std())\n",
    "avg_team_pr = all_data['power_rating'].mean() + (0*all_data['power_rating'].std())\n",
    "avg_team_resume = all_data['most_deserving_wins'].mean() + (0*all_data['most_deserving_wins'].std())\n",
    "below_avg_team_pr = all_data['power_rating'].mean() + (-1*all_data['power_rating'].std())\n",
    "below_avg_team_resume = all_data['most_deserving_wins'].mean() + (-1*all_data['most_deserving_wins'].std())\n",
    "\n",
    "\n",
    "# Get the data ranges for normalization\n",
    "x_min, x_max = all_data['most_deserving_wins'].min()-1, all_data['most_deserving_wins'].max()+1\n",
    "y_min, y_max = all_data['power_rating'].min()-3, all_data['power_rating'].max()+3\n",
    "plt.plot([elite_team_resume, x_max], [elite_team_pr, elite_team_pr], linestyle='--', color='darkgreen', alpha=0.6)  # Horizontal line\n",
    "plt.plot([elite_team_resume, elite_team_resume], [elite_team_pr, y_max], linestyle='--', color='darkgreen', alpha=0.6)  # Vertical line\n",
    "plt.plot([good_team_resume, x_max], [good_team_pr, good_team_pr], linestyle='--', color='yellow', alpha=0.6)  # Horizontal line\n",
    "plt.plot([good_team_resume, good_team_resume], [good_team_pr, y_max], linestyle='--', color='yellow', alpha=0.6)  # Vertical line\n",
    "# plt.plot([avg_team_resume, x_max], [avg_team_pr, avg_team_pr], linestyle='--', color='black', alpha=0.6)  # Horizontal line\n",
    "# plt.plot([avg_team_resume, avg_team_resume], [avg_team_pr, y_max], linestyle='--', color='black', alpha=0.6)  # Vertical line\n",
    "# plt.plot([below_avg_team_resume, x_max], [below_avg_team_pr, below_avg_team_pr], linestyle='--', color='red', alpha=0.6)  # Horizontal line\n",
    "# plt.plot([below_avg_team_resume, below_avg_team_resume], [below_avg_team_pr, y_max], linestyle='--', color='red', alpha=0.6)  # Vertical line\n",
    "plt.figure(dpi=500)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talent vs. Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 9),dpi=125)\n",
    "plt.gca().set_facecolor('#5fa391')\n",
    "plt.gcf().set_facecolor('#5fa391')\n",
    "# Set the size of the logos (adjust the numbers to make logos smaller or larger)\n",
    "logo_size = 2  # Half the size of the logo to create spacing\n",
    "# Loop through the team_data DataFrame to plot logos\n",
    "scaler100 = MinMaxScaler(feature_range=(1, 100))\n",
    "all_data['most_deserving_scaled'] = scaler100.fit_transform(all_data[['most_deserving_wins']])\n",
    "for i in range(len(all_data)):\n",
    "    # Get the logo image from the URL\n",
    "    logo_url = logos[logos['team'] == all_data.loc[i,'team']]['logo'].values[0][0]\n",
    "    response = requests.get(logo_url)\n",
    "    img = mpimg.imread(BytesIO(response.content), format='png')\n",
    "\n",
    "    # Calculate the extent for the logo\n",
    "    # Here we use logo_size for both sides to center the logo at the specific coordinates\n",
    "    ax.imshow(img, aspect='auto', \n",
    "              extent=(all_data['avg_talent'].iloc[i] - (logo_size-0.5),\n",
    "                      all_data['avg_talent'].iloc[i] + (logo_size-0.5),\n",
    "                      all_data['most_deserving_scaled'].iloc[i] - logo_size,\n",
    "                      all_data['most_deserving_scaled'].iloc[i] + logo_size))\n",
    "\n",
    "ax.plot(\n",
    "    [all_data['avg_talent'].min()-3, all_data['avg_talent'].max()+3],\n",
    "    [all_data['avg_talent'].min()-3, all_data['avg_talent'].max()+3],\n",
    "    color='black', linestyle='--'\n",
    ")\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xlabel('Talent Percentile', fontweight='bold')\n",
    "ax.set_ylabel('Resume Percentile', fontweight='bold')\n",
    "ax.set_title('Production vs. Talent', fontweight='bold', fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.xlim(all_data['avg_talent'].min() - 3, all_data['avg_talent'].max() + 3)  # Adjust x-axis limits for visibility\n",
    "plt.ylim(all_data['most_deserving_scaled'].min() - 3, all_data['most_deserving_scaled'].max() + 3)  # Adjust y-axis limits for visibility\n",
    "plt.grid(False)  # Turn off the grid\n",
    "\n",
    "plt.text(1, 98, \"Production Outperforming Talent\", fontsize=10, fontweight='bold', ha='left')\n",
    "plt.text(100, 2, \"Production Underperforming Talent\", fontsize=10, fontweight='bold', ha='right')\n",
    "\n",
    "plt.figure(dpi=500)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talent Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler100 = MinMaxScaler(feature_range=(1, 100))\n",
    "all_data['most_deserving_scaled'] = scaler100.fit_transform(all_data[['most_deserving_wins']])\n",
    "all_data['talent_performance'] = (all_data['most_deserving_scaled'] - all_data['avg_talent']) / math.sqrt(2)\n",
    "best_and_worst(all_data, logos, 'talent_performance', \"ESCAPE Talent Performance Gap\", \"Is Your Team Outperforming or Underperforming Its Roster?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler100 = MinMaxScaler(feature_range=(1, 100))\n",
    "all_data['defensive_total'] = scaler100.fit_transform(all_data[['defensive_total']])\n",
    "all_data['offensive_total'] = scaler100.fit_transform(all_data[['offensive_total']])\n",
    "\n",
    "all_data['dependence_score'] = (all_data['offensive_total'] - all_data['defensive_total']) / (all_data['offensive_total'] + all_data['defensive_total'])\n",
    "best_and_worst(all_data, logos, 'dependence_score', 'ESCAPE Unit Dependence', 'Values near 1 indicate offensive dependence, while values near -1 indicate defensive dependence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[['team', 'dependence_score']].sort_values('dependence_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Info Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_week = 1\n",
    "end_week = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prep work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 2024\n"
     ]
    }
   ],
   "source": [
    "from unittest import result\n",
    "import pandas as pd\n",
    "import cfbd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import ImageGrab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from base64 import b64decode\n",
    "from io import BytesIO\n",
    "from IPython import get_ipython\n",
    "from IPython.core.magic import register_cell_magic\n",
    "import PIL\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from matplotlib.lines import Line2D\n",
    "import math\n",
    "import cfbd\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from matplotlib import gridspec\n",
    "import datetime\n",
    "np.random.seed(42)\n",
    "configuration = cfbd.Configuration()\n",
    "configuration.api_key['Authorization'] = '7vGedNNOrnl0NGcSvt92FcVahY602p7IroVBlCA1Tt+WI/dCwtT7Gj5VzmaHrrxS'\n",
    "configuration.api_key_prefix['Authorization'] = 'Bearer'\n",
    "api_client = cfbd.ApiClient(configuration)\n",
    "advanced_instance = cfbd.StatsApi(api_client)\n",
    "games_api = cfbd.GamesApi(api_client)\n",
    "betting_api = cfbd.BettingApi(api_client)\n",
    "ratings_api = cfbd.RatingsApi(api_client)\n",
    "teams_api = cfbd.TeamsApi(api_client)\n",
    "metrics_api = cfbd.MetricsApi(api_client)\n",
    "players_api = cfbd.PlayersApi(api_client)\n",
    "recruiting_api = cfbd.RecruitingApi(api_client)\n",
    "\n",
    "week_start_list = [*games_api.get_calendar(year = 2024)]\n",
    "calendar_dict = [dict(\n",
    "    first_game_start = c.first_game_start,\n",
    "    last_game_start = c.last_game_start,\n",
    "    season = c.season,\n",
    "    season_type = c.season_type,\n",
    "    week = c.week\n",
    ") for c in week_start_list]\n",
    "calendar = pd.DataFrame(calendar_dict)\n",
    "calendar['first_game_start'] = pd.to_datetime(calendar['first_game_start'])\n",
    "calendar['last_game_start'] = pd.to_datetime(calendar['last_game_start'])\n",
    "current_year = int(calendar.loc[0, 'season'])\n",
    "\n",
    "import pytz\n",
    "\n",
    "current_time = datetime.datetime.now(pytz.UTC)\n",
    "first_game_start = calendar['first_game_start'].iloc[0]\n",
    "last_game_start = calendar['last_game_start'].iloc[-1]\n",
    "current_week = None\n",
    "if current_time < first_game_start:\n",
    "    current_week = 1\n",
    "    postseason = False\n",
    "elif current_time > last_game_start:\n",
    "    current_week = calendar.iloc[-2, -1] + 1\n",
    "    postseason = True\n",
    "else:\n",
    "    condition_1 = (calendar['first_game_start'] <= current_time) & (calendar['last_game_start'] >= current_time)\n",
    "    condition_2 = (calendar['last_game_start'].shift(1) < current_time) & (calendar['first_game_start'] > current_time)\n",
    "\n",
    "    # Combine conditions\n",
    "    result = calendar[condition_1 | condition_2].reset_index(drop=True)\n",
    "    if result['season_type'][0] == 'regular':\n",
    "        current_week = result['week'][0]\n",
    "        postseason = False\n",
    "    else:\n",
    "        current_week = calendar.iloc[-2, -1] + 1\n",
    "        postseason = True\n",
    "\n",
    "current_week = int(current_week)\n",
    "current_year = int(current_year)\n",
    "print(current_week, current_year)\n",
    "\n",
    "logos_info_list = []\n",
    "response = teams_api.get_teams()\n",
    "logos_info_list = [*logos_info_list, *response]\n",
    "logos_info_dict = [dict(\n",
    "    team = l.school,\n",
    "    color = l.color,\n",
    "    alt_color = l.alt_color,\n",
    "    logo = l.logos\n",
    ") for l in logos_info_list]\n",
    "logos = pd.DataFrame(logos_info_dict)\n",
    "logos = logos.dropna(subset=['logo', 'color'])\n",
    "\n",
    "team_data = pd.read_csv(f'./ESCAPE Ratings/Ratings/y{current_year}/ESCAPE_week{current_week}.csv')\n",
    "\n",
    "############### NEED TO UPDATE ###############\n",
    "start_season_data = pd.read_csv(f\"./ESCAPE Ratings/Ratings/y{current_year}/ESCAPE_week{current_week}.csv\")\n",
    "\n",
    "if os.path.exists(f\"./ESCAPE Ratings/Ratings/y{current_year}/ESCAPE_week{current_week-1}.csv\"):\n",
    "    last_week_data = pd.read_csv(f\"./ESCAPE Ratings/Ratings/y{current_year}/ESCAPE_week{current_week-1}.csv\")\n",
    "else:\n",
    "    last_week_data = pd.read_csv(f\"./ESCAPE Ratings/Ratings/y{current_year}/ESCAPE_week{current_week}.csv\")\n",
    "\n",
    "week_to_check = current_week - 4\n",
    "last_month_data = None\n",
    "\n",
    "# Loop to find the most recent existing file\n",
    "while week_to_check <= current_week:\n",
    "    file_path = f\"./ESCAPE Ratings/Ratings/y{current_year}/ESCAPE_week{week_to_check}.csv\"\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        # If the file is found, read it in and break the loop\n",
    "        last_month_data = pd.read_csv(file_path)\n",
    "        break\n",
    "    \n",
    "    week_to_check += 1\n",
    "\n",
    "all_data = pd.read_csv(f\"./ESCAPE Ratings/Data/y{current_year}/team_data_week{current_week}.csv\")\n",
    "\n",
    "def date_sort(game):\n",
    "    game_date = datetime.datetime.strptime(game['start_date'], \"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "    return game_date\n",
    "\n",
    "def ESCAPE_Win_Prob(home_power_rating, away_power_rating):\n",
    "    return round((1 / (1 + 10 ** ((away_power_rating - (home_power_rating)) / 20.5))) * 100, 2)\n",
    "    \n",
    "games = []\n",
    "for week in range(start_week,end_week):\n",
    "    response = games_api.get_games(year=current_year, week=week,division = 'fbs')\n",
    "    games = [*games, *response]\n",
    "games = [dict(\n",
    "            id=g.id,\n",
    "            season=g.season,\n",
    "            week=g.week,\n",
    "            start_date=g.start_date,\n",
    "            home_team=g.home_team,\n",
    "            home_elo=g.home_pregame_elo,\n",
    "            away_team=g.away_team,\n",
    "            away_elo=g.away_pregame_elo,\n",
    "            home_points = g.home_points,\n",
    "            away_points = g.away_points\n",
    "            ) for g in games if g.home_pregame_elo is not None and g.away_pregame_elo is not None]\n",
    "games.sort(key=date_sort)\n",
    "schedule_info = pd.DataFrame(games)\n",
    "\n",
    "schedule_info = schedule_info.merge(team_data[['team', 'power_rating']], \n",
    "                                    left_on='home_team', \n",
    "                                    right_on='team', \n",
    "                                    how='left').rename(columns={'power_rating': 'home_pr'})\n",
    "schedule_info = schedule_info.drop(columns=['team'])\n",
    "schedule_info = schedule_info.merge(team_data[['team', 'power_rating']], \n",
    "                                    left_on='away_team', \n",
    "                                    right_on='team', \n",
    "                                    how='left').rename(columns={'power_rating': 'away_pr'})\n",
    "schedule_info = schedule_info.drop(columns=['team'])\n",
    "\n",
    "# Apply the ESCAPE_Win_Prob function to the schedule_info DataFrame\n",
    "schedule_info['escape_win_prob'] = schedule_info.apply(\n",
    "    lambda row: ESCAPE_Win_Prob(row['home_pr'], row['away_pr']), axis=1\n",
    ")\n",
    "\n",
    "# Elo Win Probability\n",
    "schedule_info['home_win_prob'] = round((10**((schedule_info['home_elo'] - schedule_info['away_elo']) / 400)) / ((10**((schedule_info['home_elo'] - schedule_info['away_elo']) / 400)) + 1)*100,2)\n",
    "\n",
    "elo_ratings_list = [*ratings_api.get_elo_ratings(year=current_year, week=current_week)]\n",
    "elo_ratings_dict = [dict(\n",
    "    team = e.team,\n",
    "    elo = e.elo\n",
    ") for e in elo_ratings_list]\n",
    "elo_ratings = pd.DataFrame(elo_ratings_dict)\n",
    "\n",
    "records_list = []\n",
    "response = games_api.get_team_records(year=current_year)\n",
    "records_list = [*records_list, *response]\n",
    "records_dict = [dict(\n",
    "    team = r.team,\n",
    "    games_played = r.total.games,\n",
    "    wins = r.total.wins,\n",
    "    losses = r.total.losses,\n",
    "    conference_games = r.conference_games.games,\n",
    "    conference_wins = r.conference_games.wins,\n",
    "    conference_losses = r.conference_games.losses\n",
    ") for r in records_list]\n",
    "records = pd.DataFrame(records_dict)\n",
    "records.at[records[records['team'] == 'Kansas State'].index[0], 'conference_wins'] -= 1\n",
    "records.at[records[records['team'] == 'Utah'].index[0], 'conference_wins'] -= 1\n",
    "records.at[records[records['team'] == 'Baylor'].index[0], 'conference_losses'] -= 1\n",
    "records.at[records[records['team'] == 'Arizona'].index[0], 'conference_losses'] -= 1\n",
    "\n",
    "@register_cell_magic\n",
    "def capture_png(line, cell):\n",
    "    get_ipython().run_cell_magic(\n",
    "        'capture',\n",
    "        ' --no-stderr --no-stdout result',\n",
    "        cell\n",
    "    )\n",
    "    out_paths = line.strip().split(' ')\n",
    "    for output in result.outputs:\n",
    "        data = output.data\n",
    "        if 'image/png' in data:\n",
    "            path = out_paths.pop(0)\n",
    "            if not path:\n",
    "                raise ValueError('Too few paths given!')\n",
    "            png_bytes = data['image/png']\n",
    "            if isinstance(png_bytes, str):\n",
    "                png_bytes = b64decode(png_bytes)\n",
    "            assert isinstance(png_bytes, bytes)\n",
    "            bytes_io = BytesIO(png_bytes)\n",
    "            image = PIL.Image.open(bytes_io)\n",
    "            image.save(path, 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def best_and_worst(all_data, logos, metric, title, subtitle):\n",
    "    if metric == 'avg_expected_wins':\n",
    "        top_25_best = all_data.sort_values(metric, ascending=True)[:25].reset_index(drop=True)\n",
    "        top_25_worst = all_data.sort_values(metric, ascending=False)[:25].reset_index(drop=True)\n",
    "        top_25_worst = top_25_worst.sort_values(metric, ascending=True)[:25].reset_index(drop=True)\n",
    "        rounding = 3\n",
    "        good = 'Hardest'\n",
    "        bad = 'Easiest'\n",
    "    else:\n",
    "        top_25_best = all_data.sort_values(metric, ascending=False)[:25].reset_index(drop=True)\n",
    "        top_25_worst = all_data.sort_values(metric, ascending=True)[:25].reset_index(drop=True)\n",
    "        top_25_worst = top_25_worst.sort_values(metric, ascending=False)[:25].reset_index(drop=True)\n",
    "        rounding = 1\n",
    "        if (metric == 'wins_above_good') or (metric == 'performance'):\n",
    "            rounding = 3\n",
    "        if (metric == 'RTP') or (metric == 'wins_above_average'):\n",
    "            rounding = 2\n",
    "        good = 'Best'\n",
    "        bad = 'Worst'\n",
    "        if metric == 'performance':\n",
    "            good='Overperformers'\n",
    "            bad='Underperformers'\n",
    "        if (metric == 'wins_above_average'):\n",
    "            good = 'Most'\n",
    "            bad = 'Least'\n",
    "\n",
    "    # Create a figure with 5 rows and 10 columns\n",
    "    fig, axs = plt.subplots(5, 10, figsize=(20, 10), dpi=125)\n",
    "\n",
    "    # Adjust space between subplots\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "    fig.patch.set_facecolor('#5fa391')\n",
    "\n",
    "    # Title and description\n",
    "    plt.suptitle(title, fontsize=20, fontweight='bold', color='black')\n",
    "    plt.text(0.505, 0.935, subtitle, ha='center', fontsize=14, color='black', transform=fig.transFigure)\n",
    "\n",
    "    # Fill the grid alternating Best and Worst Defenses\n",
    "    for i in range(5):  # There are 5 rows\n",
    "        # Best defenses: Columns 0-4 for each row (Best in every odd index)\n",
    "        for j in range(5):  \n",
    "            ax = axs[i, j]\n",
    "            team = top_25_best.loc[i*5 + j, 'team']\n",
    "            logo_url = logos[logos['team'] == team]['logo'].values[0][0]\n",
    "            response = requests.get(logo_url)\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            ax.imshow(img)\n",
    "            ax.set_facecolor('#f0f0f0')\n",
    "            ax.set_title(f\"#{i*5 + j + 1} \\n{round(top_25_best.loc[i*5 + j, metric], rounding)}\", fontsize=14, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "\n",
    "        # Worst defenses: Columns 5-9 for each row (Worst in every even index after 5)\n",
    "        for j in range(5, 10):  \n",
    "            ax = axs[i, j]\n",
    "            team = top_25_worst.loc[i*5 + (j-5), 'team']\n",
    "            logo_url = logos[logos['team'] == team]['logo'].values[0][0]\n",
    "            response = requests.get(logo_url)\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            ax.imshow(img)\n",
    "            ax.set_facecolor('#f0f0f0')\n",
    "            \n",
    "            # Start counting for Worst from 134 and decrement\n",
    "            worst_rank = 110 + (i*5 + (j-5)) \n",
    "            ax.set_title(f\"#{worst_rank} \\n{round(top_25_worst.loc[i*5 + (j-5), metric], rounding)}\", fontsize=14, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "\n",
    "    fig.add_artist(Line2D([0.512, 0.512], [0.12, 0.92], color='black', lw=5))\n",
    "    fig.text(0.13, 0.96, good, ha='left', va='center', fontsize=20, fontweight='bold', color='black')\n",
    "    fig.text(0.89, 0.96, bad, ha='right', va='center', fontsize=20, fontweight='bold', color='black')\n",
    "\n",
    "    # Show the final figure\n",
    "    plt.show()\n",
    "\n",
    "def plot_bar_charts(ax, data, logos, metric, title, top_or_bottom):\n",
    "    if top_or_bottom == 'Top':\n",
    "        top_or_bottom = True\n",
    "    else:\n",
    "        top_or_bottom = False\n",
    "    # Data\n",
    "    teams = data['team']\n",
    "    scores = data[metric]\n",
    "    \n",
    "    team_colors = {row['team']: row['color'] for _, row in logos.iterrows()}\n",
    "    colors = [team_colors[team] for team in teams]\n",
    "\n",
    "    bar_spacing = 5  # This factor increases the spacing between the bars\n",
    "    y_pos = range(len(teams))\n",
    "    y_pos = [y * bar_spacing for y in y_pos]\n",
    "\n",
    "    # Plot bars\n",
    "    bars = ax.barh(y_pos, scores, color=colors, align='center', height=4)\n",
    "\n",
    "    for i, (y, team, bar) in enumerate(zip(y_pos, teams, bars)):\n",
    "        logo_url = logos[logos['team'] == team]['logo'].values[0][0]\n",
    "        response = requests.get(logo_url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "\n",
    "        xy = [bar.get_width() + 3, y]\n",
    "        img = OffsetImage(img, zoom=0.05)\n",
    "        img.image.axes = ax\n",
    "        ab = AnnotationBbox(img, xy, xycoords='data', frameon=False, pad=0)\n",
    "        ax.add_artist(ab)\n",
    "\n",
    "    if top_or_bottom:\n",
    "        # Add labels inside bars\n",
    "        i = 1\n",
    "        for bar, score in zip(bars, scores):\n",
    "            ax.text(bar.get_width() - 3, bar.get_y() + bar.get_height() / 2, \n",
    "                    f\"#{i} - {score:.1f}\", va='center', ha='right', fontsize=8, color='white', fontweight='bold')\n",
    "            i = i + 1\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.tick_params(axis='y', length=0)\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_yticks([])\n",
    "        # Tidy up the axis\n",
    "        ax.invert_yaxis() \n",
    "        ax.set_xlim([0, 105])  # Adjust as per your score range\n",
    "        ax.set_xticks([])  # Remove x-ticks\n",
    "        ax.set_xticklabels([])  # Remove x-labels\n",
    "    else:\n",
    "        i = 110\n",
    "        for bar, score in zip(bars, scores):\n",
    "            ax.text(bar.get_width() - bar.get_width() - 1, bar.get_y() + bar.get_height() / 2, \n",
    "                    f\"#{i} - {score:.1f}\", va='center', ha='right', fontsize=8, color='white', fontweight='bold')\n",
    "            i = i + 1\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.tick_params(axis='y', length=0)\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_yticks([])\n",
    "        # Tidy up the axis\n",
    "        ax.invert_yaxis() \n",
    "        ax.set_xlim([0, 100])  # Adjust as per your score range\n",
    "        ax.set_xticks([])  # Remove x-ticks\n",
    "        ax.set_xticklabels([])  # Remove x-labels\n",
    "\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold', color='black')\n",
    "\n",
    "    # Remove axes spines\n",
    "    for spine in ['top', 'left', 'bottom', 'right']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "\n",
    "def simulate_game_known(home_team, away_team, home_win_prob):\n",
    "    \"\"\"Simulates a single game between two teams based on home win probability.\"\"\"\n",
    "    random_outcome = np.random.random() * 100  # Generates a number between 0 and 100\n",
    "    if random_outcome < home_win_prob:\n",
    "        return home_team, away_team  # Home team wins, Away team loses\n",
    "    else:\n",
    "        return away_team, home_team  # Away team wins, Home team loses\n",
    "\n",
    "def simulate_season_known(schedules, team_data):\n",
    "    \"\"\"Simulates one season based on current power ratings and schedule.\"\"\"\n",
    "    team_wins = {team: 0 for team in team_data['team'].unique()}  # Initialize win counts\n",
    "    team_losses = {team: 0 for team in team_data['team'].unique()}  # Initialize loss counts\n",
    "\n",
    "    for _, game in schedules.iterrows():\n",
    "        home_team = game['home_team']\n",
    "        away_team = game['away_team']\n",
    "        home_win_prob = game['escape_win_prob']\n",
    "\n",
    "        # Simulate the game outcome\n",
    "        winner, loser = simulate_game_known(home_team, away_team, home_win_prob)\n",
    "        team_wins[winner] += 1  # Increment win count for the winner\n",
    "        team_losses[loser] += 1  # Increment loss count for the loser\n",
    "\n",
    "    return team_wins, team_losses  # Returns the win and loss counts for all teams at the end of the season\n",
    "\n",
    "def monte_carlo_simulation_known(num_simulations, schedules, team_data):\n",
    "    \"\"\"Runs a Monte Carlo simulation over multiple seasons.\"\"\"\n",
    "    win_results = []\n",
    "    loss_results = []\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        season_wins, season_losses = simulate_season_known(schedules, team_data)\n",
    "        win_results.append(season_wins)\n",
    "        loss_results.append(season_losses)\n",
    "    \n",
    "    return win_results, loss_results\n",
    "\n",
    "def analyze_simulation_known(win_results, loss_results, schedules, records):\n",
    "    \"\"\"Aggregates the results of multiple simulated seasons and calculates win-loss records.\"\"\"\n",
    "    # Convert list of results into DataFrames\n",
    "    win_df = pd.DataFrame(win_results)\n",
    "    loss_df = pd.DataFrame(loss_results)\n",
    "    \n",
    "    # Determine the number of games each team plays\n",
    "    game_counts = schedules.groupby('home_team').size() + schedules.groupby('away_team').size()\n",
    "    game_counts = game_counts.groupby(level=0).sum()  # Combine home and away counts\n",
    "\n",
    "    # Add 1 win for teams with only 11 games\n",
    "    for team in win_df.columns:\n",
    "        win_df[team] += records[records['team'] == team]['wins'].values[0]\n",
    "        loss_df[team] += records[records['team'] == team]['losses'].values[0]\n",
    "\n",
    "    for team in win_df.columns:\n",
    "        team_games_played = records[records['team'] == team]['games_played'].values[0]\n",
    "        if (team_games_played == 12) | (team_games_played == 13) | (team == 'Liberty') | (team == 'App State'):\n",
    "            continue\n",
    "        else:\n",
    "            if (team_games_played+game_counts[team]) == 11:\n",
    "                win_df[team] += 1\n",
    "            if (team_games_played+game_counts[team]) == 10:\n",
    "                win_df[team] += 2\n",
    "        \n",
    "    # Calculate average win totals for each team\n",
    "    avg_wins = win_df.mean(axis=0)\n",
    "    \n",
    "    # Calculate average loss totals for each team\n",
    "    avg_losses = loss_df.mean(axis=0)\n",
    "    \n",
    "    # Calculate the mode (most frequent number of wins) for each team\n",
    "    most_common_wins = win_df.mode(axis=0).iloc[0]  # mode() returns a DataFrame, take the first row\n",
    "    \n",
    "    # Calculate the mode (most frequent number of losses) for each team\n",
    "    most_common_losses = loss_df.mode(axis=0).iloc[0]  # mode() returns a DataFrame, take the first row\n",
    "    \n",
    "    # Combine wins and losses into records\n",
    "    most_common_records = pd.DataFrame({\n",
    "        'Wins': most_common_wins,\n",
    "        'Losses': most_common_losses\n",
    "    })\n",
    "    \n",
    "    win_thresholds = {}\n",
    "    for wins in range(13):  # 0 to 12 wins\n",
    "        win_thresholds[f'win_{wins}'] = win_df.apply(lambda x: (x == wins).sum() / len(x), axis=0)\n",
    "\n",
    "    win_thresholds['WIN6%'] = win_df.apply(lambda x: (x >= 6).sum() / len(x), axis=0)\n",
    "    \n",
    "    # Create the win threshold DataFrame\n",
    "    win_thresholds_df = pd.DataFrame(win_thresholds)\n",
    "    win_thresholds_df.insert(0, 'team', win_df.columns)\n",
    "    win_thresholds_df = win_thresholds_df.reset_index(drop=True)\n",
    "    win_thresholds_df['expected_wins'] = list(avg_wins)\n",
    "    win_thresholds_df['expected_loss'] = list(avg_losses)\n",
    "    win_thresholds_df['projected_wins'] = list(most_common_records['Wins'])\n",
    "    win_thresholds_df['projected_losses'] = list(most_common_records['Losses'])\n",
    "\n",
    "    return win_thresholds_df\n",
    "\n",
    "def fetch_logo_image(logo_url):\n",
    "    response = requests.get(logo_url)\n",
    "    return Image.open(BytesIO(response.content))\n",
    "\n",
    "def average_team_distribution(num_simulations, schedules, average, team_name):\n",
    "\n",
    "    def simulate_game_average(win_prob):\n",
    "        random_outcome = np.random.random() * 100  # Generates a number between 0 and 100\n",
    "        if random_outcome < win_prob:\n",
    "            return \"W\"  # Home team wins, Away team loses\n",
    "        else:\n",
    "            return \"L\"  # Away team wins, Home team loses\n",
    "        \n",
    "    def simulate_season_average(schedules, team_name, average):\n",
    "        wins = 0\n",
    "        losses = 0\n",
    "        for _, game in schedules.iterrows():\n",
    "            if game['home_team'] == team_name:\n",
    "                opponent_team = game['away_team']\n",
    "                opponent_pr = game['away_pr']\n",
    "                win_prob = ESCAPE_Win_Prob(average, opponent_pr)\n",
    "\n",
    "                # opponent_elo = game['away_elo']\n",
    "                # win_prob = round((10**((average-opponent_elo) / 400)) / ((10**((average-opponent_elo) / 400)) + 1)*100, 2)\n",
    "            else:\n",
    "                opponent_team = game['home_team']\n",
    "                opponent_pr = game['home_pr']\n",
    "                win_prob = 100 - ESCAPE_Win_Prob(opponent_pr, average)\n",
    "\n",
    "                # opponent_elo = game['home_elo']\n",
    "                # win_prob = 100 - round((10**((opponent_elo-average) / 400)) / ((10**((opponent_elo-average) / 400)) + 1)*100, 2)\n",
    "            \n",
    "            outcome = simulate_game_average(win_prob)\n",
    "            if outcome == \"W\":\n",
    "                wins += 1\n",
    "            else:\n",
    "                losses += 1\n",
    "\n",
    "        return wins, losses\n",
    "        \n",
    "    def monte_carlo_simulation_average(num_simulations, schedules, average, team_name):\n",
    "        \"\"\"Runs a Monte Carlo simulation for an average team over multiple seasons.\"\"\"\n",
    "        win_results = []\n",
    "        loss_results = []\n",
    "\n",
    "        for _ in range(num_simulations):\n",
    "            wins, losses = simulate_season_average(schedules, team_name, average)\n",
    "            win_results.append(wins)\n",
    "            loss_results.append(losses)\n",
    "        \n",
    "        return win_results, loss_results\n",
    "\n",
    "    import statistics\n",
    "    from collections import Counter\n",
    "    def analyze_simulation_average(win_results, loss_results, schedules):\n",
    "        games_played = len(schedules)\n",
    "        if games_played == 11:\n",
    "            win_results = [x + .948 for x in win_results]\n",
    "        elif games_played == 10:\n",
    "            win_results = [x + (2 * .948) for x in win_results]\n",
    "    \n",
    "        avg_wins = statistics.mean(win_results)\n",
    "        avg_loss = statistics.mean(loss_results)\n",
    "        most_common_win = statistics.mode(win_results)\n",
    "        most_common_loss = statistics.mode(loss_results)\n",
    "\n",
    "\n",
    "        win_counts = Counter(win_results)    \n",
    "        total_simulations = len(win_results)\n",
    "        win_percentages = {f\"win_{wins}\": (win_counts[wins] / total_simulations) for wins in range(13)}\n",
    "        win_thresholds = pd.DataFrame([win_percentages])\n",
    "        \n",
    "        # win_thresholds = {}\n",
    "        # for wins in range(13):  # 0 to 12 wins\n",
    "        #     win_thresholds[f'win_{wins}'] = win_df.apply(lambda x: (x == wins).sum() / len(x), axis=0)\n",
    "\n",
    "        win_thresholds['WIN6%'] = win_thresholds.loc[:, 'win_6':'win_12'].sum(axis=1)\n",
    "        win_thresholds['expected_wins'] = avg_wins\n",
    "        win_thresholds['expected_losses'] = avg_loss\n",
    "        win_thresholds['projected_wins'] = most_common_win\n",
    "        win_thresholds['projected_losses'] = most_common_loss\n",
    "\n",
    "        return win_thresholds\n",
    "    \n",
    "    avg_win, avg_loss = monte_carlo_simulation_average(num_simulations, schedules, average, team_name)\n",
    "    win_thresholds = analyze_simulation_average(avg_win, avg_loss,schedules)\n",
    "    return win_thresholds\n",
    "\n",
    "def finish_schedule(win_thresholds_in_season, team_data, logos, team):\n",
    "    # Prepare the figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    fig.patch.set_facecolor('#5fa391')\n",
    "\n",
    "    # Filter for the specific team and get the team logo\n",
    "    wins = win_thresholds_in_season[win_thresholds_in_season['team'] == team]\n",
    "    expected_wins = round(win_thresholds_in_season[win_thresholds_in_season['team'] == team]['expected_wins'].values[0], 1)\n",
    "    expected_losses = round(win_thresholds_in_season[win_thresholds_in_season['team'] == team]['expected_loss'].values[0], 1)\n",
    "    rank = team_data[team_data['team'] == team]['Unnamed: 0'].values[0]\n",
    "    team_url = logos[logos['team'] == team]['logo'].values[0][0]\n",
    "    team_logo = fetch_logo_image(team_url)\n",
    "\n",
    "    # Adjusted extent to center the logo\n",
    "    ax.imshow(team_logo, extent=(0.45, 0.5, 0.85, 0.9))\n",
    "\n",
    "    # Iterate over the 'win_0' to 'win_12' columns and display their values\n",
    "    y_pos = 0.805  # Start the text higher up\n",
    "    for i in range(13):\n",
    "        if i==7:\n",
    "            y_pos=0.81\n",
    "        prob_win = 100 * wins[f'win_{i}'].values[0]\n",
    "        if prob_win == 0:\n",
    "            prob_win = None\n",
    "            win_text = f\"{i} Wins: None\"\n",
    "        else:\n",
    "            win_text = f\"{i} Wins: {prob_win:.2f}%\"\n",
    "        if i<7:\n",
    "            ax.text(0.458, y_pos, win_text, fontsize=13, color='black', horizontalalignment='center')\n",
    "        else:\n",
    "            ax.text(0.492, y_pos, win_text, fontsize=13, color='black', horizontalalignment='center')\n",
    "        y_pos += 0.005\n",
    "\n",
    "    # Display the team name at the center\n",
    "    ax.text(0.475, 0.845, f\"#{rank} {team}\", fontsize=14, fontweight='bold', color='black', horizontalalignment='center')\n",
    "    ax.text(0.475, 0.84, f\"Expected Record: {expected_wins} - {expected_losses}\", color='black', horizontalalignment='center')\n",
    "\n",
    "    # Remove axes for a cleaner look\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Center the plot title\n",
    "    plt.title(\"Simulated Wins\", fontsize=12, fontweight='bold', verticalalignment='center')\n",
    "\n",
    "    # Ensure the layout fits well\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "def simulate_game_conference(home_team, away_team, home_win_prob):\n",
    "    \"\"\"Simulates a single game between two teams based on home win probability.\"\"\"\n",
    "    random_outcome = np.random.random() * 100  # Generates a number between 0 and 100\n",
    "    if random_outcome < home_win_prob:\n",
    "        return home_team, away_team  # Home team wins, Away team loses\n",
    "    else:\n",
    "        return away_team, home_team  # Away team wins, Home team loses\n",
    "\n",
    "def simulate_season_conference(schedules, team_data):\n",
    "    \"\"\"Simulates one season based on current power ratings and schedule.\"\"\"\n",
    "    team_wins = {team: 0 for team in team_data['team'].unique()}  # Initialize win counts\n",
    "    team_losses = {team: 0 for team in team_data['team'].unique()}  # Initialize loss counts\n",
    "\n",
    "    for _, game in schedules.iterrows():\n",
    "        home_team = game['home_team']\n",
    "        away_team = game['away_team']\n",
    "        home_win_prob = game['escape_win_prob']\n",
    "\n",
    "        # Simulate the game outcome\n",
    "        winner, loser = simulate_game_conference(home_team, away_team, home_win_prob)\n",
    "        team_wins[winner] += 1  # Increment win count for the winner\n",
    "        team_losses[loser] += 1  # Increment loss count for the loser\n",
    "\n",
    "    return team_wins, team_losses  # Returns the win and loss counts for all teams at the end of the season\n",
    "\n",
    "def monte_carlo_simulation_conference(num_simulations, schedules, team_data):\n",
    "    \"\"\"Runs a Monte Carlo simulation over multiple seasons.\"\"\"\n",
    "    win_results = []\n",
    "    loss_results = []\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        season_wins, season_losses = simulate_season_conference(schedules, team_data)\n",
    "        win_results.append(season_wins)\n",
    "        loss_results.append(season_losses)\n",
    "    \n",
    "    return win_results, loss_results\n",
    "\n",
    "def analyze_simulation_conference(win_results, loss_results, schedules, records):\n",
    "    \"\"\"Aggregates the results of multiple simulated seasons and calculates win-loss records.\"\"\"\n",
    "    # Convert list of results into DataFrames\n",
    "    win_df = pd.DataFrame(win_results)\n",
    "    loss_df = pd.DataFrame(loss_results)\n",
    "    \n",
    "    # Determine the number of games each team plays\n",
    "    game_counts = schedules.groupby('home_team').size() + schedules.groupby('away_team').size()\n",
    "    game_counts = game_counts.groupby(level=0).sum()  # Combine home and away counts\n",
    "\n",
    "    # Add 1 win for teams with only 11 games\n",
    "    for team in win_df.columns:\n",
    "        win_df[team] += records[records['team'] == team]['conference_wins'].values[0]\n",
    "        loss_df[team] += records[records['team'] == team]['conference_losses'].values[0]\n",
    "\n",
    "    # for team in win_df.columns:\n",
    "    #     team_games_played = records[records['team'] == team]['games_played'].values[0]\n",
    "    #     if (team_games_played+game_counts[team]) == 11:\n",
    "    #         win_df[team] += 1\n",
    "    #     if (team_games_played+game_counts[team]) == 10:\n",
    "    #         win_df[team] += 2\n",
    "        \n",
    "    # Calculate average win totals for each team\n",
    "    avg_wins = win_df.mean(axis=0)\n",
    "    \n",
    "    # Calculate average loss totals for each team\n",
    "    avg_losses = loss_df.mean(axis=0)\n",
    "    \n",
    "    # Calculate the mode (most frequent number of wins) for each team\n",
    "    most_common_wins = win_df.mode(axis=0).iloc[0]  # mode() returns a DataFrame, take the first row\n",
    "    \n",
    "    # Calculate the mode (most frequent number of losses) for each team\n",
    "    most_common_losses = loss_df.mode(axis=0).iloc[0]  # mode() returns a DataFrame, take the first row\n",
    "    \n",
    "    # Combine wins and losses into records\n",
    "    most_common_records = pd.DataFrame({\n",
    "        'Wins': most_common_wins,\n",
    "        'Losses': most_common_losses\n",
    "    })\n",
    "    \n",
    "    win_thresholds = {}\n",
    "    for wins in range(10):  # 0 to 12 wins\n",
    "        win_thresholds[f'win_{wins}'] = win_df.apply(lambda x: (x == wins).sum() / len(x), axis=0)\n",
    "    \n",
    "    # Create the win threshold DataFrame\n",
    "    win_thresholds_df = pd.DataFrame(win_thresholds)\n",
    "    win_thresholds_df.insert(0, 'team', win_df.columns)\n",
    "    win_thresholds_df = win_thresholds_df.reset_index(drop=True)\n",
    "    win_thresholds_df['expected_wins'] = list(avg_wins)\n",
    "    win_thresholds_df['expected_loss'] = list(avg_losses)\n",
    "    win_thresholds_df['projected_wins'] = list(most_common_records['Wins'])\n",
    "    win_thresholds_df['projected_losses'] = list(most_common_records['Losses'])\n",
    "\n",
    "    return win_thresholds_df\n",
    "\n",
    "def plot_matchup(wins_df, all_conference_wins, logos_df, team_data, last_week_data, last_month_data, start_season_data, all_data, schedule_info, records, SOS, SOR, most_deserving, home_team, away_team, neutrality=False):\n",
    "    sns.set(style='whitegrid')\n",
    "    ################################# HELPER FUNCTIONS #################################\n",
    "\n",
    "    def ESCAPE_Win_Prob(home_power_rating, away_power_rating):\n",
    "        return round((1 / (1 + 10 ** ((away_power_rating - (home_power_rating)) / 20.5))) * 100, 2)\n",
    "\n",
    "    def adjust_home_pr(home_win_prob):\n",
    "        return ((home_win_prob - 50) / 50) * 5\n",
    "\n",
    "    def round_to_nearest_half(x):\n",
    "        return np.round(x * 2) / 2   \n",
    "\n",
    "    def find_team_spread(game, team_data, team_name, home_team, away_team, neutral):\n",
    "        home_rating = team_data[team_data['team'] == home_team]['power_rating'].values[0]\n",
    "        away_rating = team_data[team_data['team'] == away_team]['power_rating'].values[0]\n",
    "        home_win_prob = game['home_win_prob']\n",
    "        def adjust_home_pr(home_win_prob):\n",
    "            return ((home_win_prob - 50) / 50) * 5\n",
    "        def round_to_nearest_half(x):\n",
    "            return np.round(x * 2) / 2 \n",
    "        if neutral:\n",
    "            spread = round((home_rating + adjust_home_pr(home_win_prob) - away_rating),1)\n",
    "        else:\n",
    "            spread = round((4.6 + home_rating + adjust_home_pr(home_win_prob) - away_rating),1)\n",
    "        if (home_team == team_name) & (spread > 0):\n",
    "            output = \"-\" + str(spread)\n",
    "        elif (home_team == team_name) & (spread < 0):\n",
    "            output = \"+\" + str(abs(spread))\n",
    "        elif (home_team != team_name) & (spread < 0):\n",
    "            output = str(spread)\n",
    "        elif (spread == 0.0):\n",
    "            output = str(spread)\n",
    "        else:\n",
    "            output = \"+\" + str(spread)\n",
    "\n",
    "        return output, spread\n",
    "    \n",
    "    def add_spreads(schedule_info, team_data, team_name):\n",
    "        # Define a helper function to apply the find_team_spread to each row\n",
    "        def compute_spread(row):\n",
    "            # Extract relevant data from the current row\n",
    "            home_team = row['home_team']\n",
    "            away_team = row['away_team']\n",
    "            neutral = row['neutral']\n",
    "            \n",
    "            # Call the find_team_spread function with this row's data\n",
    "            spread_str, raw_spread = find_team_spread(row, team_data, team_name, home_team, away_team, neutral)\n",
    "            \n",
    "            # Return both values as a tuple, so we can unpack them into two columns\n",
    "            return pd.Series([spread_str, raw_spread])\n",
    "\n",
    "        # Apply the compute_spread function to each row of the DataFrame\n",
    "        schedule_info[['spread', 'raw_spread']] = schedule_info.apply(compute_spread, axis=1)\n",
    "        \n",
    "        return schedule_info\n",
    "\n",
    "    def get_color_wl(w_l):\n",
    "        if w_l == \"W\":\n",
    "            return '#1D4D00'\n",
    "        else:\n",
    "            return '#660000'\n",
    "    \n",
    "    def get_color_future(raw_spread, game_home_team, team):\n",
    "        if (game_home_team == team) and (raw_spread <= 0):\n",
    "            return '#660000'\n",
    "        if (game_home_team == team) and (raw_spread > 0):\n",
    "            return '#1D4D00'\n",
    "        if (game_home_team != team) and (raw_spread <= 0):\n",
    "            return '#1D4D00'\n",
    "        if (game_home_team != team) and (raw_spread > 0):\n",
    "            return '#660000'\n",
    "        \n",
    "    def get_rank_color(number):\n",
    "        \"\"\"\n",
    "        Returns a hex color code based on a number between 1 and 134.\n",
    "        \n",
    "        Parameters:\n",
    "            number (int): A number between 1 and 134.\n",
    "        \n",
    "        Returns:\n",
    "            str: Hex color code corresponding to the input number.\n",
    "        \"\"\"\n",
    "        if not 1 <= number <= 134:\n",
    "            raise ValueError(\"Number must be between 1 and 134\")\n",
    "        \n",
    "        # Define the color gradient points\n",
    "        gradient = [\n",
    "            (1, '#1D4D00'),    # Start green\n",
    "            (35, '#2C5E00'),   # Midpoint green\n",
    "            (67, '#808080'),   # Grey\n",
    "            (105, '#8B0000'),  # Red in the middle\n",
    "            (134, '#660000')   # End dark red\n",
    "        ]\n",
    "        \n",
    "        # Convert hex to RGB\n",
    "        def hex_to_rgb(hex_color):\n",
    "            hex_color = hex_color.lstrip('#')\n",
    "            return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "        \n",
    "        # Convert RGB to hex\n",
    "        def rgb_to_hex(rgb):\n",
    "            return '#' + ''.join(f'{int(c):02X}' for c in rgb)\n",
    "        \n",
    "        # Interpolate between two colors\n",
    "        def interpolate_color(color1, color2, fraction):\n",
    "            return tuple(\n",
    "                color1[i] + (color2[i] - color1[i]) * fraction\n",
    "                for i in range(3)\n",
    "            )\n",
    "        \n",
    "        # Find the range that includes the number\n",
    "        for i in range(len(gradient) - 1):\n",
    "            start, end = gradient[i], gradient[i + 1]\n",
    "            if start[0] <= number <= end[0]:\n",
    "                fraction = (number - start[0]) / (end[0] - start[0])\n",
    "                start_rgb, end_rgb = hex_to_rgb(start[1]), hex_to_rgb(end[1])\n",
    "                interpolated_rgb = interpolate_color(start_rgb, end_rgb, fraction)\n",
    "                return rgb_to_hex(interpolated_rgb)\n",
    "        \n",
    "        # Fallback (should not reach here)\n",
    "        return '#000000'\n",
    "\n",
    "    def grab_team_elo(team):\n",
    "        if postseason == True:\n",
    "            elo_ratings_list = [*ratings_api.get_elo_ratings(year=current_year, team=team)]\n",
    "            elo_ratings_dict = [dict(\n",
    "                team=e.team,\n",
    "                elo=e.elo\n",
    "            ) for e in elo_ratings_list]\n",
    "            elo_ratings = pd.DataFrame(elo_ratings_dict)\n",
    "        else:\n",
    "            elo_ratings_list = [*ratings_api.get_elo_ratings(year=current_year, week=current_week, team=team)]\n",
    "            elo_ratings_dict = [dict(\n",
    "                team=e.team,\n",
    "                elo=e.elo\n",
    "            ) for e in elo_ratings_list]\n",
    "            elo_ratings = pd.DataFrame(elo_ratings_dict)        \n",
    "        return elo_ratings['elo'].values[0]\n",
    "    \n",
    "    ################################# PREPPING DATA NEEDED #################################\n",
    "\n",
    "    entire_schedule = schedule_info.copy()\n",
    "    completed_games = schedule_info[schedule_info['home_points'].notna()]\n",
    "    non_completed_games = schedule_info[schedule_info['home_points'].isna()]\n",
    "    scaler100 = MinMaxScaler(feature_range=(1,100))\n",
    "    all_data['talent_scaled_percentile'] = scaler100.fit_transform(all_data[['talent_scaled']])\n",
    "\n",
    "    home_wins_df = wins_df[wins_df['team'] == home_team]\n",
    "    away_wins_df = wins_df[wins_df['team'] == away_team]\n",
    "    # home_xwins = round(wins_df[wins_df['team'] == home_team]['expected_wins'].values[0], 1)\n",
    "    # away_xwins = round(wins_df[wins_df['team'] == away_team]['expected_wins'].values[0], 1)\n",
    "    # home_xlosses = round(wins_df[wins_df['team'] == home_team]['expected_loss'].values[0], 1)\n",
    "    # away_xlosses = round(wins_df[wins_df['team'] == away_team]['expected_loss'].values[0], 1)\n",
    "    home_rank = team_data[team_data['team'] == home_team].index[0] + 1\n",
    "    away_rank = team_data[team_data['team'] == away_team].index[0] + 1\n",
    "    home_win_6 = round(100 * home_wins_df['WIN6%'].values[0], 1)\n",
    "    away_win_6 = round(100 * away_wins_df['WIN6%'].values[0], 1)\n",
    "    home_last_week = last_week_data[last_week_data['team'] == home_team]['power_rating'].values[0]\n",
    "    away_last_week = last_week_data[last_week_data['team'] == away_team]['power_rating'].values[0]\n",
    "    home_last_month = last_month_data[last_month_data['team'] == home_team]['power_rating'].values[0]\n",
    "    away_last_month = last_month_data[last_month_data['team'] == away_team]['power_rating'].values[0]\n",
    "    home_start_rating = start_season_data[start_season_data['team'] == home_team]['power_rating'].values[0]\n",
    "    away_start_rating = start_season_data[start_season_data['team'] == away_team]['power_rating'].values[0]\n",
    "    home_wins = records[records['team'] == home_team]['wins'].values[0]\n",
    "    home_losses = records[records['team'] == home_team]['losses'].values[0]\n",
    "    home_conference_wins = records[records['team'] == home_team]['conference_wins'].values[0]\n",
    "    home_conference_losses = records[records['team'] == home_team]['conference_losses'].values[0]\n",
    "    away_wins = records[records['team'] == away_team]['wins'].values[0]\n",
    "    away_losses = records[records['team'] == away_team]['losses'].values[0]\n",
    "    away_conference_wins = records[records['team'] == away_team]['conference_wins'].values[0]\n",
    "    away_conference_losses = records[records['team'] == away_team]['conference_losses'].values[0]\n",
    "\n",
    "    average_pr = team_data['power_rating'].mean()\n",
    "    home_completed_games = completed_games[(completed_games['home_team'] == home_team) | (completed_games['away_team'] == home_team)]\n",
    "    away_completed_games = completed_games[(completed_games['home_team'] == away_team) | (completed_games['away_team'] == away_team)]\n",
    "    home_completed_games['team_win_prob'] = np.where(home_completed_games['home_team'] == home_team, \n",
    "                                    home_completed_games['escape_win_prob'], \n",
    "                                    100 - home_completed_games['escape_win_prob'])\n",
    "    away_completed_games['team_win_prob'] = np.where(away_completed_games['home_team'] == away_team, \n",
    "                                    away_completed_games['escape_win_prob'], \n",
    "                                    100 - away_completed_games['escape_win_prob'])\n",
    "    home_completed_games['avg_win_prob'] = np.where(home_completed_games['home_team'] == home_team, \n",
    "                                    ESCAPE_Win_Prob(average_pr, home_completed_games['away_pr']), \n",
    "                                    100 - ESCAPE_Win_Prob(home_completed_games['home_pr'], average_pr))\n",
    "    away_completed_games['avg_win_prob'] = np.where(away_completed_games['home_team'] == away_team, \n",
    "                                    ESCAPE_Win_Prob(average_pr, away_completed_games['away_pr']), \n",
    "                                    100 - ESCAPE_Win_Prob(away_completed_games['home_pr'], average_pr))\n",
    "    home_avg_xwins = round(sum(home_completed_games['avg_win_prob']) / 100, 1)\n",
    "    home_avg_xlosses = round(len(home_completed_games) - home_avg_xwins, 1)\n",
    "    away_avg_xwins = round(sum(away_completed_games['avg_win_prob']) / 100, 1)\n",
    "    away_avg_xlosses = round(len(away_completed_games) - away_avg_xwins, 1)\n",
    "    home_completed_xwins = round(sum(home_completed_games['team_win_prob']) / 100, 1)\n",
    "    away_completed_xwins = round(sum(away_completed_games['team_win_prob']) / 100, 1)\n",
    "    home_completed_xlosses = round(len(home_completed_games) - home_completed_xwins, 1)\n",
    "    away_completed_xlosses = round(len(away_completed_games) - away_completed_xwins, 1)\n",
    "    home_games_played = home_wins + home_losses\n",
    "    away_games_played = away_wins + away_losses\n",
    "    if len(home_completed_games) != home_games_played:\n",
    "        home_completed_xwins = home_completed_xwins + 1\n",
    "        home_avg_xwins = home_avg_xwins + 1\n",
    "    if len(away_completed_games) != away_games_played:\n",
    "        away_completed_xwins = away_completed_xwins + 1\n",
    "        away_avg_xwins = away_avg_xwins + 1\n",
    "    home_win_out = home_wins + 12 - home_games_played\n",
    "    away_win_out = away_wins + 12 - away_games_played\n",
    "    home_win_out_percent = round(home_wins_df[f'win_{home_win_out}'].values[0] * 100, 1)\n",
    "    away_win_out_percent = round(away_wins_df[f'win_{away_win_out}'].values[0] * 100, 1)\n",
    "    home_md = most_deserving[most_deserving['team'] == home_team]['Performance'].values[0]\n",
    "    away_md = most_deserving[most_deserving['team'] == away_team]['Performance'].values[0]\n",
    "    home_sor = SOR[SOR['team'] == home_team]['SOR'].values[0]\n",
    "    home_sos = SOS[SOS['team'] == home_team]['SOS'].values[0]\n",
    "    away_sor = SOR[SOR['team'] == away_team]['SOR'].values[0]\n",
    "    away_sos = SOS[SOS['team'] == away_team]['SOS'].values[0]\n",
    "    home_non_completed_games = non_completed_games[(non_completed_games['home_team'] == home_team) | (non_completed_games['away_team'] == home_team)].reset_index(drop = True)\n",
    "    away_non_completed_games = non_completed_games[(non_completed_games['home_team'] == away_team) | (non_completed_games['away_team'] == away_team)].reset_index(drop = True)\n",
    "    home_elo = grab_team_elo(home_team)\n",
    "    away_elo = grab_team_elo(away_team)\n",
    "\n",
    "    cmap = LinearSegmentedColormap.from_list('dark_gradient_orange', ['#660000', '#8B0000', '#808080', '#2C5E00', '#1D4D00'], N=100)\n",
    "    def get_color(value, vmin=0, vmax=100):\n",
    "        norm_value = (value - vmin) / (vmax - vmin)  # Normalize the value between 0 and 1\n",
    "        return cmap(norm_value)  # Get the color from the colormap\n",
    "    \n",
    "    xwin = LinearSegmentedColormap.from_list('dark_gradient_pattern', ['#660000', '#8B0000', '#808080', '#2C5E00', '#1D4D00'], N=100)\n",
    "\n",
    "    # Function to get color based on value with specified boundaries\n",
    "    def get_gradient_color(value, vmin=-1.5, vmax=1.5):\n",
    "        if value <= vmin:\n",
    "            return '#660000'  # Lighter dark red for <= -1.5\n",
    "        elif value >= vmax:\n",
    "            return '#1D4D00'  # Dark green for >= 1.5\n",
    "        else:\n",
    "            norm_value = (value - vmin) / (vmax - vmin)  # Normalize value between vmin and vmax\n",
    "            return xwin(norm_value)  # Get color from colormap for intermediate values\n",
    "\n",
    "    if (len(home_non_completed_games) != 0):\n",
    "        home_non_completed_games = add_spreads(home_non_completed_games, team_data, home_team)\n",
    "    if (len(away_non_completed_games) != 0):\n",
    "        away_non_completed_games = add_spreads(away_non_completed_games, team_data, away_team)\n",
    "\n",
    "    home_power_rating = round(team_data[team_data['team'] == home_team]['power_rating'].values[0], 2)\n",
    "    home_talent_scaled = round(all_data[all_data['team'] == home_team]['talent_scaled_percentile'].values[0], 2)\n",
    "    home_offense_success = round(all_data[all_data['team'] == home_team]['offense_success_scaled'].values[0], 2)\n",
    "    home_defense_success = round(all_data[all_data['team'] == home_team]['defense_success_scaled'].values[0], 2)\n",
    "    home_offense_explosive = round(all_data[all_data['team'] == home_team]['offense_explosive'].values[0], 2)\n",
    "    home_defense_explosive = round(all_data[all_data['team'] == home_team]['defense_explosive'].values[0], 2)\n",
    "    home_turnovers = round(all_data[all_data['team'] == home_team]['total_turnovers_scaled'].values[0], 2)\n",
    "    home_penalties = round(all_data[all_data['team'] == home_team]['penalties_scaled'].values[0], 2)\n",
    "    home_offensive = all_data[all_data['team'] == home_team]['offensive_rank'].values[0]\n",
    "    home_defensive = all_data[all_data['team'] == home_team]['defensive_rank'].values[0]\n",
    "    home_stm = int(all_data[all_data['team'] == home_team]['STM_rank'].values[0])\n",
    "    home_pbr = int(all_data[all_data['team'] == home_team]['PBR_rank'].values[0])\n",
    "    home_dce = int(all_data[all_data['team'] == home_team]['DCE_rank'].values[0])\n",
    "    home_dde = int(all_data[all_data['team'] == home_team]['DDE_rank'].values[0])\n",
    "    home_talent_rank = int(all_data[all_data['team'] == home_team]['talent_scaled_rank'].values[0])\n",
    "    home_offense_success_rank = int(all_data[all_data['team'] == home_team]['offense_success_rank'].values[0])\n",
    "    home_defense_success_rank = int(all_data[all_data['team'] == home_team]['defense_success_rank'].values[0])\n",
    "    home_offense_explosive_rank = int(all_data[all_data['team'] == home_team]['offense_explosive_rank'].values[0])\n",
    "    home_defense_explosive_rank = int(all_data[all_data['team'] == home_team]['defense_explosive_rank'].values[0])\n",
    "    home_turnover_rank = int(all_data[all_data['team'] == home_team]['total_turnovers_rank'].values[0])\n",
    "    home_penalties_rank = int(all_data[all_data['team'] == home_team]['penalties_rank'].values[0])\n",
    "\n",
    "    away_power_rating = round(team_data[team_data['team'] == away_team]['power_rating'].values[0], 2)\n",
    "    away_talent_scaled = round(all_data[all_data['team'] == away_team]['talent_scaled_percentile'].values[0], 2)\n",
    "    away_offense_success = round(all_data[all_data['team'] == away_team]['offense_success_scaled'].values[0], 2)\n",
    "    away_defense_success = round(all_data[all_data['team'] == away_team]['defense_success_scaled'].values[0], 2)\n",
    "    away_offense_explosive = round(all_data[all_data['team'] == away_team]['offense_explosive'].values[0], 2)\n",
    "    away_defense_explosive = round(all_data[all_data['team'] == away_team]['defense_explosive'].values[0], 2)\n",
    "    away_turnovers = round(all_data[all_data['team'] == away_team]['total_turnovers_scaled'].values[0], 2)\n",
    "    away_penalties = round(all_data[all_data['team'] == away_team]['penalties_scaled'].values[0], 2)\n",
    "    away_offensive = all_data[all_data['team'] == away_team]['offensive_rank'].values[0]\n",
    "    away_defensive = all_data[all_data['team'] == away_team]['defensive_rank'].values[0]\n",
    "    away_stm = int(all_data[all_data['team'] == away_team]['STM_rank'].values[0])\n",
    "    away_pbr = int(all_data[all_data['team'] == away_team]['PBR_rank'].values[0])\n",
    "    away_dce = int(all_data[all_data['team'] == away_team]['DCE_rank'].values[0])\n",
    "    away_dde = int(all_data[all_data['team'] == away_team]['DDE_rank'].values[0])\n",
    "    away_talent_rank = int(all_data[all_data['team'] == away_team]['talent_scaled_rank'].values[0])\n",
    "    away_offense_success_rank = int(all_data[all_data['team'] == away_team]['offense_success_rank'].values[0])\n",
    "    away_defense_success_rank = int(all_data[all_data['team'] == away_team]['defense_success_rank'].values[0])\n",
    "    away_offense_explosive_rank = int(all_data[all_data['team'] == away_team]['offense_explosive_rank'].values[0])\n",
    "    away_defense_explosive_rank = int(all_data[all_data['team'] == away_team]['defense_explosive_rank'].values[0])\n",
    "    away_turnover_rank = int(all_data[all_data['team'] == away_team]['total_turnovers_rank'].values[0])\n",
    "    away_penalties_rank = int(all_data[all_data['team'] == away_team]['penalties_rank'].values[0])\n",
    "\n",
    "    home_win_prob = round((10**((home_elo - away_elo) / 400)) / ((10**((home_elo - away_elo) / 400)) + 1)*100,2)\n",
    "    escape_home_prob = ESCAPE_Win_Prob(home_power_rating, away_power_rating)\n",
    "    spread = (4.6 + home_power_rating + adjust_home_pr(home_win_prob) - away_power_rating).round(1)\n",
    "    if neutrality:\n",
    "        spread = (spread - 4.6).round(1)\n",
    "    spread = round(spread,1)\n",
    "    if (spread) <= 0:\n",
    "        formatted_spread = (f'{away_team} {spread}')\n",
    "        game_win_prob = round(100 - escape_home_prob,2)\n",
    "    elif (spread) > 0:\n",
    "        formatted_spread = (f'{home_team} -{spread}')\n",
    "        game_win_prob = escape_home_prob\n",
    "\n",
    "    ################################# PLOTTING LOGOS #################################\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, figsize=(12, 10),dpi=125)\n",
    "    fig_width, fig_height = fig.get_size_inches()\n",
    "    fig.patch.set_facecolor('#5fa391')  # Set figure background color\n",
    "    ax.set_facecolor('#5fa391') \n",
    "    ax.axis('off')\n",
    "    home_logo_url = logos_df[logos_df['team'] == home_team]['logo'].values[0][0]\n",
    "    home_team_color = logos_df[logos_df['team'] == home_team]['color'].values[0]   \n",
    "    away_logo_url = logos_df[logos_df['team'] == away_team]['logo'].values[0][0]\n",
    "    away_team_color = logos_df[logos_df['team'] == away_team]['color'].values[0]   \n",
    "    \n",
    "    response = requests.get(home_logo_url)\n",
    "    logo_img = Image.open(BytesIO(response.content))\n",
    "    img_ax = fig.add_axes([-.1,-.05,0.4,0.4])\n",
    "    img_ax.imshow(logo_img)\n",
    "    img_ax.axis('off')\n",
    "\n",
    "    response = requests.get(away_logo_url)\n",
    "    logo_img = Image.open(BytesIO(response.content))\n",
    "    img_ax = fig.add_axes([1.,-.05,0.4,0.4])\n",
    "    img_ax.imshow(logo_img)\n",
    "    img_ax.axis('off')\n",
    "\n",
    "    ################################# SCHEDULE INFO ################################# \n",
    "\n",
    "    home_j = 0.29\n",
    "    plt.text(0.65, .32, \"FCS Games Not Included\", fontsize = 16, va='top', ha='center', transform = ax.transAxes, fontweight='bold')\n",
    "    for i, game in home_completed_games.iterrows():\n",
    "        neutral = game['neutral']\n",
    "        plt.text(0.295, home_j, f\"{game['week']}\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "        if game['home_team'] == home_team:\n",
    "            if game['home_points'] > game['away_points']:\n",
    "                w_L = 'W'\n",
    "            else:\n",
    "                w_L = 'L'\n",
    "        else:\n",
    "            if game['home_points'] > game['away_points']:\n",
    "                w_L = 'L'\n",
    "            else:\n",
    "                w_L = 'W'\n",
    "        if neutral:\n",
    "            if game['home_team'] == home_team:\n",
    "                home_opponent_rank = team_data[team_data['team'] == game['away_team']].index[0] + 1\n",
    "                plt.text(0.325, home_j, f\"(N)\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "                plt.text(0.355, home_j, f\"{game['away_team']} (#{home_opponent_rank})\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "            else:\n",
    "                home_opponent_rank = team_data[team_data['team'] == game['home_team']].index[0] + 1\n",
    "                plt.text(0.325, home_j, f\"(N)\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "                plt.text(0.355, home_j, f\"{game['home_team']} (#{home_opponent_rank})\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "        elif game['home_team'] == home_team:\n",
    "            home_opponent_rank = team_data[team_data['team'] == game['away_team']].index[0] + 1\n",
    "            plt.text(0.325, home_j, f\"vs\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "            plt.text(0.355, home_j, f\"{game['away_team']} (#{home_opponent_rank})\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "        else:\n",
    "            home_opponent_rank = team_data[team_data['team'] == game['home_team']].index[0] + 1\n",
    "            plt.text(0.325, home_j, f\"@\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "            plt.text(0.355, home_j, f\"{game['home_team']} (#{home_opponent_rank})\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "        if game['home_points'] > game['away_points']:\n",
    "            plt.text(0.61, home_j, f\"{int(game['home_points'])}-{int(game['away_points'])}\", fontsize = 16, va='top', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "        else:\n",
    "            plt.text(0.61, home_j, f\"{int(game['away_points'])}-{int(game['home_points'])}\", fontsize = 16, va='top', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "        home_j -= 0.03\n",
    "    if len(home_non_completed_games != 0):\n",
    "        for i, game in home_non_completed_games.iterrows():\n",
    "            game_home_team = game['home_team']\n",
    "            neutral = game['neutral']\n",
    "            plt.text(0.295, home_j, f\"{game['week']}\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "            spread = game['spread']\n",
    "            raw_spread = game['raw_spread']\n",
    "            if neutral:\n",
    "                if game['home_team'] == home_team:\n",
    "                    home_opponent_rank = team_data[team_data['team'] == game['away_team']].index[0] + 1\n",
    "                    plt.text(0.325, home_j, f\"(N)\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "                    plt.text(0.355, home_j, f\"{game['away_team']} (#{home_opponent_rank})\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "                else:\n",
    "                    home_opponent_rank = team_data[team_data['team'] == game['home_team']].index[0] + 1\n",
    "                    plt.text(0.325, home_j, f\"(N)\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "                    plt.text(0.355, home_j, f\"{game['home_team']} (#{home_opponent_rank})\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "            elif game['home_team'] == home_team:\n",
    "                home_opponent_rank = team_data[team_data['team'] == game['away_team']].index[0] + 1\n",
    "                plt.text(0.325, home_j, f\"vs\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "                plt.text(0.355, home_j, f\"{game['away_team']} (#{home_opponent_rank})\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "            else:\n",
    "                home_opponent_rank = team_data[team_data['team'] == game['home_team']].index[0] + 1\n",
    "                plt.text(0.325, home_j, f\"@\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "                plt.text(0.355, home_j, f\"{game['home_team']} (#{home_opponent_rank})\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "            plt.text(0.61, home_j, f\"{spread}\", fontsize=16, va='top', ha='left', transform=ax.transAxes, fontweight='bold', color=get_color_future(raw_spread, game_home_team, home_team))\n",
    "\n",
    "            home_j -= 0.03\n",
    "\n",
    "    away_j = 0.29\n",
    "    for i, game in away_completed_games.iterrows():\n",
    "        neutral = game['neutral']\n",
    "        plt.text(0.675, away_j, f\"{game['week']}\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "        if game['home_team'] == away_team:\n",
    "            if game['home_points'] > game['away_points']:\n",
    "                w_L = 'W'\n",
    "            else:\n",
    "                w_L = 'L'\n",
    "        else:\n",
    "            if game['home_points'] > game['away_points']:\n",
    "                w_L = 'L'\n",
    "            else:\n",
    "                w_L = 'W'\n",
    "        if neutral:\n",
    "            if game['home_team'] == away_team:\n",
    "                away_opponent_rank = team_data[team_data['team'] == game['away_team']].index[0] + 1\n",
    "                plt.text(0.705, away_j, f\"(N)\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "                plt.text(0.735, away_j, f\"{game['away_team']} (#{away_opponent_rank})\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "            else:\n",
    "                away_opponent_rank = team_data[team_data['team'] == game['home_team']].index[0] + 1\n",
    "                plt.text(0.705, away_j, f\"(N)\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "                plt.text(0.735, away_j, f\"{game['home_team']} (#{away_opponent_rank})\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "        elif game['home_team'] == away_team:\n",
    "            away_opponent_rank = team_data[team_data['team'] == game['away_team']].index[0] + 1\n",
    "            plt.text(0.705, away_j, f\"vs\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "            plt.text(0.735, away_j, f\"{game['away_team']} (#{away_opponent_rank})\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "        else:\n",
    "            away_opponent_rank = team_data[team_data['team'] == game['home_team']].index[0] + 1\n",
    "            plt.text(0.705, away_j, f\"@\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "            plt.text(0.735, away_j, f\"{game['home_team']} (#{away_opponent_rank})\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "        if game['home_points'] > game['away_points']:\n",
    "            plt.text(0.99, away_j, f\"{int(game['home_points'])}-{int(game['away_points'])}\", fontsize = 16, va='top', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "        else:\n",
    "            plt.text(0.99, away_j, f\"{int(game['away_points'])}-{int(game['home_points'])}\", fontsize = 16, va='top', transform=ax.transAxes, color = get_color_wl(w_L), fontweight='bold')\n",
    "        away_j -= 0.03\n",
    "\n",
    "    if (len(away_non_completed_games) != 0):\n",
    "        for i, game in away_non_completed_games.iterrows():\n",
    "            neutral = game['neutral']\n",
    "            game_home_team = game['home_team']\n",
    "            plt.text(0.675, away_j, f\"{game['week']}\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "            spread = game['spread']\n",
    "            raw_spread = game['raw_spread']\n",
    "            if neutral:\n",
    "                if game['home_team'] == away_team:\n",
    "                    away_opponent_rank = team_data[team_data['team'] == game['away_team']].index[0] + 1\n",
    "                    plt.text(0.705, away_j, f\"(N)\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "                    plt.text(0.735, away_j, f\"{game['away_team']} (#{away_opponent_rank})\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "                else:\n",
    "                    away_opponent_rank = team_data[team_data['team'] == game['home_team']].index[0] + 1\n",
    "                    plt.text(0.705, away_j, f\"(N)\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "                    plt.text(0.735, away_j, f\"{game['home_team']} (#{away_opponent_rank})\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "            elif game['home_team'] == away_team:\n",
    "                away_opponent_rank = team_data[team_data['team'] == game['away_team']].index[0] + 1\n",
    "                plt.text(0.705, away_j, f\"vs\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "                plt.text(0.735, away_j, f\"{game['away_team']} (#{away_opponent_rank})\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "            else:\n",
    "                away_opponent_rank = team_data[team_data['team'] == game['home_team']].index[0] + 1\n",
    "                plt.text(0.705, away_j, f\"@\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "                plt.text(0.735, away_j, f\"{game['home_team']} (#{away_opponent_rank})\", fontsize = 16, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "            plt.text(0.99, away_j, f\"{spread}\", fontsize=16, va='top', ha='left', transform=ax.transAxes, fontweight='bold', color=get_color_future(raw_spread, game_home_team, away_team))\n",
    "\n",
    "            away_j -= 0.03\n",
    "\n",
    "    plt.text(-0.075, 0.99, f\"Power Rating: {home_power_rating} (#{home_rank})\", fontsize = 25, va='top', ha='left', transform=ax.transAxes, fontweight='bold', color=get_rank_color(home_rank))\n",
    "    plt.text(-0.075, 0.94, f\"Current Record: {home_wins} - {home_losses} ({home_conference_wins} - {home_conference_losses})\", fontsize = 25, va='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "    plt.text(-0.075, 0.89, f\"Current xRecord: {home_completed_xwins} - {home_completed_xlosses}\", fontsize = 25, va='top', ha='left', transform=ax.transAxes)\n",
    "    # plt.text(-0.075, 0.84, f\"Win 6%: {home_win_6}%\", fontsize = 25, va='top', ha='left', transform=ax.transAxes)\n",
    "    # plt.text(-0.075, 0.79, f\"Win Out%: {home_win_out_percent}%\", fontsize = 25, va='top', ha='left', transform=ax.transAxes)\n",
    "    plt.text(-0.075, 0.79, \"Percentile (Rank)\", fontsize=25, verticalalignment='top', ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "    plt.text(-0.075, 0.74, f\"Team Talent: {home_talent_scaled} (#{home_talent_rank})\", fontsize=25, verticalalignment='top', ha='left', transform=ax.transAxes, color=get_color(home_talent_scaled), fontweight='bold')\n",
    "    plt.text(-0.075, 0.69, f\"Offense Success: {home_offense_success} (#{home_offense_success_rank})\", fontsize=25, verticalalignment='top', ha='left', transform=ax.transAxes, color=get_color(home_offense_success), fontweight='bold')\n",
    "    plt.text(-0.075, 0.64, f\"Offense Explosiveness: {home_offense_explosive} (#{home_offense_explosive_rank})\", fontsize=25, verticalalignment='top', ha='left', transform=ax.transAxes, color=get_color(home_offense_explosive), fontweight='bold')\n",
    "    plt.text(-0.075, 0.59, f\"Defense Success: {home_defense_success} (#{home_defense_success_rank})\", fontsize=25, verticalalignment='top', ha='left', transform=ax.transAxes, color=get_color(home_defense_success), fontweight='bold')\n",
    "    plt.text(-0.075, 0.54, f\"Defense Explosiveness: {home_defense_explosive} (#{home_defense_explosive_rank})\", fontsize=25, verticalalignment='top', ha='left', transform=ax.transAxes, color=get_color(home_defense_explosive), fontweight='bold')\n",
    "    plt.text(-0.075, 0.49, f\"Turnovers: {home_turnovers} (#{home_turnover_rank})\", fontsize=25, verticalalignment='top', ha='left', transform=ax.transAxes, color=get_color(home_turnovers), fontweight='bold')\n",
    "    plt.text(-0.075, 0.44, f\"Penalties: {home_penalties} (#{home_penalties_rank})\", fontsize=25, verticalalignment='top', ha='left', transform=ax.transAxes, color=get_color(home_penalties), fontweight='bold')\n",
    "    plt.text(-0.075, 0.39, f\"SOS: #{home_sos}\", fontsize=25, verticalalignment='top', ha='left', transform=ax.transAxes, fontweight='bold', color=get_rank_color(home_sos))\n",
    "    plt.text(0.15, 0.39, f\"SOR: #{home_sor}\", fontsize=25, verticalalignment='top', ha='left', transform=ax.transAxes, fontweight='bold', color=get_rank_color(home_sor))\n",
    "\n",
    "    plt.text(0.45, 0.69, f\"MD: #{home_md}\", fontsize = 25, va='top', ha='left', transform=ax.transAxes, fontweight='bold', color=get_rank_color(home_md))\n",
    "    plt.text(0.45, 0.64, f\"OFF: #{home_offensive}\", fontsize = 25, va='top', ha='left', transform=ax.transAxes, fontweight='bold', color=get_rank_color(home_offensive))\n",
    "    plt.text(0.45, 0.59, f\"DEF: #{home_defensive}\", fontsize = 25, va='top', ha='left', transform=ax.transAxes, fontweight='bold', color=get_rank_color(home_defensive))\n",
    "    plt.text(0.45, 0.54, f\"ST: #{home_stm}\", fontsize = 25, va='top', ha='left', transform=ax.transAxes, fontweight='bold', color=get_rank_color(home_stm))\n",
    "    plt.text(0.45, 0.49, f\"PBR: #{home_pbr}\", fontsize = 25, va='top', ha='left', transform=ax.transAxes, fontweight='bold', color=get_rank_color(home_pbr))\n",
    "    plt.text(0.45, 0.44, f\"DCE: #{home_dce}\", fontsize = 25, va='top', ha='left', transform=ax.transAxes, fontweight='bold', color=get_rank_color(home_dce))\n",
    "    plt.text(0.45, 0.39, f\"DDE: #{home_dde}\", fontsize = 25, va='top', ha='left', transform=ax.transAxes, fontweight='bold', color=get_rank_color(home_dde))\n",
    "\n",
    "\n",
    "    plt.text(1.38, 0.99, f\"Power Rating: {away_power_rating} (#{away_rank})\", fontsize = 25, va='top', ha='right', transform=ax.transAxes, fontweight='bold', color=get_rank_color(away_rank))\n",
    "    plt.text(1.38, 0.94, f\"Current Record: {away_wins} - {away_losses} ({away_conference_wins} - {away_conference_losses})\", fontsize = 25, va='top', ha='right', transform=ax.transAxes, fontweight='bold')\n",
    "    plt.text(1.38, 0.89, f\"Current xRecord: {away_completed_xwins} - {away_completed_xlosses}\", fontsize = 25, va='top', ha='right', transform=ax.transAxes)\n",
    "    # plt.text(1.38, 0.84, f\"Win 6%: {away_win_6}%\", fontsize = 25, va='top', ha='right', transform=ax.transAxes)\n",
    "    # plt.text(1.38, 0.79, f\"Win Out%: {away_win_out_percent}%\", fontsize = 25, va='top', ha='right', transform=ax.transAxes)\n",
    "    plt.text(1.38, 0.79, \"Percentile (Rank)\", fontsize=25, verticalalignment='top', ha='right', transform=ax.transAxes, fontweight='bold')\n",
    "    plt.text(1.38, 0.74, f\"Team Talent: {away_talent_scaled} (#{away_talent_rank})\", fontsize=25, verticalalignment='top', ha='right', transform=ax.transAxes, color=get_color(away_talent_scaled), fontweight='bold')\n",
    "    plt.text(1.38, 0.69, f\"Offense Success: {away_offense_success} (#{away_offense_success_rank})\", fontsize=25, verticalalignment='top', ha='right', transform=ax.transAxes, color=get_color(away_offense_success), fontweight='bold')\n",
    "    plt.text(1.38, 0.64, f\"Offense Explosiveness: {away_offense_explosive} (#{away_offense_explosive_rank})\", fontsize=25, verticalalignment='top', ha='right', transform=ax.transAxes, color=get_color(away_offense_explosive), fontweight='bold')\n",
    "    plt.text(1.38, 0.59, f\"Defense Success: {away_defense_success} (#{away_defense_success_rank})\", fontsize=25, verticalalignment='top', ha='right', transform=ax.transAxes, color=get_color(away_defense_success), fontweight='bold')\n",
    "    plt.text(1.38, 0.54, f\"Defense Explosiveness: {away_defense_explosive} (#{away_defense_explosive_rank})\", fontsize=25, verticalalignment='top', ha='right', transform=ax.transAxes, color=get_color(away_defense_explosive), fontweight='bold')\n",
    "    plt.text(1.38, 0.49, f\"Turnovers: {away_turnovers} (#{away_turnover_rank})\", fontsize=25, verticalalignment='top', ha='right', transform=ax.transAxes, color=get_color(away_turnovers), fontweight='bold')\n",
    "    plt.text(1.38, 0.44, f\"Penalties: {away_penalties} (#{away_penalties_rank})\", fontsize=25, verticalalignment='top', ha='right', transform=ax.transAxes, color=get_color(away_penalties), fontweight='bold')\n",
    "    plt.text(1.16, 0.39, f\"SOS: #{away_sos}\", fontsize=25, verticalalignment='top', ha='right', transform=ax.transAxes, fontweight='bold', color=get_rank_color(away_sos))\n",
    "    plt.text(1.38, 0.39, f\"SOR: #{away_sor}\", fontsize=25, verticalalignment='top', ha='right', transform=ax.transAxes, fontweight='bold', color=get_rank_color(away_sor))\n",
    "\n",
    "    plt.text(0.85, 0.69, f\"MD: #{away_md}\", fontsize = 25, va='top', ha='right', transform=ax.transAxes, fontweight='bold', color=get_rank_color(away_md))\n",
    "    plt.text(0.85, 0.64, f\"OFF: #{away_offensive}\", fontsize = 25, va='top', ha='right', transform=ax.transAxes, fontweight='bold', color=get_rank_color(away_offensive))\n",
    "    plt.text(0.85, 0.59, f\"DEF: #{away_defensive}\", fontsize = 25, va='top', ha='right', transform=ax.transAxes, fontweight='bold', color=get_rank_color(away_defensive))\n",
    "    plt.text(0.85, 0.54, f\"ST: #{away_stm}\", fontsize = 25, va='top', ha='right', transform=ax.transAxes, fontweight='bold', color=get_rank_color(away_stm))\n",
    "    plt.text(0.85, 0.49, f\"PBR: #{away_pbr}\", fontsize = 25, va='top', ha='right', transform=ax.transAxes, fontweight='bold', color=get_rank_color(away_pbr))\n",
    "    plt.text(0.85, 0.44, f\"DCE: #{away_dce}\", fontsize = 25, va='top', ha='right', transform=ax.transAxes, fontweight='bold', color=get_rank_color(away_dce))\n",
    "    plt.text(0.85, 0.39, f\"DDE: #{away_dde}\", fontsize = 25, va='top', ha='right', transform=ax.transAxes, fontweight='bold', color=get_rank_color(away_dde))\n",
    "\n",
    "    plt.text(0.65, 0.90, f\"ESCAPE Ratings\", fontsize = 35, va='top', ha='center', transform=ax.transAxes, fontweight='bold')\n",
    "    plt.text(0.65, 0.84, f\"{home_team} vs. {away_team}\", fontsize = 35, va='top', ha='center', transform=ax.transAxes, fontweight='bold')\n",
    "    plt.text(0.65, 0.78, f\"{formatted_spread}\", fontsize = 25, va='top', ha='center', transform=ax.transAxes, fontweight='bold')\n",
    "    plt.text(0.65, 0.73, f\"Win Prob: {game_win_prob}%\", fontsize = 25, va='top', ha='center', transform=ax.transAxes, fontweight='bold')\n",
    "    plt.text(0.65, 0.35, \"Team Stats are Percentile Based\", fontsize = 16, va='top', ha='center', transform=ax.transAxes, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_win_probabilities(wins_df, all_conference_wins, logos_df, team_data, last_week_data, last_month_data, start_season_data, all_data, schedule_info, records, SOS, SOR, team_name, branding=True):\n",
    "    # Set plot style\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    ################################# PREPPING DATA NEEDED #################################\n",
    "    entire_schedule = schedule_info.copy()\n",
    "    completed_games = schedule_info[schedule_info['home_points'].notna()]\n",
    "    schedule_info = schedule_info[schedule_info['home_points'].isna()]\n",
    "\n",
    "    wins_df = wins_df[wins_df['team'] == team_name]\n",
    "    expected_wins = round(wins_df[wins_df['team'] == team_name]['expected_wins'].values[0], 1)\n",
    "    expected_losses = round(wins_df[wins_df['team'] == team_name]['expected_loss'].values[0], 1)\n",
    "    rank = team_data[team_data['team'] == team_name].index[0] + 1\n",
    "    transposed_data = wins_df.transpose()[1:14].reset_index().reset_index()\n",
    "    transposed_data.columns.values[2] = 'prob'\n",
    "    win_6 = round(100 * wins_df['WIN6%'].values[0], 1)\n",
    "    last_week_rating = last_week_data[last_week_data['team'] == team_name]['power_rating'].values[0]\n",
    "    last_month_rating = last_month_data[last_month_data['team'] == team_name]['power_rating'].values[0]\n",
    "    start_season_rating = start_season_data[start_season_data['team'] == team_name]['power_rating'].values[0]\n",
    "\n",
    "    wins = records[records['team'] == team_name]['wins'].values[0]\n",
    "    losses = records[records['team'] == team_name]['losses'].values[0]\n",
    "\n",
    "    team_completed_games = completed_games[(completed_games['home_team'] == team_name) | (completed_games['away_team'] == team_name)]\n",
    "    team_completed_games['team_win_prob'] = np.where(team_completed_games['home_team'] == team_name, \n",
    "                                    team_completed_games['escape_win_prob'], \n",
    "                                    100 - team_completed_games['escape_win_prob'])\n",
    "    completed_expected_wins = round(sum(team_completed_games['team_win_prob']) / 100, 1)\n",
    "    completed_expected_losses = round(len(team_completed_games) - completed_expected_wins, 1)\n",
    "    games_played = wins + losses\n",
    "    if len(team_completed_games) != games_played:\n",
    "        completed_expected_wins = completed_expected_wins + 1\n",
    "\n",
    "    win_out = wins + 12 - games_played\n",
    "    win_out_percentage = round(wins_df[f'win_{win_out}'].values[0] * 100, 1)\n",
    "    def find_team_spread(game, team_data, team_name, home_team, away_team, neutral):\n",
    "        home_rating = team_data[team_data['team'] == home_team]['power_rating'].values[0]\n",
    "        away_rating = team_data[team_data['team'] == away_team]['power_rating'].values[0]\n",
    "        home_win_prob = game['home_win_prob']\n",
    "        def adjust_home_pr(home_win_prob):\n",
    "            return ((home_win_prob - 50) / 50) * 5\n",
    "        def round_to_nearest_half(x):\n",
    "            return np.round(x * 2) / 2 \n",
    "        if neutral:\n",
    "            spread = round((home_rating + adjust_home_pr(home_win_prob) - away_rating),1)\n",
    "        else:\n",
    "            spread = round((4.6 + home_rating + adjust_home_pr(home_win_prob) - away_rating),1)\n",
    "        if (home_team == team_name) & (spread > 0):\n",
    "            output = \"-\" + str(spread)\n",
    "        elif (home_team == team_name) & (spread < 0):\n",
    "            output = \"+\" + str(abs(spread))\n",
    "        elif (home_team != team_name) & (spread < 0):\n",
    "            output = str(spread)\n",
    "        elif (spread == 0.0):\n",
    "            output = str(spread)\n",
    "        else:\n",
    "            output = \"+\" + str(spread)\n",
    "\n",
    "        return output, spread\n",
    "    \n",
    "    def add_spreads(schedule_info, team_data, team_name):\n",
    "        # Define a helper function to apply the find_team_spread to each row\n",
    "        def compute_spread(row):\n",
    "            # Extract relevant data from the current row\n",
    "            home_team = row['home_team']\n",
    "            away_team = row['away_team']\n",
    "            neutral = row['neutral']\n",
    "            \n",
    "            # Call the find_team_spread function with this row's data\n",
    "            spread_str, raw_spread = find_team_spread(row, team_data, team_name, home_team, away_team, neutral)\n",
    "            \n",
    "            # Return both values as a tuple, so we can unpack them into two columns\n",
    "            return pd.Series([spread_str, raw_spread])\n",
    "\n",
    "        # Apply the compute_spread function to each row of the DataFrame\n",
    "        schedule_info[['spread', 'raw_spread']] = schedule_info.apply(compute_spread, axis=1)\n",
    "        \n",
    "        return schedule_info\n",
    "\n",
    "    # Example of calling the function\n",
    "    schedule_info = add_spreads(schedule_info, team_data, team_name)\n",
    "\n",
    "    ################################# BAR CHART #################################\n",
    "\n",
    "    # Create the plot\n",
    "    fig, (ax, ax2) = plt.subplots(nrows=2, figsize=(8, 12))\n",
    "    fig.patch.set_facecolor('#5fa391')  # Set figure background color\n",
    "    ax.set_facecolor('#5fa391')    \n",
    "    team_logo_url = logos_df[logos_df['team'] == team_name]['logo'].values[0][0]\n",
    "    team_color = logos_df[logos_df['team'] == team_name]['color'].values[0]\n",
    "    \n",
    "    # Plot the probabilities as a bar plot\n",
    "    sns.barplot(x='level_0', y='prob', data=transposed_data, ax=ax, color=team_color)\n",
    "    \n",
    "    # Set titles and labels\n",
    "    ax.set_title(f\"#{rank} {team_name} Wins Distribution\", fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel(\"Wins\", fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(\"Probability Based on 1000 Simulations\", fontsize=12)\n",
    "\n",
    "    ################################# TEAM LOGO BOTTOM MIDDLE #################################\n",
    "\n",
    "    response = requests.get(team_logo_url)\n",
    "    logo_img = Image.open(BytesIO(response.content))\n",
    "    img_ax = fig.add_axes([1.42,0.1,0.55,0.55])\n",
    "    img_ax.imshow(logo_img)\n",
    "    img_ax.axis('off')\n",
    "\n",
    "    ################################# AVERAGE TEAM STATISTICS #################################\n",
    "\n",
    "    entire_team_schedule = entire_schedule[(entire_schedule['home_team'] == team_name) | (entire_schedule['away_team'] == team_name)].reset_index()\n",
    "    average_pr = team_data['power_rating'].mean()\n",
    "    num_simulations = 1000\n",
    "    average_team_threshold = average_team_distribution(num_simulations, entire_team_schedule, average_pr, team_name)\n",
    "    transposed_avg = average_team_threshold.reset_index()  # Reset index to create a new DataFrame\n",
    "    transposed_avg = transposed_avg.melt(id_vars='index', var_name='win_count', value_name='prob')[0:13]  # Melt the DataFrame\n",
    "    transposed_avg['win_count'] = transposed_avg['win_count'].str.replace('win_', '').astype(int) \n",
    "    transposed_avg = transposed_avg.drop(columns=['index'])\n",
    "    team_completed_games['avg_win_prob'] = np.where(team_completed_games['home_team'] == team_name, \n",
    "                                    ESCAPE_Win_Prob(average_pr, team_completed_games['away_pr']), \n",
    "                                    100 - ESCAPE_Win_Prob(team_completed_games['home_pr'], average_pr))\n",
    "    avg_expected_wins = round(sum(team_completed_games['avg_win_prob']) / 100, 1)\n",
    "    avg_expected_loss = round(len(team_completed_games) - avg_expected_wins, 1)\n",
    "    strength_of_record = SOR[SOR['team'] == team_name]['SOR'].values[0]\n",
    "    strength_of_schedule = SOS[SOS['team'] == team_name]['SOS'].values[0]\n",
    "\n",
    "    games_played = wins + losses\n",
    "    if len(team_completed_games) != games_played:\n",
    "        avg_expected_wins = avg_expected_wins + 1\n",
    "\n",
    "    cmap = LinearSegmentedColormap.from_list('dark_gradient_orange', ['#660000', '#8B0000', '#CC5500', '#2C5E00', '#1D4D00'], N=100)\n",
    "    # Function to get color based on value with gradient\n",
    "    def get_color(value, vmin=0, vmax=100):\n",
    "        norm_value = (value - vmin) / (vmax - vmin)  # Normalize the value between 0 and 1\n",
    "        return cmap(norm_value)  # Get the color from the colormap\n",
    "    \n",
    "    xwin = LinearSegmentedColormap.from_list('dark_gradient_pattern', ['#660000', '#8B0000', '#CC5500', '#2C5E00', '#1D4D00'], N=100)\n",
    "\n",
    "    # Function to get color based on value with specified boundaries\n",
    "    def gradient_xWins(value, vmin=-2, vmax=2):\n",
    "        if value <= vmin:\n",
    "            return '#660000'  # Lighter dark red for <= -1.5\n",
    "        elif value >= vmax:\n",
    "            return '#1D4D00'  # Dark green for >= 1.5\n",
    "        else:\n",
    "            norm_value = (value - vmin) / (vmax - vmin)  # Normalize value between vmin and vmax\n",
    "            return xwin(norm_value)  # Get color from colormap for intermediate values\n",
    "\n",
    "    plt.text(2.45, 1.03, f\"Schedule Stats\", fontsize=12, ha='center', verticalalignment='top', transform=ax2.transAxes, fontweight='bold')\n",
    "    plt.text(2.45, 0.98, f\"Strength of Schedule: #{strength_of_schedule}\", verticalalignment='top', ha='center', transform=ax2.transAxes, fontsize=12)\n",
    "    plt.text(2.45, 0.93, f\"Strength of Record: #{strength_of_record}\", verticalalignment='top', ha='center', transform=ax2.transAxes, fontsize=12)\n",
    "    plt.text(2.45, 0.88, f\"Avg Team Current xRecord: {avg_expected_wins} - {avg_expected_loss}\", ha='center', verticalalignment='top', transform=ax2.transAxes, fontsize=12)\n",
    "    plt.text(2.45, 0.83, f\"Avg Team Final xRecord: {round(average_team_threshold.loc[0, 'expected_wins'],1)} - {round(average_team_threshold.loc[0, 'expected_losses'], 1)}\", ha='center', verticalalignment='top', transform=ax2.transAxes, fontsize=12)\n",
    "    # plt.text(1.01, 0.78, f\"Avg Team Win 6%: {round(average_team_threshold.loc[0, 'WIN6%']*100, 2)}%\", verticalalignment='top', transform=ax2.transAxes)\n",
    "    plt.text(2.45, 0.78, f\"Wins Above Average: {round(wins - avg_expected_wins, 1)}\", verticalalignment='top', ha='center', transform=ax2.transAxes, color = gradient_xWins(round(wins - avg_expected_wins, 1)), fontweight='bold', fontsize=12)\n",
    "    plt.text(2.45, 0.73, f\"Expected Wins Above Average: {round(completed_expected_wins - avg_expected_wins, 1)}\", ha='center', fontsize=12, verticalalignment='top', transform=ax2.transAxes, color = gradient_xWins(round(completed_expected_wins - avg_expected_wins, 1)), fontweight='bold')\n",
    "    plt.text(2.45, 0.68, f\"Adjusted Performance: {round(wins - completed_expected_wins, 1)}\", verticalalignment='top', ha='center', transform=ax2.transAxes, color=gradient_xWins(round(wins - completed_expected_wins, 1)), fontweight='bold', fontsize=12)\n",
    "    plt.text(2.45, 0.63, f\"Schedule-Adjusted Final Wins: {round(expected_wins - round(average_team_threshold.loc[0, 'expected_wins'],1), 1)}\", ha='center',verticalalignment='top', transform=ax2.transAxes, color = gradient_xWins(round(expected_wins - round(average_team_threshold.loc[0, 'expected_wins'],1), 1)), fontweight='bold', fontsize=12)\n",
    "\n",
    "    ################################# AVERAGE TEAM DISTRIBUTION CHART #################################\n",
    "\n",
    "    fig.patch.set_facecolor('#5fa391')  # Set figure background color\n",
    "    ax2.set_facecolor('#5fa391')    \n",
    "    # Plot the probabilities as a bar plot\n",
    "    sns.barplot(x='win_count', y='prob', data=transposed_avg, ax=ax2, color='#555555')\n",
    "    \n",
    "    # Set titles and labels\n",
    "    ax2.set_title(f\"Average Team vs. {team_name} Schedule\", fontsize=16, fontweight='bold')\n",
    "    ax2.set_xlabel(\"Wins\", fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel(\"Probability Based on 1000 Simulations\", fontsize=12)\n",
    "\n",
    "    ################################# TEAM STATISTICS #################################\n",
    "\n",
    "    cmap = LinearSegmentedColormap.from_list('dark_gradient_orange', ['#660000', '#8B0000', '#CC5500', '#2C5E00', '#1D4D00'], N=100)\n",
    "    # Function to get color based on value with gradient\n",
    "    def get_color(value, vmin=0, vmax=100):\n",
    "        norm_value = (value - vmin) / (vmax - vmin)  # Normalize the value between 0 and 1\n",
    "        return cmap(norm_value)  # Get the color from the colormap\n",
    "    \n",
    "    xwin = LinearSegmentedColormap.from_list('dark_gradient_pattern', ['#660000', '#8B0000', '#CC5500', '#2C5E00', '#1D4D00'], N=100)\n",
    "\n",
    "    # Function to get color based on value with specified boundaries\n",
    "    def get_gradient_color(value, vmin=-1.5, vmax=1.5):\n",
    "        if value <= vmin:\n",
    "            return '#660000'  # Lighter dark red for <= -1.5\n",
    "        elif value >= vmax:\n",
    "            return '#1D4D00'  # Dark green for >= 1.5\n",
    "        else:\n",
    "            norm_value = (value - vmin) / (vmax - vmin)  # Normalize value between vmin and vmax\n",
    "            return xwin(norm_value)  # Get color from colormap for intermediate values\n",
    "\n",
    "    # Fetch the scaled talent and add it as text\n",
    "    power_rating = round(all_data[all_data['team'] == team_name]['power_rating'].values[0], 2)\n",
    "    talent_scaled = round(all_data[all_data['team'] == team_name]['talent_scaled'].values[0], 2)\n",
    "    offense_success = round(all_data[all_data['team'] == team_name]['offense_success_scaled'].values[0], 2)\n",
    "    defense_success = round(all_data[all_data['team'] == team_name]['defense_success_scaled'].values[0], 2)\n",
    "    offense_explosive = round(all_data[all_data['team'] == team_name]['offense_explosive'].values[0], 2)\n",
    "    defense_explosive = round(all_data[all_data['team'] == team_name]['defense_explosive'].values[0], 2)\n",
    "    turnovers = round(all_data[all_data['team'] == team_name]['total_turnovers_scaled'].values[0], 2)\n",
    "    penalties = round(all_data[all_data['team'] == team_name]['penalties_scaled'].values[0], 2)\n",
    "\n",
    "        ################################# CONFERENCE WINS INFO #################################\n",
    "\n",
    "    conference_wins = records[records['team'] == team_name]['conference_wins'].values[0]\n",
    "    conference_losses = records[records['team'] == team_name]['conference_losses'].values[0]\n",
    "    expected_conference_wins = round(all_conference_wins[all_conference_wins['team'] == team_name]['expected_wins'].values[0], 1)\n",
    "    expected_conference_losses = round(all_conference_wins[all_conference_wins['team'] == team_name]['expected_loss'].values[0], 1)\n",
    "    conference = all_conference_wins[all_conference_wins['team'] == team_name]['conference'].values[0]\n",
    "\n",
    "    if conference != 'FBS Independents':\n",
    "        plt.text(1.01, 0.88, f\"Current Record: {wins} - {losses} ({conference_wins} - {conference_losses})\", verticalalignment='top', transform=ax.transAxes, fontweight='bold')\n",
    "    else:\n",
    "        plt.text(1.01, 0.88, f\"Current Record: {wins} - {losses}\", verticalalignment='top', transform=ax.transAxes, fontweight='bold')\n",
    "    plt.text(1.01, 0.78, f\"Final xRecord: {expected_wins} - {expected_losses}\", verticalalignment='top', transform=ax.transAxes)\n",
    "    plt.text(1.01, 0.83, f\"Current xRecord: {completed_expected_wins} - {completed_expected_losses}\", verticalalignment='top', transform=ax.transAxes)\n",
    "    plt.text(1.01, 0.73, f\"Win 6%: {win_6}%\", fontsize=12, verticalalignment='top', transform=ax.transAxes)\n",
    "    plt.text(1.01, 0.68, f\"Win Out%: {win_out_percentage}%\", fontsize=12, verticalalignment='top', transform=ax.transAxes)\n",
    "    plt.text(1.01, 0.63, f\"Team Talent: {talent_scaled}\", fontsize=12, verticalalignment='top', transform=ax.transAxes, color=get_color(talent_scaled/10), fontweight='bold')\n",
    "    plt.text(1.01, 0.58, f\"Offense Success: {offense_success}\", fontsize=12, verticalalignment='top', transform=ax.transAxes, color=get_color(offense_success), fontweight='bold')\n",
    "    plt.text(1.01, 0.53, f\"Offense Explosiveness: {offense_explosive}\", fontsize=12, verticalalignment='top', transform=ax.transAxes, color=get_color(offense_explosive), fontweight='bold')\n",
    "    plt.text(1.01, 0.48, f\"Defense Success: {defense_success}\", fontsize=12, verticalalignment='top', transform=ax.transAxes, color=get_color(defense_success), fontweight='bold')\n",
    "    plt.text(1.01, 0.43, f\"Defense Explosiveness: {defense_explosive}\", fontsize=12, verticalalignment='top', transform=ax.transAxes, color=get_color(defense_explosive), fontweight='bold')\n",
    "    plt.text(1.01, 0.38, f\"Turnovers: {turnovers}\", fontsize=12, verticalalignment='top', transform=ax.transAxes, color = get_color(turnovers), fontweight='bold')\n",
    "    plt.text(1.01, 0.33, f\"Penalties: {penalties}\", fontsize=12, verticalalignment='top', transform=ax.transAxes, color=get_color(penalties), fontweight='bold')\n",
    "\n",
    "    ################################# NEXT GAME #################################    \n",
    "\n",
    "    def get_watchability_color(value, vmin=-20, vmax=20):\n",
    "        if value <= vmin:\n",
    "            return '#660000'\n",
    "        elif value >= vmax:\n",
    "            return '#1D4D00'\n",
    "        else:\n",
    "            norm_value = (value - vmin) / (vmax - vmin)  # Normalize the value between 0 and 1\n",
    "            return cmap(norm_value)  # Get the color from the colormap\n",
    "\n",
    "    next_game = schedule_info[(schedule_info['home_team'] == team_name) | (schedule_info['away_team'] == team_name)].reset_index()[:1]\n",
    "    if next_game['week'].values[0] != current_week:\n",
    "        plt.text(1.01, 0.28, \"This Week: BYE\", fontsize = 12, verticalalignment='top', transform=ax.transAxes, fontweight='bold')\n",
    "    else:\n",
    "        if next_game['home_team'].values[0] == team_name:\n",
    "            opponent = next_game['away_team'].values[0]\n",
    "        else:\n",
    "            opponent = next_game['home_team'].values[0]\n",
    "\n",
    "        spread = abs(next_game['raw_spread'].values[0])\n",
    "        watchability = ((team_data[team_data['team'] == team_name]['power_rating'].values[0] + team_data[team_data['team'] == opponent]['power_rating'].values[0]) / 2) - (spread * 0.5) + 7\n",
    "        opponent_url = logos[logos['team'] == opponent]['logo'].values[0][0]\n",
    "        response = requests.get(opponent_url)\n",
    "        logo_img = Image.open(BytesIO(response.content))\n",
    "        img_ax = fig.add_axes([0.98, 0.53, 0.1, 0.1], anchor='NE', zorder=1)\n",
    "        img_ax.imshow(logo_img)\n",
    "        img_ax.axis('off')  # No axis for the image\n",
    "        plt.text(1.01, 0.28, f\"This Week\", fontsize = 12, verticalalignment='top', transform=ax.transAxes, fontweight='bold')\n",
    "        opponent_rank = team_data[team_data['team'] == opponent].index[0] + 1\n",
    "        plt.text(1.01, 0.23, f\"#{opponent_rank} {opponent}\", fontsize = 12, verticalalignment='top', transform=ax.transAxes, fontweight='bold')\n",
    "        plt.text(1.01, 0.04, f\"Game Quality: {round(watchability,1)}\", fontsize = 12, verticalalignment='top', transform=ax.transAxes, color=get_watchability_color(watchability),fontweight='bold')\n",
    "\n",
    "\n",
    "    ################################# LIKELY LOSS #################################\n",
    "\n",
    "    team_schedule = schedule_info[(schedule_info['home_team'] == team_name) | (schedule_info['away_team'] == team_name)].reset_index()\n",
    "    team_schedule['raw_spread'] = pd.to_numeric(team_schedule['spread'], errors='coerce')\n",
    "    team_schedule['team_win_prob'] = np.where(team_schedule['home_team'] == team_name, \n",
    "                                 team_schedule['escape_win_prob'], \n",
    "                                 100 - team_schedule['escape_win_prob'])\n",
    "    lowest_prob_row = team_schedule.loc[team_schedule['team_win_prob'].idxmin()]\n",
    "    if lowest_prob_row['home_team'] == team_name:\n",
    "        most_likely_loss = lowest_prob_row['away_team']\n",
    "    else:\n",
    "        most_likely_loss = lowest_prob_row['home_team']\n",
    "    likely_loss_rank = team_data[team_data['team'] == most_likely_loss].index[0] + 1\n",
    "    loss_url = logos[logos['team'] == most_likely_loss]['logo'].values[0][0]\n",
    "    response = requests.get(loss_url)\n",
    "    loss_logo = Image.open(BytesIO(response.content))\n",
    "    img_ax = fig.add_axes([1.32,.547,0.10,0.10])\n",
    "    img_ax.imshow(loss_logo)\n",
    "    img_ax.axis('off')\n",
    "    # plt.text(1.335, 0.33, f\"The Most Likely Loss, Win, and Closest Game Based on WP\", fontsize = 12, verticalalignment='top', transform=ax.transAxes, fontweight='bold')\n",
    "    plt.text(1.45, 0.22, f\"Most Likely Loss\", fontsize = 12, verticalalignment='top', ha='center', transform=ax.transAxes, fontweight='bold')\n",
    "    plt.text(1.45, 0.04, f\"#{likely_loss_rank} {most_likely_loss}\", fontsize = 12, ha='center', verticalalignment='top', transform=ax.transAxes, fontweight='bold')\n",
    "\n",
    "    ################################# LIKELY WIN #################################\n",
    "\n",
    "    highest_prob_row = team_schedule.loc[team_schedule['team_win_prob'].idxmax()]\n",
    "    if highest_prob_row['home_team'] == team_name:\n",
    "        most_likely_win = highest_prob_row['away_team']\n",
    "    else:\n",
    "        most_likely_win = highest_prob_row['home_team']\n",
    "    likely_win_rank = team_data[team_data['team'] == most_likely_win].index[0] + 1\n",
    "    win_url = logos[logos['team'] == most_likely_win]['logo'].values[0][0]\n",
    "    response = requests.get(win_url)\n",
    "    win_logo = Image.open(BytesIO(response.content))\n",
    "    img_ax = fig.add_axes([1.58,.547,0.10,0.10])\n",
    "    img_ax.imshow(win_logo)\n",
    "    img_ax.axis('off')\n",
    "    plt.text(1.75, 0.22, f\"Most Likely Win\", fontsize = 12, verticalalignment='top', ha='center',transform=ax.transAxes, fontweight='bold')\n",
    "    plt.text(1.75, 0.04, f\"#{likely_win_rank} {most_likely_win}\", fontsize = 12, ha='center',verticalalignment='top', transform=ax.transAxes, fontweight='bold')\n",
    "\n",
    "    ################################# CLOSEST GAME #################################\n",
    "\n",
    "    closest_index = (team_schedule['team_win_prob']-50).abs().idxmin()\n",
    "    closest_prob_row = team_schedule.loc[closest_index]\n",
    "    if closest_prob_row['home_team'] == team_name:\n",
    "        closest_game_team = closest_prob_row['away_team']\n",
    "    else:\n",
    "        closest_game_team = closest_prob_row['home_team']\n",
    "    closest_rank = team_data[team_data['team'] == closest_game_team].index[0] + 1\n",
    "    close_url = logos[logos['team'] == closest_game_team]['logo'].values[0][0]\n",
    "    response = requests.get(close_url)\n",
    "    close_logo = Image.open(BytesIO(response.content))\n",
    "    img_ax = fig.add_axes([1.84,.547,0.10,0.10])\n",
    "    img_ax.imshow(close_logo)\n",
    "    img_ax.axis('off')\n",
    "    plt.text(2.05, 0.22, f\"Closest Game\", fontsize = 12, verticalalignment='top', ha='center',transform=ax.transAxes, fontweight='bold')\n",
    "    plt.text(2.05, 0.04, f\"#{closest_rank} {closest_game_team}\", fontsize = 12, ha='center',verticalalignment='top', transform=ax.transAxes, fontweight='bold')\n",
    "\n",
    "    ################################# SCHEDULE INFO #################################    \n",
    "    \n",
    "    def get_color_wl(w_l):\n",
    "        if w_l == \"W\":\n",
    "            return '#1D4D00'\n",
    "        else:\n",
    "            return '#660000'\n",
    "    j = 0.83\n",
    "    plt.text(1.52, 0.88, f\"FCS Games are Not Included in Schedule\", fontsize = 12, verticalalignment='top', transform=ax.transAxes, fontweight='bold')\n",
    "    for i, game in team_completed_games.iterrows():\n",
    "        neutral = game['neutral']\n",
    "        plt.text(1.36, j, f\"{game['week']}\", fontsize = 13, verticalalignment='top', transform=ax.transAxes, fontweight='bold')\n",
    "        if game['home_team'] == team_name:\n",
    "            if game['home_points'] > game['away_points']:\n",
    "                w_l = 'W'\n",
    "            else:\n",
    "                w_l = 'L'\n",
    "        else:\n",
    "            if game['home_points'] > game['away_points']:\n",
    "                w_l = 'L'\n",
    "            else:\n",
    "                w_l = 'W'\n",
    "        if neutral:\n",
    "            if game['home_team'] == team_name:\n",
    "                opponent_rank = team_data[team_data['team'] == game['away_team']].index[0] + 1\n",
    "                plt.text(1.4, j, f\"{game['home_team']} (N) {game['away_team']} (#{opponent_rank})\", fontsize = 13, verticalalignment='top', transform=ax.transAxes, color = get_color_wl(w_l), fontweight='bold')\n",
    "            else:\n",
    "                opponent_rank = team_data[team_data['team'] == game['home_team']].index[0] + 1\n",
    "                plt.text(1.4, j, f\"{game['away_team']} (N) {game['home_team']} (#{opponent_rank})\", fontsize = 13, verticalalignment='top', transform=ax.transAxes, color = get_color_wl(w_l), fontweight='bold')       \n",
    "        elif game['home_team'] == team_name:\n",
    "            opponent_rank = team_data[team_data['team'] == game['away_team']].index[0] + 1\n",
    "            plt.text(1.4, j, f\"{game['home_team']} vs. {game['away_team']} (#{opponent_rank})\", fontsize = 13, verticalalignment='top', transform=ax.transAxes, color = get_color_wl(w_l), fontweight='bold')\n",
    "        else:\n",
    "            opponent_rank = team_data[team_data['team'] == game['home_team']].index[0] + 1\n",
    "            plt.text(1.4, j, f\"{game['away_team']} @ {game['home_team']} (#{opponent_rank})\", fontsize = 13, verticalalignment='top', transform=ax.transAxes, color = get_color_wl(w_l), fontweight='bold')\n",
    "        plt.text(2.02, j, f\"{w_l}\", fontsize = 13, verticalalignment='top', transform=ax.transAxes, color = get_color_wl(w_l), fontweight='bold')\n",
    "        if game['home_points'] > game['away_points']:\n",
    "            plt.text(2.12, j, f\"{int(game['home_points'])}-{int(game['away_points'])}\", fontsize = 13, verticalalignment='top', transform=ax.transAxes, color = get_color_wl(w_l), fontweight='bold')\n",
    "        else:\n",
    "            plt.text(2.12, j, f\"{int(game['away_points'])}-{int(game['home_points'])}\", fontsize = 13, verticalalignment='top', transform=ax.transAxes, color = get_color_wl(w_l), fontweight='bold')\n",
    "        j -= 0.05\n",
    "\n",
    "    def get_color_future(w_l):\n",
    "        if w_l <= 0:\n",
    "            return '#1D4D00'\n",
    "        else:\n",
    "            return '#660000'\n",
    "    for i, game in team_schedule.iterrows():\n",
    "        neutral = game['neutral']\n",
    "        plt.text(1.36, j, f\"{game['week']}\", fontsize = 13, verticalalignment='top', transform=ax.transAxes, fontweight='bold')\n",
    "        spread = game['spread']\n",
    "        raw_spread = game['raw_spread']\n",
    "        if neutral:\n",
    "            if game['home_team'] == team_name:\n",
    "                opponent_rank = team_data[team_data['team'] == game['away_team']].index[0] + 1\n",
    "                plt.text(1.4, j, f\"{game['home_team']} (N) {game['away_team']} (#{opponent_rank})\", fontsize = 13, verticalalignment='top', transform=ax.transAxes)\n",
    "            else:\n",
    "                opponent_rank = team_data[team_data['team'] == game['home_team']].index[0] + 1\n",
    "                plt.text(1.4, j, f\"{game['away_team']} (N) {game['home_team']} (#{opponent_rank})\", fontsize = 13, verticalalignment='top', transform=ax.transAxes)\n",
    "        elif game['home_team'] == team_name:\n",
    "            opponent_rank = team_data[team_data['team'] == game['away_team']].index[0] + 1\n",
    "            plt.text(1.4, j, f\"{game['home_team']} vs. {game['away_team']} (#{opponent_rank})\", fontsize = 13, verticalalignment='top', transform=ax.transAxes)\n",
    "        else:\n",
    "            opponent_rank = team_data[team_data['team'] == game['home_team']].index[0] + 1\n",
    "            plt.text(1.4, j, f\"{game['away_team']} @ {game['home_team']} (#{opponent_rank})\", fontsize = 13, verticalalignment='top', transform=ax.transAxes)\n",
    "        plt.text(2.02, j, f\"{round(game['team_win_prob'],1)}%\", fontsize = 13, verticalalignment='top', transform=ax.transAxes, fontweight='bold')\n",
    "        plt.text(2.12, j, f\"{spread}\", fontsize = 13, verticalalignment='top', transform=ax.transAxes, color=get_color_future(raw_spread), fontweight='bold')\n",
    "        # plt.text(1.75, j, f\"{int(game['home_points'])}-{int(game['away_points'])}\", fontsize = 12, verticalalignment='top', transform=ax.transAxes)\n",
    "        j -= 0.05\n",
    "\n",
    "    ################################# CHANCE TO WIN _ GAMES #################################\n",
    "\n",
    "    import matplotlib.font_manager as fm\n",
    "    checkmark_font = fm.FontProperties(family='DejaVu Sans')\n",
    "    import matplotlib.colors as mcolors\n",
    "\n",
    "    dark_green = '#1D4D00'\n",
    "    medium_green = '#3C7300'\n",
    "    orange = '#D2691E'\n",
    "    black = 'black'\n",
    "    def interpolate_color(c1, c2, factor):\n",
    "        \"\"\"Interpolate between two colors c1 and c2 based on factor (0 to 1).\"\"\"\n",
    "        color1 = mcolors.hex2color(c1)\n",
    "        color2 = mcolors.hex2color(c2)\n",
    "        return mcolors.rgb2hex([(1 - factor) * a + factor * b for a, b in zip(color1, color2)])\n",
    "    def get_color_percentage(percentage):\n",
    "        if 40 <= percentage <= 60:\n",
    "            return dark_green  # Dark green is constant in this range\n",
    "        elif 30 <= percentage < 40:\n",
    "            factor = (percentage - 30) / (40 - 30)\n",
    "            return interpolate_color(orange, medium_green, factor)\n",
    "        elif 60 < percentage <= 70:\n",
    "            factor = (percentage - 60) / (70 - 60)\n",
    "            return interpolate_color(medium_green, orange, factor)\n",
    "        elif 15 <= percentage < 30:\n",
    "            factor = (percentage - 15) / (30 - 15)\n",
    "            return interpolate_color(black, orange, factor)\n",
    "        elif 70 < percentage <= 85:\n",
    "            factor = (percentage - 70) / (85 - 70)\n",
    "            return interpolate_color(orange, black, factor)\n",
    "        else:\n",
    "            return black  # Anything outside the defined ranges is black\n",
    "\n",
    "    plt.text(2.32, 0.88, \"Overall xWins\", fontsize=12, transform=ax.transAxes, fontweight='bold', verticalalignment='top', ha='center')\n",
    "    plt.text(2.24, 0.83, \"Wins\", fontsize=12, transform=ax.transAxes, fontweight='bold', verticalalignment='top', ha='center')\n",
    "    plt.text(2.32, 0.83, \">=\", fontsize = 12, transform=ax.transAxes, fontweight='bold', verticalalignment='top', ha='center')\n",
    "    plt.text(2.40, 0.83, \"=\", fontsize = 12, transform=ax.transAxes, fontweight='bold', verticalalignment='top', ha='center')\n",
    "    team_index = wins_df[wins_df['team'] == team_name].index[0]\n",
    "    win_columns = [f'win_{j}' for j in range(13)]\n",
    "    cumulative_probs = wins_df.loc[team_index, win_columns].values[::-1].cumsum()[::] * 100\n",
    "\n",
    "    for j in range(len(cumulative_probs)):\n",
    "        if 12-j == wins_df[wins_df['team'] == team_name]['projected_wins'].values[0]:\n",
    "            plt.text(2.24, 0.78 - 0.05*j, f\"{12-j}\", fontsize=12, transform=ax.transAxes, verticalalignment='top', ha='center', fontweight='bold', color = 'darkblue')\n",
    "        elif j == 12-wins:\n",
    "            plt.text(2.24, 0.78 - 0.05*j, f\"{12-j}\", fontsize=12, transform=ax.transAxes, verticalalignment='top', fontweight='bold', fontproperties=checkmark_font, color='green', ha='center')\n",
    "        else:\n",
    "            plt.text(2.24, 0.78 - 0.05*j, f\"{12-j}\", fontsize=12, transform=ax.transAxes, verticalalignment='top', ha='center', fontweight='bold')\n",
    "        if j > 12-wins:\n",
    "            continue\n",
    "        else:\n",
    "            if cumulative_probs[j] == 0:\n",
    "                continue\n",
    "            elif cumulative_probs[j] < 1:\n",
    "                plt.text(2.32, 0.78 - 0.05*j, f\"<1%\", fontsize=12, transform=ax.transAxes,  fontweight='bold',verticalalignment='top', ha='center', color=get_color_percentage(1))\n",
    "            elif cumulative_probs[j] == 100:\n",
    "                plt.text(2.32, 0.78 - 0.05*j, f\"100%\", fontsize=12, transform=ax.transAxes,  fontweight='bold',verticalalignment='top', ha='center', color=get_color_percentage(99))   \n",
    "            elif cumulative_probs[j] >= 99:\n",
    "                plt.text(2.32, 0.78 - 0.05*j, f\">99%\", fontsize=12, transform=ax.transAxes,  fontweight='bold',verticalalignment='top', ha='center', color=get_color_percentage(99))                \n",
    "            else:\n",
    "                plt.text(2.32, 0.78 - 0.05*j, f\"{round(cumulative_probs[j])}%\", fontsize=12, transform=ax.transAxes,  fontweight='bold',verticalalignment='top', ha='center', color=get_color_percentage(cumulative_probs[j]))\n",
    "\n",
    "    for i in range(len(win_columns[::-1])):\n",
    "        if i > 12-wins:\n",
    "            continue\n",
    "        else:\n",
    "            if wins_df.loc[team_index, win_columns[::-1][i]]*100 == 0:\n",
    "                continue\n",
    "            elif wins_df.loc[team_index, win_columns[::-1][i]]*100 <= 1:\n",
    "                plt.text(2.40, 0.78 - 0.05*i, f\"<1%\", fontsize=12, transform=ax.transAxes, verticalalignment='top', ha='center', fontweight='bold', color=get_color_percentage(1))\n",
    "            elif wins_df.loc[team_index, win_columns[::-1][i]]*100 == 100:\n",
    "                plt.text(2.40, 0.78 - 0.05*i, f\"100%\", fontsize=12, transform=ax.transAxes, verticalalignment='top', ha='center', fontweight='bold', color=get_color_percentage(99))\n",
    "            elif wins_df.loc[team_index, win_columns[::-1][i]]*100 >= 99:\n",
    "                plt.text(2.40, 0.78 - 0.05*i, f\">99%\", fontsize=12, transform=ax.transAxes, verticalalignment='top', ha='center', fontweight='bold', color=get_color_percentage(99))\n",
    "            else:\n",
    "                plt.text(2.40, 0.78 - 0.05*i, f\"{round(wins_df.loc[team_index, win_columns[::-1][i]]*100)}%\", fontsize=12, fontweight='bold', transform=ax.transAxes, verticalalignment='top', ha='center', color = get_color_percentage(wins_df.loc[team_index, win_columns[::-1][i]]*100))\n",
    "\n",
    "    num_conference_games = {\n",
    "        'SEC':8,\n",
    "        'Big Ten':9,\n",
    "        'ACC':8,\n",
    "        'Big 12':9,\n",
    "        'Mountain West':7,\n",
    "        'American Athletic':9,\n",
    "        'Pac-12':1,\n",
    "        'Sun Belt':8,\n",
    "        'Mid-American':8,\n",
    "        'Conference USA':8\n",
    "    }\n",
    "\n",
    "    team_conference = all_conference_wins[all_conference_wins['team'] == team_name]['conference'].values[0]\n",
    "    if team_conference != 'FBS Independents':     \n",
    "        plt.text(2.56, 0.88, \"Conference xWins\", fontsize=12, transform=ax.transAxes, fontweight='bold', verticalalignment='top', ha='center')\n",
    "        plt.text(2.48, 0.83, \"Wins\", fontsize=12, transform=ax.transAxes, fontweight='bold', verticalalignment='top', ha='center')\n",
    "        plt.text(2.56, 0.83, \">=\", fontsize = 12, transform=ax.transAxes, fontweight='bold', verticalalignment='top', ha='center')\n",
    "        plt.text(2.64, 0.83, \"=\", fontsize = 12, transform=ax.transAxes, fontweight='bold', verticalalignment='top', ha='center')\n",
    "        team_index = all_conference_wins[all_conference_wins['team'] == team_name].index[0]\n",
    "        this_conference_wins = all_conference_wins[all_conference_wins['conference'] == team_conference]\n",
    "        conference_games = num_conference_games[team_conference]  \n",
    "        win_columns = [f'win_{j}' for j in range(conference_games+1)]\n",
    "        cumulative_probs = this_conference_wins.loc[team_index, win_columns].values[::-1].cumsum()[::] * 100\n",
    "        for j in range(0,conference_games+1):\n",
    "            if conference_games-j == all_conference_wins[all_conference_wins['team'] == team_name]['projected_wins'].values[0]:\n",
    "                plt.text(2.48, 0.78 - 0.05*j, f\"{conference_games-j}\", fontsize=12, transform=ax.transAxes, verticalalignment='top', ha='center', fontweight='bold', color = 'darkblue')\n",
    "            elif j == conference_games-conference_wins:\n",
    "                plt.text(2.48, 0.78 - 0.05*j, f\"{conference_games-j}\", fontsize=12, transform=ax.transAxes,  fontweight='bold',verticalalignment='top', fontproperties=checkmark_font, color='green', ha='center')\n",
    "            else:\n",
    "                plt.text(2.48, 0.78 - 0.05*j, f\"{conference_games-j}\", fontsize=12, transform=ax.transAxes, verticalalignment='top', ha='center', fontweight='bold')\n",
    "            if j > conference_games-conference_wins:\n",
    "                continue\n",
    "            else:\n",
    "                if cumulative_probs[j] == 0:\n",
    "                    continue\n",
    "                elif cumulative_probs[j] < 1:\n",
    "                    plt.text(2.56, 0.78 - 0.05*j, f\"<1%\", fontsize=12, transform=ax.transAxes,  fontweight='bold',verticalalignment='top', ha='center', color=get_color_percentage(1))\n",
    "                elif cumulative_probs[j] == 100:\n",
    "                    plt.text(2.56, 0.78 - 0.05*j, f\"100%\", fontsize=12, transform=ax.transAxes,  fontweight='bold',verticalalignment='top', ha='center', color=get_color_percentage(100))\n",
    "                elif cumulative_probs[j] >= 99:\n",
    "                    plt.text(2.56, 0.78 - 0.05*j, f\">99%\", fontsize=12, transform=ax.transAxes,  fontweight='bold',verticalalignment='top', ha='center', color=get_color_percentage(99))\n",
    "                else:\n",
    "                    plt.text(2.56, 0.78 - 0.05*j, f\"{round(cumulative_probs[j])}%\", fontsize=12, transform=ax.transAxes, fontweight='bold', verticalalignment='top', ha='center',color=get_color_percentage(cumulative_probs[j]))\n",
    "\n",
    "        for i in range(len(win_columns[::-1])):\n",
    "            if i > conference_games - conference_wins:\n",
    "                continue\n",
    "            else:\n",
    "                if this_conference_wins.loc[team_index, win_columns[::-1][i]]*100 == 0:\n",
    "                    continue\n",
    "                elif this_conference_wins.loc[team_index, win_columns[::-1][i]]*100 <= 1:\n",
    "                    plt.text(2.64, 0.78 - 0.05*i, f\"<1%\", fontsize=12, transform=ax.transAxes, verticalalignment='top', ha='center', fontweight='bold', color=get_color_percentage(1))\n",
    "                elif this_conference_wins.loc[team_index, win_columns[::-1][i]]*100 == 100:\n",
    "                    plt.text(2.64, 0.78 - 0.05*i, f\"100%\", fontsize=12, transform=ax.transAxes, verticalalignment='top', ha='center', fontweight='bold', color=get_color_percentage(99)) \n",
    "                elif this_conference_wins.loc[team_index, win_columns[::-1][i]]*100 >= 99:\n",
    "                    plt.text(2.64, 0.78 - 0.05*i, f\">99%\", fontsize=12, transform=ax.transAxes, verticalalignment='top', ha='center', fontweight='bold', color=get_color_percentage(99))                    \n",
    "                else:\n",
    "                    plt.text(2.64, 0.78 - 0.05*i, f\"{round(this_conference_wins.loc[team_index, win_columns[::-1][i]]*100)}%\", fontsize=12, fontweight='bold', transform=ax.transAxes, verticalalignment='top', ha='center', color=get_color_percentage(this_conference_wins.loc[team_index, win_columns[::-1][i]]*100))\n",
    "\n",
    "    ################################# NEXT OPPONENT #################################\n",
    "\n",
    "    plt.text(1.01, -0.01, \"Opponent's Rankings\",fontsize = 12, verticalalignment='top', transform=ax.transAxes, fontweight='bold')\n",
    "    if next_game['week'].values[0] == current_week:\n",
    "        opp_power_rating = round(all_data[all_data['team'] == opponent]['power_rating'].values[0], 2)\n",
    "        opp_talent_scaled = round(all_data[all_data['team'] == opponent]['talent_scaled'].values[0], 2)\n",
    "        opp_offense_success = round(all_data[all_data['team'] == opponent]['offense_success_scaled'].values[0], 2)\n",
    "        opp_defense_success = round(all_data[all_data['team'] == opponent]['defense_success_scaled'].values[0], 2)\n",
    "        opp_offense_explosive = round(all_data[all_data['team'] == opponent]['offense_explosive'].values[0], 2)\n",
    "        opp_defense_explosive = round(all_data[all_data['team'] == opponent]['defense_explosive'].values[0], 2)\n",
    "        opp_turnovers = round(all_data[all_data['team'] == opponent]['total_turnovers_scaled'].values[0], 2)\n",
    "        opp_penalties = round(all_data[all_data['team'] == opponent]['penalties_scaled'].values[0], 2)\n",
    "\n",
    "        plt.text(1.01, -0.06, f\"Opponent RTG: {opp_power_rating}\", fontsize=12, verticalalignment='top', transform=ax.transAxes)\n",
    "        plt.text(1.01, -0.11, f\"Team Talent: {opp_talent_scaled}\", fontsize=12, verticalalignment='top', transform=ax.transAxes, color=get_color(opp_talent_scaled/10), fontweight='bold')\n",
    "        plt.text(1.01, -0.16, f\"Offense Success: {opp_offense_success}\", fontsize=12, verticalalignment='top', transform=ax.transAxes, color=get_color(opp_offense_success), fontweight='bold')\n",
    "        plt.text(1.01, -0.21, f\"Offense Explosiveness: {opp_offense_explosive}\", fontsize=12, verticalalignment='top', transform=ax.transAxes, color=get_color(opp_offense_explosive), fontweight='bold')\n",
    "        plt.text(1.01, -0.26, f\"Defense Success: {opp_defense_success}\", fontsize=12, verticalalignment='top', transform=ax.transAxes, color=get_color(opp_defense_success), fontweight='bold')\n",
    "        plt.text(1.01, -0.31, f\"Defense Explosiveness: {opp_defense_explosive}\", fontsize=12, verticalalignment='top', transform=ax.transAxes, color=get_color(opp_defense_explosive), fontweight='bold')\n",
    "        plt.text(1.01, -0.36, f\"Turnovers: {opp_turnovers}\", fontsize=12, verticalalignment='top', transform=ax.transAxes, color = get_color(opp_turnovers), fontweight='bold')\n",
    "        plt.text(1.01, -0.41, f\"Penalties: {opp_penalties}\", fontsize=12, verticalalignment='top', transform=ax.transAxes, color=get_color(opp_penalties), fontweight='bold')\n",
    "\n",
    "    ################################# ENDING BOILER PLATE #################################\n",
    "    if branding:\n",
    "        plt.text(1.82, .14, \"@EscapeRatingCFB\", fontsize=16, ha='center', verticalalignment='top', transform=ax2.transAxes, fontweight='bold')\n",
    "        img_path = './escape_logo.jpg'  # Replace with the actual path to the image\n",
    "        img = mpimg.imread(img_path)\n",
    "        img_ax = fig.add_axes([2.1,.04,0.30,0.30])\n",
    "        img_ax.imshow(img)\n",
    "        img_ax.axis('off')\n",
    "    \n",
    "    plt.text(1.82, 0.32, f\"RTG: {power_rating} (#{rank})\", fontsize=16, verticalalignment='top', transform=ax2.transAxes, fontweight='bold', ha='center')\n",
    "    if power_rating >= last_week_rating:\n",
    "        plt.text(1.82, 0.27, f\"Week Change: +{round(power_rating-last_week_rating,1)}\", fontsize=12, verticalalignment='top', transform=ax2.transAxes, fontweight='bold', color = '#1D4D00', ha='center')\n",
    "    if power_rating < last_week_rating:\n",
    "        plt.text(1.82, 0.27, f\"Week Change: {round(power_rating-last_week_rating,1)}\", fontsize=12, verticalalignment='top', transform=ax2.transAxes, fontweight='bold', color = '#660000', ha='center')\n",
    "\n",
    "    if power_rating >= last_month_rating:\n",
    "        plt.text(1.82, 0.23, f\"Month Change: +{round(power_rating-last_month_rating,1)}\", fontsize=12, verticalalignment='top', transform=ax2.transAxes, fontweight='bold', color = '#1D4D00', ha='center')\n",
    "    if power_rating < last_month_rating:\n",
    "        plt.text(1.82, 0.23, f\"Month Change: {round(power_rating-last_month_rating,1)}\", fontsize=12, verticalalignment='top', transform=ax2.transAxes, fontweight='bold', color = '#660000', ha='center')\n",
    "\n",
    "    if power_rating >= start_season_rating:\n",
    "        plt.text(1.82, 0.19, f\"Season Change: +{round(power_rating-start_season_rating,1)}\", fontsize=12, verticalalignment='top', transform=ax2.transAxes, fontweight='bold', color = '#1D4D00', ha='center')\n",
    "    if power_rating < start_season_rating:\n",
    "        plt.text(1.82, 0.19, f\"Season Change: {round(power_rating-start_season_rating,1)}\", fontsize=12, verticalalignment='top', transform=ax2.transAxes, fontweight='bold', color = '#660000', ha='center')\n",
    "\n",
    "    plt.text(1.01, 0.485, 'Data Dictionary', fontsize=12, verticalalignment='top', transform=ax2.transAxes, fontweight='bold')\n",
    "    # plt.text(1.01, 0.47, \"'x' stands for 'Expected'\", fontsize=12, verticalalignment='top', transform=ax2.transAxes)\n",
    "    # plt.text(1.01, 0.42, \"'Avg' stands for 'Average'\", fontsize=12, verticalalignment='top', transform=ax2.transAxes)\n",
    "    plt.text(1.01, 0.45, \"0.0 is the average FBS Power Rating\", fontsize=10, verticalalignment='top', transform=ax2.transAxes)\n",
    "    plt.text(1.01, 0.42, \"Team Stats are scaled from 1 to 100\", fontsize=10, verticalalignment='top', transform=ax2.transAxes)\n",
    "    plt.text(1.01, 0.39, \"Team Talent is scaled from 100 to 1000\", fontsize=10, verticalalignment='top', transform=ax2.transAxes)\n",
    "    plt.text(1.01, 0.36, \"Game Quality is between -27 and 27\", fontsize=10, verticalalignment='top', transform=ax2.transAxes)\n",
    "    plt.text(1.01, 0.33, \"Wins Above Average:\", fontsize=10, verticalalignment='top', transform=ax2.transAxes)\n",
    "    plt.text(1.01, 0.30, \"Wins compared to the average team\", fontsize=8, verticalalignment='top', transform=ax2.transAxes)\n",
    "    plt.text(1.01, 0.27, \"Expected Wins Above Average:\", fontsize=10, verticalalignment='top', transform=ax2.transAxes)\n",
    "    plt.text(1.01, 0.24, \"xPerformance versus the average xPerformance\", fontsize=8, verticalalignment='top', transform=ax2.transAxes)\n",
    "    plt.text(1.01, 0.21, \"Adjusted Performance:\", fontsize=10, verticalalignment='top', transform=ax2.transAxes)\n",
    "    plt.text(1.01, 0.18, \"Performance adjusted for schedule difficulty\", fontsize=8, verticalalignment='top', transform=ax2.transAxes)\n",
    "    plt.text(1.01, 0.15, \"Schedule-Adjusted Final Wins:\", fontsize=10, verticalalignment='top', transform=ax2.transAxes)\n",
    "    plt.text(1.01, 0.12, \"Expected win total versus the average expected win total\", fontsize=8, verticalalignment='top', transform=ax2.transAxes)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Improve the layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### running simulations - known games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_wins, team_loss = monte_carlo_simulation_known(1000, schedule_info, team_data)\n",
    "win_thresholds_in_season = analyze_simulation_known(team_wins, team_loss, schedule_info, records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_week = 1\n",
    "end_week = 16\n",
    "games_list = []\n",
    "for week in range(start_week,end_week):\n",
    "    response = games_api.get_games(year=current_year, week=week,division = 'fbs')\n",
    "    games_list = [*games_list, *response]\n",
    "if postseason:\n",
    "    response = games_api.get_games(year=current_year, division = 'fbs', season_type='postseason')\n",
    "    games_list = [*games_list, *response]\n",
    "games = [dict(\n",
    "            id=g.id,\n",
    "            season=g.season,\n",
    "            week=g.week,\n",
    "            start_date=g.start_date,\n",
    "            home_team=g.home_team,\n",
    "            home_elo=g.home_pregame_elo,\n",
    "            away_team=g.away_team,\n",
    "            away_elo=g.away_pregame_elo,\n",
    "            home_points = g.home_points,\n",
    "            away_points = g.away_points,\n",
    "            neutral = g.neutral_site\n",
    "            ) for g in games_list if g.home_pregame_elo is not None and g.away_pregame_elo is not None]\n",
    "games.sort(key=date_sort)\n",
    "year_long_schedule = pd.DataFrame(games)\n",
    "year_long_schedule = year_long_schedule.merge(team_data[['team', 'power_rating']], \n",
    "                                    left_on='home_team', \n",
    "                                    right_on='team', \n",
    "                                    how='left').rename(columns={'power_rating': 'home_pr'})\n",
    "year_long_schedule = year_long_schedule.drop(columns=['team'])\n",
    "year_long_schedule = year_long_schedule.merge(team_data[['team', 'power_rating']], \n",
    "                                    left_on='away_team', \n",
    "                                    right_on='team', \n",
    "                                    how='left').rename(columns={'power_rating': 'away_pr'})\n",
    "year_long_schedule = year_long_schedule.drop(columns=['team'])\n",
    "year_long_schedule['escape_win_prob'] = year_long_schedule.apply(\n",
    "    lambda row: ESCAPE_Win_Prob(row['home_pr'], row['away_pr']), axis=1\n",
    ")\n",
    "year_long_schedule['home_win_prob'] = round((10**((year_long_schedule['home_elo'] - year_long_schedule['away_elo']) / 400)) / ((10**((year_long_schedule['home_elo'] - year_long_schedule['away_elo']) / 400)) + 1)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_elo = elo_ratings['elo'].mean()\n",
    "average_pr = round(team_data['power_rating'].mean(), 2)\n",
    "good_team_pr = round(team_data['power_rating'].std() + team_data['power_rating'].mean(),2)\n",
    "elite_team_pr = round(2*team_data['power_rating'].std() + team_data['power_rating'].mean(),2)\n",
    "expected_wins_list = []\n",
    "for team in team_data['team']:\n",
    "    schedule = year_long_schedule[(year_long_schedule['home_team'] == team) | (year_long_schedule['away_team'] == team)]\n",
    "    df = average_team_distribution(1000, schedule, elite_team_pr, team)\n",
    "    expected_wins = df['expected_wins'].values[0]\n",
    "    expected_wins_list.append(expected_wins)\n",
    "SOS = pd.DataFrame(zip(team_data['team'], expected_wins_list), columns=['team', 'avg_expected_wins'])\n",
    "SOS = SOS.sort_values('avg_expected_wins').reset_index(drop = True)\n",
    "SOS['SOS'] = SOS.index + 1\n",
    "\n",
    "completed_games = year_long_schedule[year_long_schedule['home_points'].notna()]\n",
    "current_xWins_list = []\n",
    "good_xWins_list = []\n",
    "elite_xWins_list = []\n",
    "for team in team_data['team']:\n",
    "    team_completed_games = completed_games[(completed_games['home_team'] == team) | (completed_games['away_team'] == team)]\n",
    "    games_played = records[records['team'] == team]['games_played'].values[0]\n",
    "    wins = records[records['team'] == team]['wins'].values[0]\n",
    "    team_completed_games['avg_win_prob'] = np.where(team_completed_games['home_team'] == team,\n",
    "                                                    ESCAPE_Win_Prob(average_pr, team_completed_games['away_pr']),\n",
    "                                                    100 - ESCAPE_Win_Prob(team_completed_games['home_pr'], average_pr))\n",
    "    team_completed_games['good_win_prob'] = np.where(team_completed_games['home_team'] == team,\n",
    "                                                    ESCAPE_Win_Prob(good_team_pr, team_completed_games['away_pr']),\n",
    "                                                    100 - ESCAPE_Win_Prob(team_completed_games['home_pr'], good_team_pr))\n",
    "    team_completed_games['elite_win_prob']  = np.where(team_completed_games['home_team'] == team,\n",
    "                                                    ESCAPE_Win_Prob(elite_team_pr, team_completed_games['away_pr']),\n",
    "                                                    100 - ESCAPE_Win_Prob(team_completed_games['home_pr'], elite_team_pr))\n",
    "\n",
    "    # team_completed_games['avg_win_prob'] = np.where(team_completed_games['home_team'] == team, \n",
    "    #                             round((10**((average_elo-team_completed_games['away_elo']) / 400)) / ((10**((average_elo-team_completed_games['away_elo']) / 400)) + 1)*100, 2), \n",
    "    #                             100 - round((10**((team_completed_games['home_elo'] - average_elo) / 400)) / ((10**((team_completed_games['home_elo']- average_elo) / 400)) + 1)*100, 2))\n",
    "    current_xWins = round(sum(team_completed_games['avg_win_prob']) / 100, 2)\n",
    "    good_xWins = round(sum(team_completed_games['good_win_prob']) / 100, 2)\n",
    "    elite_xWins = round(sum(team_completed_games['elite_win_prob']) / 100, 2)\n",
    "    if games_played != len(team_completed_games):\n",
    "        current_xWins += 1\n",
    "        good_xWins += 1\n",
    "        elite_xWins += 1\n",
    "    relative_current_xWins = round(wins - current_xWins, 2)\n",
    "    relative_good_xWins = round(wins - good_xWins, 2)\n",
    "    relative_elite_xWins = round(wins - elite_xWins, 2)\n",
    "    current_xWins_list.append(relative_current_xWins)\n",
    "    good_xWins_list.append(relative_good_xWins)\n",
    "    elite_xWins_list.append(relative_elite_xWins)\n",
    "SOR = pd.DataFrame(zip(team_data['team'], current_xWins_list, good_xWins_list, elite_xWins_list), columns=['team','wins_above_average','wins_above_good','wins_above_elite'])\n",
    "SOR = SOR.sort_values('wins_above_average', ascending=False).reset_index(drop=True)\n",
    "SOR['SOR'] = SOR.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "num_12_pr = team_data['power_rating'][11]\n",
    "num_12_elo = elo_ratings.sort_values('elo', ascending=False)[11:12]['elo'].values[0]\n",
    "completed_games = year_long_schedule[year_long_schedule['home_points'].notna()]\n",
    "completed_games['margin_of_victory'] = completed_games['home_points'] - completed_games['away_points']\n",
    "standard_deviation = abs(completed_games['margin_of_victory']).std()\n",
    "\n",
    "team_probabilities = []\n",
    "for team in team_data['team']:\n",
    "    team_games = completed_games[\n",
    "        (completed_games['home_team'] == team) | (completed_games['away_team'] == team)\n",
    "    ]\n",
    "    team_games = team_games.dropna()\n",
    "    total_probability = 0\n",
    "    for _, game in team_games.iterrows():\n",
    "        if game['home_team'] == team:\n",
    "            twelve_expected_margin = (\n",
    "                4.6 + num_12_pr - team_data.loc[team_data['team'] == game['away_team'], 'power_rating'].values[0]\n",
    "            )\n",
    "            expected_margin = (\n",
    "                4.6 + team_data.loc[team_data['team'] == game['home_team'], 'power_rating'].values[0] - team_data.loc[team_data['team'] == game['away_team'], 'power_rating'].values[0]\n",
    "            )\n",
    "            actual_margin = game['margin_of_victory']\n",
    "        else:\n",
    "            expected_margin = (\n",
    "                team_data.loc[team_data['team'] == game['away_team'], 'power_rating'].values[0] - (team_data.loc[team_data['team'] == game['home_team'], 'power_rating'].values[0] + 4.6)\n",
    "            )\n",
    "            twelve_expected_margin = (\n",
    "                num_12_pr - (team_data.loc[team_data['team'] == game['home_team'], 'power_rating'].values[0] + 4.6)\n",
    "            )\n",
    "            actual_margin = -game['margin_of_victory']  # Reverse for away games\n",
    "        z_score = (actual_margin - expected_margin) / standard_deviation\n",
    "        twelve_score = (actual_margin - twelve_expected_margin) / standard_deviation\n",
    "        probability = norm.cdf(z_score) - 0.5\n",
    "        twelve_probability = 1 - norm.cdf(twelve_score)\n",
    "\n",
    "        # relative to your own expectation\n",
    "        total_probability += (probability)\n",
    "\n",
    "        # relative to the number 12 team\n",
    "        # total_probability += (probability - twelve_probability)\n",
    "        \n",
    "    team_probabilities.append({'team': team, 'RTP': (total_probability/ len(team_games))})\n",
    "\n",
    "RTP = pd.DataFrame(team_probabilities)\n",
    "RTP = RTP.sort_values(by='RTP', ascending=False)\n",
    "RTP['RTP'] = 10 + (10 * RTP['RTP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_12_pr = team_data['power_rating'][11]\n",
    "\n",
    "# Ensure MOV is calculated in the completed_games DataFrame\n",
    "completed_games = year_long_schedule[year_long_schedule['home_points'].notna()]\n",
    "completed_games['margin_of_victory'] = completed_games['home_points'] - completed_games['away_points']\n",
    "\n",
    "# Function to scale MOV\n",
    "def f(mov):\n",
    "    return np.clip(np.log(abs(mov) + 1) * np.sign(mov), -10, 10)\n",
    "\n",
    "current_xWins_list = []\n",
    "\n",
    "for team in team_data['team']:\n",
    "    # Filter completed games for the current team\n",
    "    team_completed_games = completed_games[(completed_games['home_team'] == team) | (completed_games['away_team'] == team)]\n",
    "    \n",
    "    # Get the current team's record\n",
    "    games_played = records[records['team'] == team]['games_played'].values[0]\n",
    "    wins = records[records['team'] == team]['wins'].values[0]\n",
    "    \n",
    "    # Adjust win probability with MOV influence\n",
    "    team_completed_games['avg_win_prob'] = np.where(\n",
    "        team_completed_games['home_team'] == team,\n",
    "        ESCAPE_Win_Prob(num_12_pr, team_completed_games['away_pr']) + f(team_completed_games['margin_of_victory']),\n",
    "        100 - ESCAPE_Win_Prob(team_completed_games['home_pr'], num_12_pr) - f(-team_completed_games['margin_of_victory'])\n",
    "    )\n",
    "    \n",
    "    # Calculate expected wins (xWins)\n",
    "    current_xWins = round(sum(team_completed_games['avg_win_prob']) / 100, 3)\n",
    "    \n",
    "    # Adjust for incomplete games\n",
    "    if games_played != len(team_completed_games):\n",
    "        current_xWins += 1\n",
    "    \n",
    "    # Calculate relative xWins (wins vs. expected wins)\n",
    "    relative_current_xWins = round(wins - current_xWins, 3)\n",
    "    current_xWins_list.append(relative_current_xWins)\n",
    "\n",
    "# Create the \"most deserving\" DataFrame\n",
    "most_deserving = pd.DataFrame(zip(team_data['team'], current_xWins_list), columns=['team', 'wins_above_average'])\n",
    "most_deserving = most_deserving.sort_values('wins_above_average', ascending=False).reset_index(drop=True)\n",
    "most_deserving['Performance'] = most_deserving.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_conference_map = team_data.set_index('team')['conference'].to_dict()\n",
    "year_long_schedule['home_conference'] = year_long_schedule['home_team'].map(team_conference_map)\n",
    "year_long_schedule['away_conference'] = year_long_schedule['away_team'].map(team_conference_map)\n",
    "\n",
    "conference_list = list(team_data['conference'].unique())\n",
    "all_conference_wins = pd.DataFrame()\n",
    "# Filter year_long_schedule where both home_conference and away_conference match conference_list[0]\n",
    "for i in range(len(conference_list)):\n",
    "    conference_schedule = year_long_schedule[\n",
    "        (year_long_schedule['home_conference'] == conference_list[i]) &\n",
    "        (year_long_schedule['away_conference'] == conference_list[i])\n",
    "    ]\n",
    "    conference_team_data = team_data[team_data['conference'] == conference_list[i]]\n",
    "    uncompleted_conference_games = conference_schedule[conference_schedule['home_points'].isna()]\n",
    "    wins, losses = monte_carlo_simulation_conference(1000, uncompleted_conference_games, conference_team_data)\n",
    "    conference_wins = analyze_simulation_conference(wins, losses, uncompleted_conference_games, records)\n",
    "    conference_wins['conference'] = conference_list[i]\n",
    "    conference_wins = conference_wins.sort_values('expected_wins', ascending=False).reset_index(drop=True)\n",
    "    all_conference_wins = pd.concat([all_conference_wins, conference_wins])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### every game overview for the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "configuration = cfbd.Configuration()\n",
    "configuration.api_key['Authorization'] = '7vGedNNOrnl0NGcSvt92FcVahY602p7IroVBlCA1Tt+WI/dCwtT7Gj5VzmaHrrxS'\n",
    "configuration.api_key_prefix['Authorization'] = 'Bearer'\n",
    "api_client = cfbd.ApiClient(configuration)\n",
    "\n",
    "advanced_instance = cfbd.StatsApi(api_client)\n",
    "\n",
    "games_api = cfbd.GamesApi(api_client)\n",
    "\n",
    "betting_api = cfbd.BettingApi(api_client)\n",
    "\n",
    "ratings_api = cfbd.RatingsApi(api_client)\n",
    "\n",
    "teams_api = cfbd.TeamsApi(api_client)\n",
    "\n",
    "metrics_api = cfbd.MetricsApi(api_client)\n",
    "\n",
    "players_api = cfbd.PlayersApi(api_client)\n",
    "\n",
    "recruiting_api = cfbd.RecruitingApi(api_client)\n",
    "def date_sort(game):\n",
    "    game_date = datetime.datetime.strptime(game['start_date'], \"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "    return game_date\n",
    "\n",
    "if postseason:\n",
    "    games = []\n",
    "    response = games_api.get_games(year=current_year, division = 'fbs', season_type='postseason')\n",
    "    games = [*games, *response]\n",
    "else:\n",
    "    games = []\n",
    "    response = games_api.get_games(year=current_year, week = current_week, division = 'fbs')\n",
    "    games = [*games, *response]\n",
    "\n",
    "games = [dict(\n",
    "            id=g.id,\n",
    "            season=g.season,\n",
    "            week=g.week,\n",
    "            start_date=g.start_date,\n",
    "            home_team=g.home_team,\n",
    "            home_conference=g.home_conference,\n",
    "            home_points=g.home_points,\n",
    "            home_elo=g.home_pregame_elo,\n",
    "            away_team=g.away_team,\n",
    "            away_conference=g.away_conference,\n",
    "            away_points=g.away_points,\n",
    "            away_elo=g.away_pregame_elo,\n",
    "            neutral = g.neutral_site\n",
    "            ) for g in games if g.home_pregame_elo is not None and g.away_pregame_elo is not None]\n",
    "games.sort(key=date_sort)\n",
    "week_games = pd.DataFrame(games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, game in week_games.iterrows():\n",
    "    away_team = game['away_team'].strip()\n",
    "    home_team = game['home_team'].strip()\n",
    "    neutral = game['neutral']\n",
    "    plot_matchup(win_thresholds_in_season, all_conference_wins, \n",
    "                        logos, team_data, last_week_data, last_month_data, \n",
    "                        start_season_data, all_data, year_long_schedule, records, SOS, SOR, most_deserving, home_team, away_team, neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### individual game overviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "away_team = \"Ohio State\"\n",
    "home_team = \"Notre Dame\"\n",
    "plot_matchup(win_thresholds_in_season, all_conference_wins, \n",
    "                        logos, team_data, last_week_data, last_month_data, \n",
    "                        start_season_data, all_data, year_long_schedule, records, SOS, SOR, most_deserving, home_team, away_team, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### team stat visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_stats_visual(all_data, records, schedule_info, logos, team):\n",
    "\n",
    "    cmap = LinearSegmentedColormap.from_list('dark_gradient_orange', ['#660000', '#8B0000', '#808080', '#2C5E00', '#1D4D00'], N=100)\n",
    "    def get_color(value, vmin=0, vmax=100):\n",
    "        norm_value = (value - vmin) / (vmax - vmin)  # Normalize the value between 0 and 1\n",
    "        return cmap(norm_value)  # Get the color from the colormap\n",
    "    \n",
    "    def get_rank_color(number):\n",
    "        \"\"\"\n",
    "        Returns a hex color code based on a number between 1 and 134.\n",
    "        \n",
    "        Parameters:\n",
    "            number (int): A number between 1 and 134.\n",
    "        \n",
    "        Returns:\n",
    "            str: Hex color code corresponding to the input number.\n",
    "        \"\"\"\n",
    "        if not 1 <= number <= 134:\n",
    "            raise ValueError(\"Number must be between 1 and 134\")\n",
    "        \n",
    "        # Define the color gradient points\n",
    "        gradient = [\n",
    "            (1, '#1D4D00'),    # Start green\n",
    "            (35, '#2C5E00'),   # Midpoint green\n",
    "            (67, '#808080'),   # Grey\n",
    "            (105, '#8B0000'),  # Red in the middle\n",
    "            (134, '#660000')   # End dark red\n",
    "        ]\n",
    "        \n",
    "        # Convert hex to RGB\n",
    "        def hex_to_rgb(hex_color):\n",
    "            hex_color = hex_color.lstrip('#')\n",
    "            return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "        \n",
    "        # Convert RGB to hex\n",
    "        def rgb_to_hex(rgb):\n",
    "            return '#' + ''.join(f'{int(c):02X}' for c in rgb)\n",
    "        \n",
    "        # Interpolate between two colors\n",
    "        def interpolate_color(color1, color2, fraction):\n",
    "            return tuple(\n",
    "                color1[i] + (color2[i] - color1[i]) * fraction\n",
    "                for i in range(3)\n",
    "            )\n",
    "        \n",
    "        # Find the range that includes the number\n",
    "        for i in range(len(gradient) - 1):\n",
    "            start, end = gradient[i], gradient[i + 1]\n",
    "            if start[0] <= number <= end[0]:\n",
    "                fraction = (number - start[0]) / (end[0] - start[0])\n",
    "                start_rgb, end_rgb = hex_to_rgb(start[1]), hex_to_rgb(end[1])\n",
    "                interpolated_rgb = interpolate_color(start_rgb, end_rgb, fraction)\n",
    "                return rgb_to_hex(interpolated_rgb)\n",
    "        \n",
    "        # Fallback (should not reach here)\n",
    "        return '#000000'\n",
    "\n",
    "    team_logo_url = logos[logos['team'] == team]['logo'].values[0][0]\n",
    "    response = requests.get(team_logo_url)\n",
    "    logo_img = Image.open(BytesIO(response.content))\n",
    "\n",
    "    scaler100 = MinMaxScaler(feature_range=(1,100))\n",
    "    all_data['talent_scaled_percentile'] = scaler100.fit_transform(all_data[['talent_scaled']])\n",
    "    all_data['offensive_total_scaled'] = scaler100.fit_transform(all_data[['offensive_total']])\n",
    "    all_data['defensive_total_scaled'] = scaler100.fit_transform(all_data[['defensive_total']])\n",
    "    all_data['stm_scaled'] = scaler100.fit_transform(all_data[['STM']])\n",
    "    pbr_min = all_data['PBR'].min()\n",
    "    pbr_max = all_data['PBR'].max()\n",
    "    all_data['pbr_scaled'] = 100 - (all_data['PBR'] - pbr_min) * 99 / (pbr_max - pbr_min)\n",
    "    all_data['dce_scaled'] = scaler100.fit_transform(all_data[['DCE']])\n",
    "    all_data['dde_scaled'] = scaler100.fit_transform(all_data[['DDE']])\n",
    "    all_data['most_deserving_scaled'] = scaler100.fit_transform(all_data[['most_deserving_wins']])\n",
    "    all_data['talent_performance'] = (all_data['most_deserving_scaled'] - all_data['avg_talent']) / math.sqrt(2)\n",
    "    all_data['talent_performance_scaled'] = scaler100.fit_transform(all_data[['talent_performance']])\n",
    "    all_data['TPG_rank'] = all_data['talent_performance_scaled'].rank(method='min', ascending=False)\n",
    "\n",
    "    wins = records[records['team'] == team]['wins'].values[0]\n",
    "    losses = records[records['team'] == team]['losses'].values[0]\n",
    "    conference_wins = records[records['team'] == team]['conference_wins'].values[0]\n",
    "    conference_losses = records[records['team'] == team]['conference_losses'].values[0]\n",
    "    \n",
    "    color = all_data[all_data['team'] == team]['color'].values[0]\n",
    "    alt_color = all_data[all_data['team'] == team]['alt_color'].values[0]\n",
    "\n",
    "    power_rating = all_data[all_data['team'] == team]['power_rating'].values[0]\n",
    "    rank = all_data[all_data['team'] == team].index[0] + 1\n",
    "    MD = all_data[all_data['team'] == team]['most_deserving'].values[0]\n",
    "    SOR = all_data[all_data['team'] == team]['SOR'].values[0]\n",
    "    SOS = all_data[all_data['team'] == team]['SOS'].values[0]\n",
    "    PBR_rank = int(all_data[all_data['team'] == team]['PBR_rank'].values[0])\n",
    "    DCE_rank = int(all_data[all_data['team'] == team]['DCE_rank'].values[0])\n",
    "    DDE_rank = int(all_data[all_data['team'] == team]['DDE_rank'].values[0])\n",
    "    offensive_rank = all_data[all_data['team'] == team]['offensive_rank'].values[0]\n",
    "    defensive_rank = all_data[all_data['team'] == team]['defensive_rank'].values[0]\n",
    "    stm_rank = int(all_data[all_data['team'] == team]['STM_rank'].values[0])\n",
    "    talent_rank = int(all_data[all_data['team'] == team]['talent_scaled_rank'].values[0])\n",
    "    offense_success_rank = int(all_data[all_data['team'] == team]['offense_success_rank'].values[0])\n",
    "    offense_explosive_rank = int(all_data[all_data['team'] == team]['offense_explosive_rank'].values[0])\n",
    "    defense_success_rank = int(all_data[all_data['team'] == team]['defense_success_rank'].values[0])\n",
    "    defense_explosive_rank = int(all_data[all_data['team'] == team]['defense_explosive_rank'].values[0])\n",
    "    turnover_rank = int(all_data[all_data['team'] == team]['total_turnovers_rank'].values[0])\n",
    "    penalties_rank = int(all_data[all_data['team'] == team]['penalties_rank'].values[0])\n",
    "    tpg_rank = int(all_data[all_data['team'] == team]['TPG_rank'].values[0])\n",
    "\n",
    "    offensive_total = round(all_data[all_data['team'] == team]['offensive_total_scaled'].values[0])\n",
    "    defensive_total = round(all_data[all_data['team'] == team]['defensive_total_scaled'].values[0])\n",
    "    stm = round(all_data[all_data['team'] == team]['stm_scaled'].values[0])\n",
    "    offense_success = round(all_data[all_data['team'] == team]['offense_success_scaled'].values[0])\n",
    "    offense_explosive = round(all_data[all_data['team'] == team]['offense_explosive'].values[0])\n",
    "    defense_success = round(all_data[all_data['team'] == team]['defense_success_scaled'].values[0])\n",
    "    defense_explosive = round(all_data[all_data['team'] == team]['defense_explosive'].values[0])\n",
    "    tpg = round(all_data[all_data['team'] == team]['talent_performance_scaled'].values[0])\n",
    "    pbr = round(all_data[all_data['team'] == team]['pbr_scaled'].values[0])\n",
    "    dce = round(all_data[all_data['team'] == team]['dce_scaled'].values[0])\n",
    "    dde = round(all_data[all_data['team'] == team]['dde_scaled'].values[0])\n",
    "\n",
    "    categories = [\n",
    "        'OFF', 'DEF', 'DEF S', 'DEF E',\n",
    "        'DDE', 'TPG', 'ST',\n",
    "        'DCE', 'OFF E', 'OFF S'\n",
    "    ]\n",
    "    values = [\n",
    "        offensive_total, defensive_total, defense_success, defense_explosive,\n",
    "        dde, tpg, stm,\n",
    "        dce, offense_explosive, offense_success\n",
    "    ]\n",
    "\n",
    "    # Close the circle for the radar chart\n",
    "    values.append(values[0])  # Add the first value to close the circle\n",
    "\n",
    "    # Angle for each category\n",
    "    num_vars = len(categories)\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    angles.append(angles[0])  # Add the starting angle to close the circle\n",
    "\n",
    "    # Plot the spider chart\n",
    "    fig, ax = plt.subplots(figsize=(12, 8), subplot_kw=dict(polar=True))\n",
    "    ax.set_theta_offset((np.pi/2) - ((angles[0] + angles[1]) / 2))\n",
    "    fig.set_facecolor('#5fa391')\n",
    "    ax.set_facecolor('#5fa391')\n",
    "    ax.fill(angles, values, color=color, alpha=0.6)\n",
    "    ax.plot(angles, values, color=color, linewidth=5)\n",
    "    ax.set_yticks([25, 50, 75, 102])\n",
    "    ax.set_yticklabels(['25', '50', '75', '100'], color=\"white\")\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(categories, fontsize=10)\n",
    "\n",
    "    plt.text(\n",
    "        0.5, 1.1, team,\n",
    "        ha='center',\n",
    "        transform=ax.transAxes,\n",
    "        fontweight='bold',\n",
    "        fontsize=16,\n",
    "        color='#FFFFFF',\n",
    "        bbox=dict(\n",
    "            boxstyle='square,pad=0.3',  # Rounded box with padding\n",
    "            edgecolor='none',          # No border\n",
    "            facecolor=color,         # Box background color\n",
    "            alpha=0.7                  # Transparency\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # image_box = OffsetImage(logo_img, zoom=0.3)  # Adjust zoom as needed\n",
    "    # image_annot = AnnotationBbox(\n",
    "    #     image_box,\n",
    "    #     (-0.2, -0.05),  # Adjust position directly under the text\n",
    "    #     frameon=False,\n",
    "    #     xycoords='axes fraction'\n",
    "    # )\n",
    "    # plt.gca().add_artist(image_annot)\n",
    "\n",
    "    plt.text(-0.8,1.1, f\"Record: {wins} - {losses} ({conference_wins} - {conference_losses})\", ha='left', fontweight='bold', fontsize = 18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,1.02, f\"Rating: {power_rating} (#{rank})\", ha='left', fontweight='bold', fontsize = 18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,0.94, f\"Offense: #{offensive_rank}\", fontweight='bold', ha ='left', color=get_rank_color(offensive_rank), fontsize = 18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,0.86, f\"Defense: #{defensive_rank}\", fontweight='bold', ha ='left', color=get_rank_color(defensive_rank), fontsize = 18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,0.78, f\"Special Teams: #{stm_rank}\", fontweight='bold', ha ='left', color=get_rank_color(stm_rank), fontsize = 18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,0.70, f\"Talent: #{talent_rank}\", fontweight='bold', ha='left', color=get_rank_color(talent_rank), fontsize=18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,0.62, f\"OFF Success: #{offense_success_rank}\", fontweight='bold', ha='left', color=get_rank_color(offense_success_rank), fontsize=18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,0.54, f\"OFF Explosiveness: #{offense_explosive_rank}\", fontweight='bold', ha='left', color=get_rank_color(offense_explosive_rank), fontsize=18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,0.46, f\"DEF Success: #{defense_success_rank}\", fontweight='bold', ha='left', color=get_rank_color(defense_success_rank), fontsize=18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,0.38, f\"DEF Explosiveness: #{defense_explosive_rank}\", fontweight='bold', ha='left', color=get_rank_color(defense_explosive_rank), fontsize=18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,0.30, f\"Turnovers: #{turnover_rank}\", fontweight='bold', ha='left', color=get_rank_color(turnover_rank), fontsize=18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,0.22, f\"Penalties: #{penalties_rank}\", fontweight='bold', ha='left', color=get_rank_color(penalties_rank), fontsize=18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,0.14, f\"Most Deserving: #{MD}\", ha='left', fontweight='bold', color=get_rank_color(MD), fontsize = 18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,0.06, f\"SOR: #{SOR}\", ha='left', fontweight='bold', color=get_rank_color(SOR), fontsize = 18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,-0.02, f\"SOS: #{SOS}\", ha='left', fontweight='bold', color=get_rank_color(SOS), fontsize = 18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,-0.10, f\"DCE: #{DCE_rank}\", ha='left', fontweight='bold', color=get_rank_color(DCE_rank), fontsize = 18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,-0.18, f\"DDE: #{DDE_rank}\", ha='left', fontweight='bold', color=get_rank_color(DDE_rank), fontsize = 18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,-0.26, f\"PBR: #{PBR_rank}\", ha='left', fontweight='bold', color=get_rank_color(PBR_rank), fontsize = 18, transform=ax.transAxes)\n",
    "    plt.text(-0.8,-0.34, f\"TPG: #{tpg_rank}\", ha='left', fontweight='bold', color=get_rank_color(tpg_rank), fontsize = 18, transform=ax.transAxes)\n",
    "\n",
    "    entire_schedule = schedule_info.copy()\n",
    "    completed_games = schedule_info[schedule_info['home_points'].notna()]\n",
    "    schedule_info = schedule_info[schedule_info['home_points'].isna()]\n",
    "\n",
    "    team_completed_games = completed_games[(completed_games['home_team'] == team) | (completed_games['away_team'] == team)]\n",
    "    team_completed_games['team_win_prob'] = np.where(team_completed_games['home_team'] == team, \n",
    "                                    team_completed_games['escape_win_prob'], \n",
    "                                    100 - team_completed_games['escape_win_prob'])\n",
    "    games_played = records[records['team'] == team]['games_played'].values[0]\n",
    "    difference = games_played - len(team_completed_games)\n",
    "    expected_wins = round((team_completed_games['team_win_prob'] / 100).sum(),1)\n",
    "    expected_wins = round(expected_wins + (difference * 0.95),1)\n",
    "    expected_losses = round(games_played - expected_wins,1)\n",
    "\n",
    "    \n",
    "    def get_color_future(w_l):\n",
    "        if w_l <= 0:\n",
    "            return '#1D4D00'\n",
    "        else:\n",
    "            return '#660000'\n",
    "\n",
    "    def get_color_wl(w_l):\n",
    "        if w_l == \"W\":\n",
    "            return '#1D4D00'\n",
    "        else:\n",
    "            return '#660000'\n",
    "\n",
    "    def find_team_spread(game, team_data, team_name, home_team, away_team, neutral):\n",
    "        home_rating = all_data[all_data['team'] == home_team]['power_rating'].values[0]\n",
    "        away_rating = all_data[all_data['team'] == away_team]['power_rating'].values[0]\n",
    "        home_win_prob = game['home_win_prob']\n",
    "        def adjust_home_pr(home_win_prob):\n",
    "            return ((home_win_prob - 50) / 50) * 5\n",
    "        def round_to_nearest_half(x):\n",
    "            return np.round(x * 2) / 2 \n",
    "        if neutral:\n",
    "            spread = round((home_rating + adjust_home_pr(home_win_prob) - away_rating),1)\n",
    "        else:\n",
    "            spread = round((4.6 + home_rating + adjust_home_pr(home_win_prob) - away_rating),1)\n",
    "        if (home_team == team_name) & (spread > 0):\n",
    "            output = \"-\" + str(spread)\n",
    "        elif (home_team == team_name) & (spread < 0):\n",
    "            output = \"+\" + str(abs(spread))\n",
    "        elif (home_team != team_name) & (spread < 0):\n",
    "            output = str(spread)\n",
    "        elif (spread == 0.0):\n",
    "            output = str(spread)\n",
    "        else:\n",
    "            output = \"+\" + str(spread)\n",
    "\n",
    "        return output, spread\n",
    "    \n",
    "    def add_spreads(schedule_info, team_data, team_name):\n",
    "        # Define a helper function to apply the find_team_spread to each row\n",
    "        def compute_spread(row):\n",
    "            # Extract relevant data from the current row\n",
    "            home_team = row['home_team']\n",
    "            away_team = row['away_team']\n",
    "            neutral = row['neutral']\n",
    "            \n",
    "            # Call the find_team_spread function with this row's data\n",
    "            spread_str, raw_spread = find_team_spread(row, team_data, team_name, home_team, away_team, neutral)\n",
    "            \n",
    "            # Return both values as a tuple, so we can unpack them into two columns\n",
    "            return pd.Series([spread_str, raw_spread])\n",
    "\n",
    "        # Apply the compute_spread function to each row of the DataFrame\n",
    "        schedule_info[['spread', 'raw_spread']] = schedule_info.apply(compute_spread, axis=1)\n",
    "        \n",
    "        return schedule_info\n",
    "\n",
    "    # Example of calling the function\n",
    "    schedule_info = add_spreads(schedule_info, team_data, team)\n",
    "    team_schedule = schedule_info[(schedule_info['home_team'] == team) | (schedule_info['away_team'] == team)].reset_index()\n",
    "    team_schedule['raw_spread'] = pd.to_numeric(team_schedule['spread'], errors='coerce')\n",
    "\n",
    "    j = 0.98\n",
    "    font_size = 12\n",
    "    # Completed games section\n",
    "    plt.text(1.8, 1.1, f\"Expected Record: {expected_wins} - {expected_losses}\", ha='right', fontweight='bold', fontsize=18, transform=ax.transAxes)\n",
    "    plt.text(1.8, 1.02, \"FCS Games Not Included in Schedule\", fontsize=font_size, ha='right', transform=ax.transAxes, fontweight='bold')\n",
    "\n",
    "    for i, game in team_completed_games.iterrows():\n",
    "        neutral = game['neutral']\n",
    "        week = game['week']\n",
    "        home_team = game['home_team']\n",
    "        away_team = game['away_team']\n",
    "        home_points = game['home_points']\n",
    "        away_points = game['away_points']\n",
    "\n",
    "        # Determine win/loss\n",
    "        if home_team == team:\n",
    "            w_l = 'W' if home_points > away_points else 'L'\n",
    "        else:\n",
    "            w_l = 'L' if home_points > away_points else 'W'\n",
    "\n",
    "        # Display week and opponent\n",
    "        plt.text(1.13, j, f\"{week}\", fontsize=font_size, ha='right', transform=ax.transAxes, fontweight='bold')\n",
    "        if neutral:\n",
    "            opponent = away_team if home_team == team else home_team\n",
    "            opponent_rank = team_data[team_data['team'] == opponent].index[0] + 1\n",
    "            location = \"(N)\"\n",
    "        else:\n",
    "            opponent = away_team if home_team == team else home_team\n",
    "            opponent_rank = team_data[team_data['team'] == opponent].index[0] + 1\n",
    "            location = \"vs.\" if home_team == team else \"@\"\n",
    "        plt.text(1.14, j, f\"{location} {opponent} (#{opponent_rank})\", fontsize=font_size, ha='left', transform=ax.transAxes, color=get_color_wl(w_l), fontweight='bold')\n",
    "\n",
    "        # Display score\n",
    "        score = f\"{int(home_points)}-{int(away_points)}\" if home_points > away_points else f\"{int(away_points)}-{int(home_points)}\"\n",
    "        plt.text(1.8, j, score, fontsize=font_size, ha='right', transform=ax.transAxes, color=get_color_wl(w_l), fontweight='bold')\n",
    "\n",
    "        j -= 0.04\n",
    "\n",
    "    for i, game in team_schedule.iterrows():\n",
    "        neutral = game['neutral']\n",
    "        week = game['week']\n",
    "        spread = game['spread']\n",
    "        raw_spread = game['raw_spread']\n",
    "        home_team = game['home_team']\n",
    "        away_team = game['away_team']\n",
    "\n",
    "        # Display week and opponent\n",
    "        plt.text(1.13, j, f\"{week}\", fontsize=font_size, ha='right', transform=ax.transAxes, fontweight='bold')\n",
    "        if neutral:\n",
    "            opponent = away_team if home_team == team else home_team\n",
    "            opponent_rank = team_data[team_data['team'] == opponent].index[0] + 1\n",
    "            location = \"(N)\"\n",
    "        else:\n",
    "            opponent = away_team if home_team == team else home_team\n",
    "            opponent_rank = team_data[team_data['team'] == opponent].index[0] + 1\n",
    "            location = \"vs.\" if home_team == team else \"@\"\n",
    "        plt.text(1.14, j, f\"{location} {opponent} (#{opponent_rank})\", fontsize=font_size, ha='left', transform=ax.transAxes, fontweight='bold')\n",
    "\n",
    "        # Display spread\n",
    "        plt.text(1.8, j, f\"{spread}\", fontsize=font_size, ha='right', transform=ax.transAxes, color=get_color_future(raw_spread), fontweight='bold')\n",
    "\n",
    "        j -= 0.04\n",
    "\n",
    "\n",
    "\n",
    "    # plt.text(1.8,-0.02, \"All stats are percentile ranks\", ha='right', fontsize=12, transform = ax.transAxes)\n",
    "    plt.text(1.8,0.16, \"OFF - Total Offense\", ha='right', fontsize=12, transform = ax.transAxes)\n",
    "    plt.text(1.8,0.12, \"DEF - Total Defense\", ha='right', fontsize=12, transform = ax.transAxes)\n",
    "    plt.text(1.8,0.08, \"OFF S - Offense Success\", ha='right', fontsize=12, transform = ax.transAxes)\n",
    "    plt.text(1.8,0.04, \"OFF E - Offense Explosiveness\", ha='right', fontsize=12, transform = ax.transAxes)\n",
    "    plt.text(1.8,0, \"DEF S - Defense Success\", ha='right', fontsize=12, transform = ax.transAxes)\n",
    "    plt.text(1.8,-0.04, \"DEF E - Defense Explosiveness\", ha='right', fontsize=12, transform = ax.transAxes)\n",
    "    plt.text(1.8,-0.08, \"SOR - Strength of Record, how impressive is your record\", ha='right', fontsize=12, transform = ax.transAxes)\n",
    "    plt.text(1.8,-0.12, \"SOS - Strength of Schedule, how hard your schedule is\", ha='right', fontsize=12, transform = ax.transAxes)\n",
    "    plt.text(1.8,-0.16, \"DCE - Drive Control Efficiency, how well your offense controls the ball\", ha='right', fontsize=12, transform = ax.transAxes)\n",
    "    plt.text(1.8,-0.20, \"DDE - Drive Disruption Efficiency, how well your defense disrupts offenses\", ha='right', fontsize=12, transform = ax.transAxes)\n",
    "    plt.text(1.8,-0.24, \"PBR - Penalty Burden Ratio, how well your team limits or overcomes penalties\", ha='right', fontsize=12, transform = ax.transAxes)\n",
    "    plt.text(1.8,-0.28, \"TPG - Talent Performance Gap, your performance relative to your talent\", ha='right', fontsize=12, transform = ax.transAxes)\n",
    "    plt.text(0.5,-0.34, \"Figure: @EscapeRatingCFB | Data: @CFB_Data\", ha='center', fontsize=14, fontweight='bold', transform = ax.transAxes)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats_visual(all_data, records, year_long_schedule, logos, 'Notre Dame')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Achieving vs. Expections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_list = []\n",
    "completed_games = year_long_schedule.dropna()\n",
    "for team_name in team_data['team']:\n",
    "    wins = records[records['team'] == team_name]['wins'].values[0]\n",
    "    losses = records[records['team'] == team_name]['losses'].values[0]\n",
    "\n",
    "    team_completed_games = completed_games[(completed_games['home_team'] == team_name) | (completed_games['away_team'] == team_name)]\n",
    "    team_completed_games['team_win_prob'] = np.where(team_completed_games['home_team'] == team_name, \n",
    "                                    team_completed_games['escape_win_prob'], \n",
    "                                    100 - team_completed_games['escape_win_prob'])\n",
    "    completed_expected_wins = round(sum(team_completed_games['team_win_prob']) / 100, 2)\n",
    "    completed_expected_losses = round(len(team_completed_games) - completed_expected_wins, 1)\n",
    "    games_played = wins + losses\n",
    "    if len(team_completed_games) != games_played:\n",
    "        completed_expected_wins = completed_expected_wins + 1\n",
    "    performance = wins - completed_expected_wins\n",
    "    performance_list.append(performance)\n",
    "current_performance = pd.DataFrame(zip(team_data['team'], performance_list), columns = ['team', 'performance'])\n",
    "\n",
    "best_and_worst(current_performance, logos, 'performance', f'Week {current_week} ESCAPE Overperformers and Underperformers', \"Wins ABOVE or BELOW Your Retroactive Win Expectation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Deserving Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_and_worst(most_deserving, logos, 'wins_above_average', f'Week {current_week} Most Deserving', \"Performance Against Schedule Relative to the No. 12 Power Rated Team\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Most Deserving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "# Define the number of rows and columns\n",
    "n_teams = len(team_data)\n",
    "n_columns = (n_teams // 20) + (1 if n_teams % 20 != 0 else 0)\n",
    "\n",
    "# Plot configuration\n",
    "fig, axes = plt.subplots(nrows=20, ncols=n_columns, figsize=(20, 10),dpi=125)\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "fig.patch.set_facecolor('#5fa391')\n",
    "plt.suptitle(f'Week {current_week} ESCAPE Most Deserving Ratings.', fontsize=14, y=0.92, x=0.55)\n",
    "\n",
    "min_rating = most_deserving['wins_above_average'].min()\n",
    "max_rating = most_deserving['wins_above_average'].max()\n",
    "rating_range = max_rating-min_rating\n",
    "\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list('dark_gradient_orange', ['#660000', '#8B0000', '#CC5500', '#2C5E00', '#1D4D00'], N=rating_range)\n",
    "\n",
    "def get_color(value, vmin=min_rating, vmax=max_rating):\n",
    "    norm_value = (value - vmin) / (vmax - vmin)  # Normalize the value between 0 and 1\n",
    "    return cmap(norm_value)  # Get the color from the colormap\n",
    "\n",
    "# Define a colormap from red to green\n",
    "cmap = plt.get_cmap('RdYlGn')\n",
    "\n",
    "def get_color(power_rating):\n",
    "    \"\"\"Return a color based on the power rating normalized to a range between 0 and 1.\"\"\"\n",
    "    norm_rating = (power_rating - min_rating) / (max_rating - min_rating)\n",
    "    return cmap(norm_rating)\n",
    "\n",
    "# Iterate through the data to plot\n",
    "for idx, team in most_deserving.iterrows():\n",
    "    power_rating = team['wins_above_average']\n",
    "    team_name = team['team']\n",
    "    logo_url = logos[logos['team'] == team_name]['logo'].values[0][0]\n",
    "    row = idx % 20\n",
    "    col = idx // 20\n",
    "    \n",
    "    ax = axes[row, col]\n",
    "    ax.axis('off')  # Turn off the axis\n",
    "    \n",
    "    # Fetch the logo image from URL and display it\n",
    "    response = requests.get(logo_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    ax.imshow(img)\n",
    "\n",
    "    # Get the color for the current power rating\n",
    "    color = get_color(power_rating)\n",
    "\n",
    "    text_ax = ax.inset_axes([0.2, 0.3, 0.75, 0.5])  # Move the text box to the right of the logo\n",
    "    text_ax.axis('off')  # Turn off the text axis\n",
    "\n",
    "    # Get the color for the current power rating\n",
    "    color = get_color(power_rating)\n",
    "\n",
    "    # Display the rank\n",
    "    text_ax.text(-1.2, 0.5, f\"#{idx + 1}\", ha='center', va='center', fontsize=8, color='black', transform=text_ax.transAxes, fontweight='bold')\n",
    "\n",
    "    # Display the team name to the right of the logo\n",
    "    text_ax.text(1.5, 0.5, f\"{team_name}\", ha='left', va='center', fontsize=6, color='black', transform=text_ax.transAxes)\n",
    "\n",
    "    # Display the power rating in a separate line with its color\n",
    "    text_ax.text(6.5, 0.5, f\"{power_rating:.2f}\", ha='left', va='center', fontsize=8, color='black', transform=text_ax.transAxes, fontweight='bold')\n",
    "\n",
    "    text_ax.text(9, 0.9, \"|\", ha='left', va='center', fontsize=14, color='black', transform=text_ax.transAxes, fontweight='bold')\n",
    "    text_ax.text(9, -0.6, \"|\", ha='left', va='center', fontsize=14, color='black', transform=text_ax.transAxes, fontweight='bold')\n",
    "    \n",
    "\n",
    "if n_teams % 20 != 0:\n",
    "    for empty_row in range(n_teams % 20, 20):\n",
    "        axes[empty_row, n_columns - 1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Deserving Playoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "most_deserving_playoff = most_deserving.merge(team_data[['team', 'conference']], on='team', how='left')\n",
    "# most_deserving_playoff = most_deserving_playoff[~(most_deserving_playoff['team'] == 'BYU')][0:25]\n",
    "# most_deserving_playoff = most_deserving_playoff[~(most_deserving_playoff['team'] == 'Army')][0:25]\n",
    "conference_list = ['SEC', 'Big Ten', 'Big 12', 'ACC', 'Conference USA', 'Mid-American', 'Sun Belt', 'American Athletic', 'Mountain West']\n",
    "\n",
    "\n",
    "# top_4_seeds = most_deserving_playoff[most_deserving_playoff['conference'].isin(conference_list)].groupby('conference').first().sort_values('wins_above_average', ascending=False).reset_index()[0:4]\n",
    "# autobid_5 = most_deserving_playoff[most_deserving_playoff['conference'].isin(conference_list)].groupby('conference').first().sort_values('wins_above_average', ascending=False).reset_index()[4:5]\n",
    "\n",
    "\n",
    "conference_champs = ['Oregon', 'Georgia', 'Boise State', 'Arizona State', 'Clemson', 'Army']\n",
    "top_4_seeds = most_deserving_playoff[most_deserving_playoff['team'].isin(conference_champs)].sort_values('wins_above_average', ascending=False).reset_index()[0:4]\n",
    "autobid_5 = most_deserving_playoff[most_deserving_playoff['team'].isin(conference_champs)].sort_values('wins_above_average', ascending=False).reset_index()[4:5]\n",
    "\n",
    "excluded_teams = list(top_4_seeds['team']) + list(autobid_5['team'])\n",
    "at_large_bids = most_deserving_playoff[~most_deserving_playoff['team'].isin(excluded_teams)].head(7).reset_index(drop=True)\n",
    "at_large_bids = pd.concat([at_large_bids, autobid_5]).reset_index(drop=True)\n",
    "first_four_out = most_deserving_playoff[~most_deserving_playoff['team'].isin(excluded_teams)].head(11).reset_index(drop=True)[7:]\n",
    "next_four_out = most_deserving_playoff[~most_deserving_playoff['team'].isin(excluded_teams)].head(15).reset_index(drop=True)[11:]\n",
    "# Creating a dictionary for at_large_bids starting from seed 5\n",
    "at_large_dict = {i + 5: team for i, team in enumerate(at_large_bids['team'])}\n",
    "power_5_dict = {i + 1: team for i, team in enumerate(top_4_seeds['team'])}\n",
    "seeding = {**power_5_dict, **at_large_dict}\n",
    "\n",
    "\n",
    "# Function to fetch the logo image for a team\n",
    "def fetch_logo_image(logo_url):\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    from io import BytesIO\n",
    "\n",
    "    response = requests.get(logo_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    return img\n",
    "\n",
    "def draw_playoff_bracket(seeding):\n",
    "    fig, ax = plt.subplots(figsize=(12, 12),dpi=125)\n",
    "    \n",
    "    # Round 1 matchups and byes for teams 1-4\n",
    "    first_round_matchups = [\n",
    "        (8, 9), (5, 12), (7, 10), (6, 11) \n",
    "    ]\n",
    "    \n",
    "    # Mapping teams to their matchup in round 1\n",
    "    matchups_text = [\n",
    "        f\"#{match[0]} {seeding[match[0]]} vs #{match[1]} {seeding[match[1]]}\" for match in first_round_matchups\n",
    "    ]\n",
    "    \n",
    "    # Round 2 (quarterfinals): top seeds (1-4) vs winners of round 1\n",
    "    top_seeds = [1, 4, 2, 3]\n",
    "\n",
    "    # Positions for round 1 (y coordinates for matches)\n",
    "    y_round_1 = [0.90, 0.65, 0.4, 0.15]\n",
    "    \n",
    "    # Positions for round 2 (y coordinates for top 4 seeds)\n",
    "    y_round_2 = [0.90, 0.65, 0.4, 0.15]\n",
    "\n",
    "    top_seed_locations = [0.8, 0.55, 0.3, 0.05]\n",
    "    \n",
    "    # Adding matchups from the first round\n",
    "    for i, (y, text) in enumerate(zip(y_round_1, matchups_text)):\n",
    "        ax.text(0.05, y+0.05, text, fontsize=10, verticalalignment='center')\n",
    "        # Fetch logos for both teams in the matchup from team_data\n",
    "        team1_logo_url = logos[logos['team'] == seeding[first_round_matchups[i][0]]]['logo'].values[0][0]\n",
    "        team2_logo_url = logos[logos['team'] == seeding[first_round_matchups[i][1]]]['logo'].values[0][0]\n",
    "        \n",
    "        # Display team 1 logo\n",
    "        team1_logo = fetch_logo_image(team1_logo_url)\n",
    "        imagebox1 = OffsetImage(team1_logo, zoom=0.1)\n",
    "        ab1 = AnnotationBbox(imagebox1, (0.1, y), frameon=False)\n",
    "        ax.add_artist(ab1)\n",
    "        \n",
    "        # Display team 2 logo\n",
    "        team2_logo = fetch_logo_image(team2_logo_url)\n",
    "        imagebox2 = OffsetImage(team2_logo, zoom=0.1)\n",
    "        ab2 = AnnotationBbox(imagebox2, (0.2, y), frameon=False)\n",
    "        ax.add_artist(ab2)\n",
    "\n",
    "    # Adding the top 4 seeds (bye teams)\n",
    "    for i, seed in enumerate(top_seeds):\n",
    "        # Fetch and display logo for the top seed (bye team)\n",
    "        ax.text(0.25, top_seed_locations[i]+0.05, f\"#{seed} {seeding[seed]}\", fontsize=10, verticalalignment='center')\n",
    "        bye_team_logo_url = logos[logos['team'] == seeding[seed]]['logo'].values[0][0]\n",
    "        bye_team_logo = fetch_logo_image(bye_team_logo_url)\n",
    "        imagebox_bye = OffsetImage(bye_team_logo, zoom=0.1)\n",
    "        ab_bye = AnnotationBbox(imagebox_bye, (0.3, top_seed_locations[i]), frameon=False)\n",
    "        ax.add_artist(ab_bye)\n",
    "    \n",
    "    # Drawing lines connecting round 1 winners to the top 4 seeds\n",
    "    for i in range(4):\n",
    "        ax.add_patch(patches.ConnectionPatch((0.15, y_round_1[i]-0.05), (0.15, top_seed_locations[i]), 'data', 'data', arrowstyle=\"-\"))\n",
    "        ax.add_patch(patches.ConnectionPatch((0.15, top_seed_locations[i]), (0.25, top_seed_locations[i]), 'data', 'data', arrowstyle=\"-\"))\n",
    "        ax.add_patch(patches.ConnectionPatch((0.35, top_seed_locations[i]), (0.5, top_seed_locations[i]), 'data', 'data', arrowstyle='-'))\n",
    "        \n",
    "\n",
    "    ax.add_patch(patches.ConnectionPatch((0.5, top_seed_locations[0]), (0.5, top_seed_locations[1]), 'data', 'data', arrowstyle='-'))\n",
    "    ax.add_patch(patches.ConnectionPatch((0.5, top_seed_locations[2]), (0.5, top_seed_locations[3]), 'data', 'data', arrowstyle='-'))\n",
    "    ax.add_patch(patches.ConnectionPatch((0.5, (top_seed_locations[0]+top_seed_locations[1])/2), (0.7, (top_seed_locations[0]+top_seed_locations[1])/2), 'data', 'data', arrowstyle='-'))\n",
    "    ax.add_patch(patches.ConnectionPatch((0.5, (top_seed_locations[2]+top_seed_locations[3])/2), (0.7, (top_seed_locations[2]+top_seed_locations[3])/2), 'data', 'data', arrowstyle='-'))\n",
    "    ax.add_patch(patches.ConnectionPatch((0.7, (top_seed_locations[0]+top_seed_locations[1])/2), (0.7, (top_seed_locations[2]+top_seed_locations[3])/2), 'data', 'data', arrowstyle='-'))\n",
    "    ax.add_patch(patches.ConnectionPatch((0.7, (top_seed_locations[1]+top_seed_locations[2])/2), (0.9, (top_seed_locations[1]+top_seed_locations[2])/2), 'data', 'data', arrowstyle='-'))\n",
    "\n",
    "    ax.text(0.8, 0.95, \"First Four Out\", fontsize = 12, verticalalignment='center', ha='center',fontweight='bold')\n",
    "    ax.text(0.8,0.92, f\"{first_four_out.iloc[0,0]}\", fontsize = 12, verticalalignment='center', ha='center')\n",
    "    ax.text(0.8,0.89, f\"{first_four_out.iloc[1,0]}\", fontsize = 12, verticalalignment='center', ha='center')\n",
    "    ax.text(0.8,0.86, f\"{first_four_out.iloc[2,0]}\", fontsize = 12, verticalalignment='center', ha='center')\n",
    "    ax.text(0.8,0.83, f\"{first_four_out.iloc[3,0]}\", fontsize = 12, verticalalignment='center', ha='center')\n",
    "    ax.text(0.8,0.80, f\"Next Four Out\", verticalalignment='center', fontsize = 12, ha='center', fontweight='bold')\n",
    "    ax.text(0.8,0.77, f\"{next_four_out.iloc[0,0]}\", fontsize = 12, verticalalignment='center', ha='center')\n",
    "    ax.text(0.8,0.74, f\"{next_four_out.iloc[1,0]}\", fontsize = 12, verticalalignment='center', ha='center')\n",
    "    ax.text(0.8,0.71, f\"{next_four_out.iloc[2,0]}\", fontsize = 12, verticalalignment='center', ha='center')\n",
    "    ax.text(0.8,0.68, f\"{next_four_out.iloc[3,0]}\", fontsize = 12, verticalalignment='center', ha='center')\n",
    "    \n",
    "    # Final formatting\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axis('off')\n",
    "    plt.gca().set_facecolor('#5fa391')\n",
    "    plt.gcf().set_facecolor('#5fa391')\n",
    "    plt.title(\"Most Deserving Playoff Bracket\", fontweight='bold', fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "# Assuming team_data is a DataFrame with columns ['team', 'logo'], where 'logo' is the URL to each team's logo\n",
    "draw_playoff_bracket(seeding, team_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability to reach each round of playoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Select 12 random integers between 0 and 133 without replacement\n",
    "random_integers = random.sample(range(0, 50), 12)\n",
    "\n",
    "seeding = {\n",
    "    1: team_data.iloc[random_integers[0], :]['team'],\n",
    "    2: team_data.iloc[random_integers[1], :]['team'],\n",
    "    3: team_data.iloc[random_integers[2], :]['team'],\n",
    "    4: team_data.iloc[random_integers[3], :]['team'],\n",
    "    5: team_data.iloc[random_integers[4], :]['team'],\n",
    "    6: team_data.iloc[random_integers[5], :]['team'],\n",
    "    7: team_data.iloc[random_integers[6], :]['team'],\n",
    "    8: team_data.iloc[random_integers[7], :]['team'],\n",
    "    9: team_data.iloc[random_integers[8], :]['team'],\n",
    "    10: team_data.iloc[random_integers[9], :]['team'],\n",
    "    11: team_data.iloc[random_integers[10], :]['team'],\n",
    "    12: team_data.iloc[random_integers[11], :]['team']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from IPython.display import Image\n",
    "import matplotlib.offsetbox as offsetbox\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "seeding = {1: 'Oregon',\n",
    " 2: 'Georgia',\n",
    " 3: 'Boise State',\n",
    " 4: 'Arizona State',\n",
    " 5: 'Texas',\n",
    " 6: 'Penn State',\n",
    " 7: 'Notre Dame',\n",
    " 8: 'Ohio State',\n",
    " 9: 'Tennessee',\n",
    " 10: 'Indiana',\n",
    " 11: 'SMU',\n",
    " 12: 'Clemson'}\n",
    "\n",
    "# Parameters\n",
    "n_simulations = 10000  # Number of simulations\n",
    "\n",
    "first_round_games = [\n",
    "    (seeding[8], seeding[9]),\n",
    "    (seeding[7], seeding[10]),\n",
    "    (seeding[6], seeding[11]),\n",
    "    (seeding[5], seeding[12]),\n",
    "]\n",
    "\n",
    "advancement_counts = {seeding[seed]: 0 for seed in range(5, 13)}\n",
    "for _ in range(n_simulations):\n",
    "    for game in first_round_games:\n",
    "        t1, t2 = game\n",
    "        pr_t1 = team_data[team_data['team'] == t1]['power_rating'].values[0] + 1\n",
    "        pr_t2 = team_data[team_data['team'] == t2]['power_rating'].values[0]\n",
    "        prob_t1_wins = ESCAPE_Win_Prob(pr_t1, pr_t2)\n",
    "        # Simulate the game outcome\n",
    "        winner = t1 if 100 * np.random.rand() < prob_t1_wins else t2\n",
    "        advancement_counts[winner] += 1\n",
    "advance_to_quarters = {team: count / n_simulations for team, count in advancement_counts.items()}\n",
    "\n",
    "quarterfinal_games = [\n",
    "    (seeding[1], seeding[8], seeding[9]),\n",
    "    (seeding[2], seeding[7], seeding[10]),\n",
    "    (seeding[3], seeding[6], seeding[11]),\n",
    "    (seeding[4], seeding[5], seeding[12]),\n",
    "]\n",
    "\n",
    "second_advancement_counts = {seeding[seed]: 0 for seed in range(1,13)}\n",
    "for _ in range(n_simulations):\n",
    "    for game in quarterfinal_games:\n",
    "        t1, t2, t3 = game\n",
    "        t2_advancement_prob = advance_to_quarters[t2]\n",
    "        opponent = t2 if np.random.rand() < t2_advancement_prob else t3\n",
    "        pr_t1 = team_data[team_data['team'] == t1]['power_rating'].values[0]\n",
    "        pr_t2 = team_data[team_data['team'] == opponent]['power_rating'].values[0]\n",
    "        prob_t1_wins = ESCAPE_Win_Prob(pr_t1, pr_t2)\n",
    "        winner = t1 if 100 * np.random.rand() < prob_t1_wins else opponent\n",
    "        second_advancement_counts[winner] += 1\n",
    "advance_to_semis = {team: count / n_simulations for team, count in second_advancement_counts.items()}\n",
    "\n",
    "semifinal_games = [\n",
    "    (seeding[1], seeding[8], seeding[9], seeding[4], seeding[5], seeding[12]),\n",
    "    (seeding[2], seeding[7], seeding[10], seeding[3], seeding[6], seeding[11]),\n",
    "]\n",
    "\n",
    "third_advancement_counts = {seeding[seed]: 0 for seed in range(1,13)}\n",
    "for _ in range(n_simulations):\n",
    "    for game in semifinal_games:\n",
    "        t1,t2,t3,t4,t5,t6 = game\n",
    "        t1_advance_prob = advance_to_semis[t1]\n",
    "        t2_advance_prob = advance_to_semis[t2]\n",
    "        t3_advance_prob = (t1_advance_prob + t2_advance_prob)\n",
    "        t4_advance_prob = advance_to_semis[t4]\n",
    "        t5_advance_prob = advance_to_semis[t5]\n",
    "        t6_advance_prob = (t4_advance_prob + t5_advance_prob)\n",
    "        random_val = np.random.rand()\n",
    "        other_val = np.random.rand()\n",
    "        if random_val < t1_advance_prob:\n",
    "            team_one = t1\n",
    "        elif random_val > t3_advance_prob:\n",
    "            team_one = t3\n",
    "        else:\n",
    "            team_one = t2\n",
    "        if other_val < t4_advance_prob:\n",
    "            team_two = t4\n",
    "        elif other_val > t6_advance_prob:\n",
    "            team_two = t6\n",
    "        else:\n",
    "            team_two = t5\n",
    "        pr_t1 = team_data[team_data['team'] == team_one]['power_rating'].values[0]\n",
    "        pr_t2 = team_data[team_data['team'] == team_two]['power_rating'].values[0]\n",
    "        prob_t1_wins = ESCAPE_Win_Prob(pr_t1, pr_t2)\n",
    "        winner = team_one if 100 * np.random.rand() < prob_t1_wins else team_two\n",
    "        third_advancement_counts[winner] += 1\n",
    "advance_to_finals = {team: count / n_simulations for team, count in third_advancement_counts.items()}\n",
    "        \n",
    "championship_game = [\n",
    "    (seeding[1], seeding[8], seeding[9], seeding[4], seeding[5], seeding[12], seeding[2], seeding[7], seeding[10], seeding[3], seeding[6], seeding[11]),\n",
    "]\n",
    "\n",
    "fourth_advancement_counts = {seeding[seed]: 0 for seed in range(1,13)}\n",
    "for _ in range(n_simulations):\n",
    "    for game in championship_game:\n",
    "        t1,t2,t3,t4,t5,t6, t7,t8,t9,t10,t11,t12 = game\n",
    "        t1_advance_prob = advance_to_finals[t1]\n",
    "        t2_advance_prob = t1_advance_prob + advance_to_finals[t2]\n",
    "        t3_advance_prob = t2_advance_prob + advance_to_finals[t3]\n",
    "        t4_advance_prob = t3_advance_prob + advance_to_finals[t4]\n",
    "        t5_advance_prob = t4_advance_prob + advance_to_finals[t5]\n",
    "\n",
    "        t6_advance_prob = advance_to_finals[t6]\n",
    "        t7_advance_prob = t6_advance_prob + advance_to_finals[t7]\n",
    "        t8_advance_prob = t7_advance_prob + advance_to_finals[t8]\n",
    "        t9_advance_prob = t8_advance_prob + advance_to_finals[t9]\n",
    "        t10_advance_prob = t9_advance_prob + advance_to_finals[t10]\n",
    "        t11_advance_prob = t10_advance_prob + advance_to_finals[t11]\n",
    "\n",
    "        rand_val = np.random.rand()\n",
    "        other_val = np.random.rand()\n",
    "\n",
    "        if rand_val < t1_advance_prob:\n",
    "            team_one = t1\n",
    "        elif rand_val < t2_advance_prob:\n",
    "            team_one = t2\n",
    "        elif rand_val < t3_advance_prob:\n",
    "            team_one = t3\n",
    "        elif rand_val < t4_advance_prob:\n",
    "            team_one = t4\n",
    "        elif rand_val < t5_advance_prob:\n",
    "            team_one = t5\n",
    "        else:\n",
    "            team_one = t6\n",
    "\n",
    "        if other_val < t6_advance_prob:\n",
    "            team_two = t6\n",
    "        elif other_val < t7_advance_prob:\n",
    "            team_two = t7\n",
    "        elif other_val < t8_advance_prob:\n",
    "            team_two = t8\n",
    "        elif other_val < t9_advance_prob:\n",
    "            team_two = t9\n",
    "        elif other_val < t10_advance_prob:\n",
    "            team_two = t10\n",
    "        elif other_val < t11_advance_prob:\n",
    "            team_two = t11\n",
    "        else:\n",
    "            team_two = t12\n",
    "                \n",
    "        pr_t1 = team_data[team_data['team'] == team_one]['power_rating'].values[0]\n",
    "        pr_t2 = team_data[team_data['team'] == team_two]['power_rating'].values[0]\n",
    "        prob_t1_wins = ESCAPE_Win_Prob(pr_t1, pr_t2)\n",
    "        winner = team_one if 100 * np.random.rand() < prob_t1_wins else team_two\n",
    "        fourth_advancement_counts[winner] += 1\n",
    "win_championship = {team: count / n_simulations for team, count in fourth_advancement_counts.items()}\n",
    "\n",
    "all_teams = set(advance_to_quarters.keys()) | set(advance_to_semis.keys()) | set(advance_to_finals.keys()) | set(win_championship.keys())\n",
    "final_results_df = pd.DataFrame([\n",
    "    {\n",
    "        \"Seed\": next((seed for seed, name in seeding.items() if name == team), None),  # Get the seeding for the team\n",
    "        \"Team\": team,\n",
    "        \"Quarterfinals\": round(advance_to_quarters.get(team, 1) * 100),\n",
    "        \"Semifinals\": round(advance_to_semis.get(team, 0) * 100),\n",
    "        \"NC Game\": round(advance_to_finals.get(team, 0) * 100),\n",
    "        \"Win NC\": round(win_championship.get(team, 0) * 100),\n",
    "    }\n",
    "    for team in sorted(all_teams)  # Sort teams alphabetically for consistency\n",
    "])\n",
    "final_results_df = final_results_df.sort_values('Seed')\n",
    "\n",
    "def normalize(val, min_val, max_val):\n",
    "    return (val - min_val) / (max_val - min_val)\n",
    "\n",
    "min_value = final_results_df.iloc[:, 2:].min().min()\n",
    "max_value = final_results_df.iloc[:, 2:].max().max()\n",
    "fig, ax = plt.subplots(figsize=(8, 6),dpi=125)\n",
    "fig.patch.set_facecolor('#5fa391')\n",
    "\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "# Add the table\n",
    "table = ax.table(\n",
    "    cellText=final_results_df.values,\n",
    "    colLabels=final_results_df.columns,\n",
    "    cellLoc='center',\n",
    "    loc='center',\n",
    "    colColours=['#5fa391'] * len(final_results_df.columns)  # Set the header background color\n",
    ")\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(14)  # Bigger font size\n",
    "table.auto_set_column_width(col=list(range(len(final_results_df.columns))))\n",
    "cmap = LinearSegmentedColormap.from_list('custom_green', [(0, '#d5f5e3'), (1, '#006400')])  # Lighter green to dark green\n",
    "# Add the gradient to the cells based on the value\n",
    "for (i, j), cell in table.get_celld().items():\n",
    "    cell.set_edgecolor('black')\n",
    "    cell.set_linewidth(1.2)\n",
    "\n",
    "    # Set header row background color\n",
    "    if i == 0:\n",
    "        cell.set_facecolor('#5fa391')  # Set header row to #5fa391\n",
    "        cell.set_text_props(fontsize=14, color='black')  # White text in header\n",
    "    # Set 'Team' and 'Seeding' columns to #5fa391\n",
    "    elif j == 0 or j == 1:  # Team column (index 0) and Seeding column (index 1)\n",
    "        cell.set_facecolor('#5fa391')  # Set background color for \"Team\" and \"Seeding\" columns\n",
    "        cell.set_text_props(fontsize=14, weight='bold', color='black')  # White text for these columns\n",
    "    else:\n",
    "        # Normalize the value for gradient color\n",
    "        value = final_results_df.iloc[i-1, j]  # Get the cell value (skip header)\n",
    "        \n",
    "        # If the value is 0, replace it with \"<1\"\n",
    "        if value == 0:\n",
    "            display_value = \"<1%\"\n",
    "        else:\n",
    "            display_value = f\"{value:}%\"\n",
    "\n",
    "\n",
    "        normalized_value = normalize(value, min_value, max_value)\n",
    "        color = cmap(normalized_value)  # Get the color from colormap\n",
    "\n",
    "        # Set the cell background color\n",
    "        cell.set_facecolor(color)\n",
    "        cell.set_text_props(fontsize=14, fontweight='bold', color='black')  # Increase text size\n",
    "        cell.get_text().set_text(display_value)\n",
    "    \n",
    "\n",
    "    cell.set_height(0.1)  # Adjust this value for vertical spacing\n",
    "\n",
    "fig.suptitle('Probability To Advance To Each Round', fontsize=18, weight='bold', color='black', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulate from semis in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from IPython.display import Image\n",
    "import matplotlib.offsetbox as offsetbox\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "seeding = {1: 'Ohio State',\n",
    " 2: 'Notre Dame',\n",
    " 3: 'Penn State',\n",
    " 4: 'Texas'}\n",
    "\n",
    "# Parameters\n",
    "n_simulations = 10000  # Number of simulations\n",
    "\n",
    "first_round_games = [\n",
    "    (seeding[1], seeding[4]),\n",
    "    (seeding[2], seeding[3])\n",
    "]\n",
    "\n",
    "advancement_counts = {seeding[seed]: 0 for seed in range(1, 5)}\n",
    "for _ in range(n_simulations):\n",
    "    for game in first_round_games:\n",
    "        t1, t2 = game\n",
    "        pr_t1 = team_data[team_data['team'] == t1]['power_rating'].values[0] + 1\n",
    "        pr_t2 = team_data[team_data['team'] == t2]['power_rating'].values[0]\n",
    "        prob_t1_wins = ESCAPE_Win_Prob(pr_t1, pr_t2)\n",
    "        # Simulate the game outcome\n",
    "        winner = t1 if 100 * np.random.rand() < prob_t1_wins else t2\n",
    "        advancement_counts[winner] += 1\n",
    "advance_to_championship = {team: count / n_simulations for team, count in advancement_counts.items()}\n",
    "\n",
    "final_games = [\n",
    "    (seeding[1], seeding[2], seeding[3], seeding[4])\n",
    "]\n",
    "\n",
    "second_advancement_counts = {seeding[seed]: 0 for seed in range(1,5)}\n",
    "for _ in range(n_simulations):\n",
    "    for game in final_games:\n",
    "        t1, t2, t3, t4 = game\n",
    "\n",
    "        t1_advancement_prob = advance_to_championship[t1]\n",
    "        team1 = t1 if np.random.rand() < t1_advancement_prob else t4\n",
    "        t2_advancement_prob = advance_to_championship[t2]\n",
    "        team2 = t2 if np.random.rand() < t2_advancement_prob else t3\n",
    "        pr_t1 = team_data[team_data['team'] == team1]['power_rating'].values[0]\n",
    "        pr_t2 = team_data[team_data['team'] == team2]['power_rating'].values[0]\n",
    "        prob_t1_wins = ESCAPE_Win_Prob(pr_t1, pr_t2)\n",
    "        winner = team1 if 100 * np.random.rand() < prob_t1_wins else team2\n",
    "        second_advancement_counts[winner] += 1\n",
    "win_nc = {team: count / n_simulations for team, count in second_advancement_counts.items()}\n",
    "\n",
    "all_teams = set(advance_to_championship.keys()) | set(win_nc.keys())\n",
    "final_results_df = pd.DataFrame([\n",
    "    {\n",
    "        \"Seed\": next((seed for seed, name in seeding.items() if name == team), None),  # Get the seeding for the team\n",
    "        \"Team\": team,\n",
    "        \"NC Game\": round(advance_to_championship.get(team, 0) * 100),\n",
    "        \"Win NC\": round(win_nc.get(team, 0) * 100),\n",
    "    }\n",
    "    for team in sorted(all_teams)  # Sort teams alphabetically for consistency\n",
    "])\n",
    "final_results_df = final_results_df.sort_values('Seed')\n",
    "\n",
    "def normalize(val, min_val, max_val):\n",
    "    return (val - min_val) / (max_val - min_val)\n",
    "\n",
    "min_value = final_results_df.iloc[:, 2:].min().min()\n",
    "max_value = final_results_df.iloc[:, 2:].max().max()\n",
    "fig, ax = plt.subplots(figsize=(8, 6),dpi=125)\n",
    "fig.patch.set_facecolor('#5fa391')\n",
    "\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "# Add the table\n",
    "table = ax.table(\n",
    "    cellText=final_results_df.values,\n",
    "    colLabels=final_results_df.columns,\n",
    "    cellLoc='center',\n",
    "    loc='center',\n",
    "    colColours=['#5fa391'] * len(final_results_df.columns)  # Set the header background color\n",
    ")\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(14)  # Bigger font size\n",
    "table.auto_set_column_width(col=list(range(len(final_results_df.columns))))\n",
    "cmap = LinearSegmentedColormap.from_list('custom_green', [(0, '#d5f5e3'), (1, '#006400')])  # Lighter green to dark green\n",
    "# Add the gradient to the cells based on the value\n",
    "for (i, j), cell in table.get_celld().items():\n",
    "    cell.set_edgecolor('black')\n",
    "    cell.set_linewidth(1.2)\n",
    "\n",
    "    # Set header row background color\n",
    "    if i == 0:\n",
    "        cell.set_facecolor('#5fa391')  # Set header row to #5fa391\n",
    "        cell.set_text_props(fontsize=14, color='black')  # White text in header\n",
    "    # Set 'Team' and 'Seeding' columns to #5fa391\n",
    "    elif j == 0 or j == 1:  # Team column (index 0) and Seeding column (index 1)\n",
    "        cell.set_facecolor('#5fa391')  # Set background color for \"Team\" and \"Seeding\" columns\n",
    "        cell.set_text_props(fontsize=14, weight='bold', color='black')  # White text for these columns\n",
    "    else:\n",
    "        # Normalize the value for gradient color\n",
    "        value = final_results_df.iloc[i-1, j]  # Get the cell value (skip header)\n",
    "        \n",
    "        # If the value is 0, replace it with \"<1\"\n",
    "        if value == 0:\n",
    "            display_value = \"<1%\"\n",
    "        else:\n",
    "            display_value = f\"{value:}%\"\n",
    "\n",
    "\n",
    "        normalized_value = normalize(value, min_value, max_value)\n",
    "        color = cmap(normalized_value)  # Get the color from colormap\n",
    "\n",
    "        # Set the cell background color\n",
    "        cell.set_facecolor(color)\n",
    "        cell.set_text_props(fontsize=14, fontweight='bold', color='black')  # Increase text size\n",
    "        cell.get_text().set_text(display_value)\n",
    "    \n",
    "\n",
    "    cell.set_height(0.1)  # Adjust this value for vertical spacing\n",
    "\n",
    "fig.suptitle('Probability To Advance To Each Round', fontsize=14, weight='bold', color='black', y=0.75)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOS Top 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_and_worst(SOS, logos, 'avg_expected_wins', f'Week {current_week} ESCAPE SOS', \"If An Elite Team Played Your Schedule, They Would Have __ Wins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOR Top 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_and_worst(SOR, logos, 'wins_above_good', f'Week {current_week} ESCAPE SOR', \"Wins Above or Below a Good Team\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Rating Team Pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_pr = round(team_data['power_rating'].mean(), 2)\n",
    "good_team_pr = round(team_data['power_rating'].std() + team_data['power_rating'].mean(), 2)\n",
    "elite_team_pr = round(2 * team_data['power_rating'].std() + team_data['power_rating'].mean(), 2)\n",
    "super_team_pr = round(3 * team_data['power_rating'].std() + team_data['power_rating'].mean(), 2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import numpy as np\n",
    "\n",
    "# Merge team_data with logos to include the logo column\n",
    "team_data_logo = team_data.merge(logos, on='team', how='left')\n",
    "\n",
    "# Categorize teams\n",
    "super_teams = team_data_logo[team_data_logo['power_rating'] > super_team_pr].reset_index(drop=True)\n",
    "elite_teams = team_data_logo[team_data_logo['power_rating'] > elite_team_pr].reset_index(drop=True)\n",
    "good_teams = team_data_logo[\n",
    "    (team_data_logo['power_rating'] > good_team_pr) & (team_data_logo['power_rating'] <= elite_team_pr)\n",
    "].reset_index(drop=True)\n",
    "average_teams = team_data_logo[\n",
    "    (team_data_logo['power_rating'] > average_pr) & (team_data_logo['power_rating'] <= good_team_pr)\n",
    "].reset_index(drop=True)\n",
    "below_average_teams = team_data_logo[team_data_logo['power_rating'] <= average_pr].reset_index(drop=True)\n",
    "\n",
    "# Function to plot logos with centering and dynamic spacing\n",
    "def plot_team_logos(ax, teams, level, spacing_factor=1.5, row_spacing=0.5, max_teams_per_row=10):\n",
    "    count = len(teams)\n",
    "    rows = (count // max_teams_per_row) + (1 if count % max_teams_per_row != 0 else 0)\n",
    "\n",
    "    for row in range(rows):\n",
    "        # Calculate the row teams\n",
    "        start_idx = row * max_teams_per_row\n",
    "        end_idx = min((row + 1) * max_teams_per_row, count)\n",
    "        row_teams = teams.iloc[start_idx:end_idx]\n",
    "\n",
    "        # Center x positions for current row\n",
    "        x = np.linspace(-max_teams_per_row / 2, max_teams_per_row / 2, len(row_teams)) * spacing_factor\n",
    "        y = np.full(len(row_teams), -level - row * row_spacing)  # Offset rows within a tier\n",
    "\n",
    "        for i, (team, logo) in enumerate(zip(row_teams['team'], row_teams['logo'])):\n",
    "            logo = logo[0]\n",
    "            img = mpimg.imread(logo)  # Load the logo image\n",
    "            imagebox = OffsetImage(img, zoom=0.1)\n",
    "            ab = AnnotationBbox(imagebox, (x[i], y[i]), frameon=False)\n",
    "            ax.add_artist(ab)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(11, 15))\n",
    "fig.patch.set_facecolor('#5fa391')\n",
    "\n",
    "# Plot logos with adjusted spacing\n",
    "plot_team_logos(ax, elite_teams, -0.2, spacing_factor=1, row_spacing = 0.4, max_teams_per_row=max(len(elite_teams) // 2, 1)+1)\n",
    "plot_team_logos(ax, good_teams, 0.7, spacing_factor=1, row_spacing = 0.4, max_teams_per_row=max(len(good_teams) // 3, 1)+1)\n",
    "plot_team_logos(ax, average_teams, 2, spacing_factor=1, row_spacing = 0.5, max_teams_per_row=max(len(average_teams) // 4, 1)+1)\n",
    "plot_team_logos(ax, below_average_teams, 4.1, spacing_factor=1, row_spacing = 0.5, max_teams_per_row=max(len(below_average_teams) // 4, 1)+1)\n",
    "\n",
    "ax.hlines(y=-0.5, xmin=-2.5, xmax=2.5, colors='black', linewidth=3)\n",
    "ax.hlines(y=-1.75, xmin=-6.5, xmax=6.5, colors='black', linewidth=3)\n",
    "ax.hlines(y=-3.8, xmin=-9, xmax=9, colors='black', linewidth=3)\n",
    "ax.hlines(y=-5.9, xmin=-9, xmax=9, colors='black', linewidth=3)\n",
    "\n",
    "ax.text(-2.5, -0.45, \"Elite Teams\", ha='left', fontsize=14, fontweight='bold', color='black')\n",
    "ax.text(-6.5, -1.7, \"Good Teams\", ha='left', fontsize=14, fontweight='bold', color='black')\n",
    "ax.text(-9, -3.75, \"Average Teams\", ha='left', fontsize=14, fontweight='bold', color='black')\n",
    "ax.text(-9, -5.85, \"Below Average Teams\", ha='left', fontsize=14, fontweight='bold', color='black')\n",
    "# ax.text(0, -6.3, \"Below Average Teams\", ha='center', fontsize=12, fontweight='bold', color='black')\n",
    "\n",
    "# Adjust plot limits and formatting\n",
    "ax.set_xlim(-9.5, 9.5)  # Center based on the widest row\n",
    "ax.set_ylim(-5.5, 1)  # Extend y-axis to fit all levels\n",
    "ax.set_yticks([-0.75, -2.25, -4, -6])\n",
    "ax.set_yticklabels([\"Elite Teams\", \"Good Teams\", \"Average Teams\", \"Below Average Teams\"])\n",
    "ax.text(0, 0.67, \"Team Pyramid\", ha='center', fontsize=24, fontweight='bold')\n",
    "ax.text(0, 0.5, \"Teams Listed in Descending Order Within Each Row\", fontsize = 16, ha='center')\n",
    "ax.axis(\"off\")  # Remove axis lines\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Deserving Team Pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_pr = round(most_deserving['wins_above_average'].mean(), 2)\n",
    "good_team_pr = round(most_deserving['wins_above_average'].std() + most_deserving['wins_above_average'].mean(), 2)\n",
    "elite_team_pr = round(2 * most_deserving['wins_above_average'].std() + most_deserving['wins_above_average'].mean(), 2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import numpy as np\n",
    "\n",
    "# Merge team_data with logos to include the logo column\n",
    "team_data_logo = most_deserving.merge(logos, on='team', how='left')\n",
    "\n",
    "# Categorize teams\n",
    "elite_teams = team_data_logo[team_data_logo['wins_above_average'] > elite_team_pr].reset_index(drop=True)\n",
    "good_teams = team_data_logo[\n",
    "    (team_data_logo['wins_above_average'] > good_team_pr) & (team_data_logo['wins_above_average'] <= elite_team_pr)\n",
    "].reset_index(drop=True)\n",
    "average_teams = team_data_logo[\n",
    "    (team_data_logo['wins_above_average'] > average_pr) & (team_data_logo['wins_above_average'] <= good_team_pr)\n",
    "].reset_index(drop=True)\n",
    "below_average_teams = team_data_logo[team_data_logo['wins_above_average'] <= average_pr].reset_index(drop=True)\n",
    "\n",
    "# Function to plot logos with centering and dynamic spacing\n",
    "def plot_team_logos(ax, teams, level, spacing_factor=1.5, row_spacing=0.5, max_teams_per_row=10):\n",
    "    count = len(teams)\n",
    "    rows = (count // max_teams_per_row) + (1 if count % max_teams_per_row != 0 else 0)\n",
    "\n",
    "    for row in range(rows):\n",
    "        # Calculate the row teams\n",
    "        start_idx = row * max_teams_per_row\n",
    "        end_idx = min((row + 1) * max_teams_per_row, count)\n",
    "        row_teams = teams.iloc[start_idx:end_idx]\n",
    "\n",
    "        # Center x positions for current row\n",
    "        x = np.linspace(-max_teams_per_row / 2, max_teams_per_row / 2, len(row_teams)) * spacing_factor\n",
    "        y = np.full(len(row_teams), -level - row * row_spacing)  # Offset rows within a tier\n",
    "\n",
    "        for i, (team, logo) in enumerate(zip(row_teams['team'], row_teams['logo'])):\n",
    "            logo = logo[0]\n",
    "            img = mpimg.imread(logo)  # Load the logo image\n",
    "            imagebox = OffsetImage(img, zoom=0.1)\n",
    "            ab = AnnotationBbox(imagebox, (x[i], y[i]), frameon=False)\n",
    "            ax.add_artist(ab)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(11, 15))\n",
    "fig.patch.set_facecolor('#5fa391')\n",
    "\n",
    "# Plot logos with adjusted spacing\n",
    "plot_team_logos(ax, elite_teams, -0.2, spacing_factor=1, row_spacing = 0.4, max_teams_per_row=max(len(elite_teams) // 2, 1))\n",
    "plot_team_logos(ax, good_teams, 0.7, spacing_factor=1, row_spacing = 0.4, max_teams_per_row=max(len(good_teams) // 3, 1))\n",
    "plot_team_logos(ax, average_teams, 2, spacing_factor=1, row_spacing = 0.5, max_teams_per_row=max(len(average_teams) // 4, 1)+1)\n",
    "plot_team_logos(ax, below_average_teams, 4.1, spacing_factor=1, row_spacing = 0.5, max_teams_per_row=max(len(below_average_teams) // 4, 1)+1)\n",
    "\n",
    "ax.hlines(y=-0.5, xmin=-2.5, xmax=2.5, colors='black', linewidth=3)\n",
    "ax.hlines(y=-1.75, xmin=-6.5, xmax=6.5, colors='black', linewidth=3)\n",
    "ax.hlines(y=-3.8, xmin=-9, xmax=9, colors='black', linewidth=3)\n",
    "ax.hlines(y=-5.9, xmin=-9, xmax=9, colors='black', linewidth=3)\n",
    "\n",
    "ax.text(-2.5, -0.45, \"2+ SD\", ha='left', fontsize=14, fontweight='bold', color='black')\n",
    "ax.text(-6.5, -1.7, \"1+ SD\", ha='left', fontsize=14, fontweight='bold', color='black')\n",
    "ax.text(-9, -3.75, \"0+ SD\", ha='left', fontsize=14, fontweight='bold', color='black')\n",
    "ax.text(-9, -5.85, \"<0 SD\", ha='left', fontsize=14, fontweight='bold', color='black')\n",
    "# ax.text(0, -6.3, \"Below Average Teams\", ha='center', fontsize=12, fontweight='bold', color='black')\n",
    "\n",
    "# Adjust plot limits and formatting\n",
    "ax.set_xlim(-9.5, 9.5)  # Center based on the widest row\n",
    "ax.set_ylim(-5.5, 1)  # Extend y-axis to fit all levels\n",
    "ax.set_yticks([-0.75, -2.25, -4, -6])\n",
    "ax.set_yticklabels([\"Elite Teams\", \"Good Teams\", \"Average Teams\", \"Below Average Teams\"])\n",
    "ax.text(0, 0.67, \"Most Deserving Team Pyramid\", ha='center', fontsize=24, fontweight='bold')\n",
    "ax.text(0, 0.5, \"Teams Listed in Descending Order Within Each Row\", fontsize = 16, ha='center')\n",
    "ax.axis(\"off\")  # Remove axis lines\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Margin of Victory Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_and_worst(RTP, logos, 'RTP', f'ESCAPE Margin of Victory', \"If You Are Expected to Win by 10 Points, Your Average MOV is __ Points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conference Champions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_week = 17\n",
    "current_year = 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import result\n",
    "import pandas as pd\n",
    "import cfbd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import ImageGrab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from base64 import b64decode\n",
    "from io import BytesIO\n",
    "from IPython import get_ipython\n",
    "from IPython.core.magic import register_cell_magic\n",
    "import PIL\n",
    "configuration = cfbd.Configuration()\n",
    "configuration.api_key['Authorization'] = '7vGedNNOrnl0NGcSvt92FcVahY602p7IroVBlCA1Tt+WI/dCwtT7Gj5VzmaHrrxS'\n",
    "configuration.api_key_prefix['Authorization'] = 'Bearer'\n",
    "api_client = cfbd.ApiClient(configuration)\n",
    "advanced_instance = cfbd.StatsApi(api_client)\n",
    "games_api = cfbd.GamesApi(api_client)\n",
    "betting_api = cfbd.BettingApi(api_client)\n",
    "ratings_api = cfbd.RatingsApi(api_client)\n",
    "teams_api = cfbd.TeamsApi(api_client)\n",
    "metrics_api = cfbd.MetricsApi(api_client)\n",
    "players_api = cfbd.PlayersApi(api_client)\n",
    "recruiting_api = cfbd.RecruitingApi(api_client)\n",
    "\n",
    "def date_sort(game):\n",
    "    game_date = datetime.datetime.strptime(game['start_date'], \"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "    return game_date\n",
    "\n",
    "def ESCAPE_Win_Prob(home_power_rating, away_power_rating):\n",
    "    return round((1 / (1 + 10 ** ((away_power_rating - (home_power_rating)) / 20.5))) * 100, 2)\n",
    "\n",
    "logos_info_list = []\n",
    "response = teams_api.get_teams()\n",
    "logos_info_list = [*logos_info_list, *response]\n",
    "logos_info_dict = [dict(\n",
    "    team = l.school,\n",
    "    color = l.color,\n",
    "    alt_color = l.alt_color,\n",
    "    logo = l.logos\n",
    ") for l in logos_info_list]\n",
    "logos = pd.DataFrame(logos_info_dict)\n",
    "logos = logos.dropna(subset=['logo', 'color'])\n",
    "\n",
    "records_list = []\n",
    "response = games_api.get_team_records(year=2024)\n",
    "records_list = [*records_list, *response]\n",
    "records_dict = [dict(\n",
    "    team = r.team,\n",
    "    games_played = r.total.games,\n",
    "    wins = r.total.wins,\n",
    "    losses = r.total.losses,\n",
    "    conference_games = r.conference_games.games,\n",
    "    conference_wins = r.conference_games.wins,\n",
    "    conference_losses = r.conference_games.losses\n",
    ") for r in records_list]\n",
    "records = pd.DataFrame(records_dict)\n",
    "records.at[records[records['team'] == 'Kansas State'].index[0], 'conference_wins'] -= 1\n",
    "records.at[records[records['team'] == 'Utah'].index[0], 'conference_wins'] -= 1\n",
    "records.at[records[records['team'] == 'Baylor'].index[0], 'conference_losses'] -= 1\n",
    "records.at[records[records['team'] == 'Arizona'].index[0], 'conference_losses'] -= 1\n",
    "\n",
    "start_week = 1\n",
    "end_week = 17\n",
    "\n",
    "team_data = pd.read_csv(f'./ESCAPE Ratings/Ratings/y{current_year}/ESCAPE_week{current_week}.csv')\n",
    "\n",
    "games_list = []\n",
    "for week in range(start_week,end_week):\n",
    "    response = games_api.get_games(year=current_year, week=week,division = 'fbs')\n",
    "    games_list = [*games_list, *response]\n",
    "games = [dict(\n",
    "            id=g.id,\n",
    "            season=g.season,\n",
    "            week=g.week,\n",
    "            start_date=g.start_date,\n",
    "            home_team=g.home_team,\n",
    "            home_elo=g.home_pregame_elo,\n",
    "            away_team=g.away_team,\n",
    "            away_elo=g.away_pregame_elo,\n",
    "            home_points = g.home_points,\n",
    "            away_points = g.away_points,\n",
    "            neutral = g.neutral_site\n",
    "            ) for g in games_list if g.home_pregame_elo is not None and g.away_pregame_elo is not None]\n",
    "games.sort(key=date_sort)\n",
    "year_long_schedule = pd.DataFrame(games)\n",
    "\n",
    "year_long_schedule = year_long_schedule.merge(team_data[['team', 'power_rating']], \n",
    "                                    left_on='home_team', \n",
    "                                    right_on='team', \n",
    "                                    how='left').rename(columns={'power_rating': 'home_pr'})\n",
    "year_long_schedule = year_long_schedule.drop(columns=['team'])\n",
    "year_long_schedule = year_long_schedule.merge(team_data[['team', 'power_rating']], \n",
    "                                    left_on='away_team', \n",
    "                                    right_on='team', \n",
    "                                    how='left').rename(columns={'power_rating': 'away_pr'})\n",
    "year_long_schedule = year_long_schedule.drop(columns=['team'])\n",
    "\n",
    "# Apply the ESCAPE_Win_Prob function to the schedule_info DataFrame\n",
    "year_long_schedule['escape_win_prob'] = year_long_schedule.apply(\n",
    "    lambda row: ESCAPE_Win_Prob(row['home_pr'], row['away_pr']), axis=1\n",
    ")\n",
    "\n",
    "year_long_schedule['home_win_prob'] = round((10**((year_long_schedule['home_elo'] - year_long_schedule['away_elo']) / 400)) / ((10**((year_long_schedule['home_elo'] - year_long_schedule['away_elo']) / 400)) + 1)*100,2)\n",
    "\n",
    "team_conference_map = team_data.set_index('team')['conference'].to_dict()\n",
    "year_long_schedule['home_conference'] = year_long_schedule['home_team'].map(team_conference_map)\n",
    "year_long_schedule['away_conference'] = year_long_schedule['away_team'].map(team_conference_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_game_conference(home_team, away_team, home_win_prob):\n",
    "    \"\"\"Simulates a single game between two teams based on home win probability.\"\"\"\n",
    "    random_outcome = np.random.random() * 100  # Generates a number between 0 and 100\n",
    "    if random_outcome < home_win_prob:\n",
    "        return home_team, away_team  # Home team wins, Away team loses\n",
    "    else:\n",
    "        return away_team, home_team  # Away team wins, Home team loses\n",
    "\n",
    "def simulate_season_conference(schedules, team_data):\n",
    "    \"\"\"Simulates one season based on current power ratings and schedule.\"\"\"\n",
    "    team_wins = {team: 0 for team in team_data['team'].unique()}  # Initialize win counts\n",
    "    team_losses = {team: 0 for team in team_data['team'].unique()}  # Initialize loss counts\n",
    "\n",
    "    for _, game in schedules.iterrows():\n",
    "        home_team = game['home_team']\n",
    "        away_team = game['away_team']\n",
    "        home_win_prob = game['escape_win_prob']\n",
    "\n",
    "        # Simulate the game outcome\n",
    "        winner, loser = simulate_game_conference(home_team, away_team, home_win_prob)\n",
    "        team_wins[winner] += 1  # Increment win count for the winner\n",
    "        team_losses[loser] += 1  # Increment loss count for the loser\n",
    "\n",
    "    return team_wins, team_losses  # Returns the win and loss counts for all teams at the end of the season\n",
    "\n",
    "def monte_carlo_simulation_conference(num_simulations, schedules, team_data):\n",
    "    \"\"\"Runs a Monte Carlo simulation over multiple seasons.\"\"\"\n",
    "    win_results = []\n",
    "    loss_results = []\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        season_wins, season_losses = simulate_season_conference(schedules, team_data)\n",
    "        win_results.append(season_wins)\n",
    "        loss_results.append(season_losses)\n",
    "    \n",
    "    return win_results, loss_results\n",
    "\n",
    "def analyze_simulation_conference(win_results, loss_results, schedules, records):\n",
    "    \"\"\"Aggregates the results of multiple simulated seasons and calculates win-loss records.\"\"\"\n",
    "    # Convert list of results into DataFrames\n",
    "    win_df = pd.DataFrame(win_results)\n",
    "    loss_df = pd.DataFrame(loss_results)\n",
    "    \n",
    "    # Determine the number of games each team plays\n",
    "    game_counts = schedules.groupby('home_team').size() + schedules.groupby('away_team').size()\n",
    "    game_counts = game_counts.groupby(level=0).sum()  # Combine home and away counts\n",
    "\n",
    "    # Add 1 win for teams with only 11 games\n",
    "    for team in win_df.columns:\n",
    "        win_df[team] += records[records['team'] == team]['conference_wins'].values[0]\n",
    "        loss_df[team] += records[records['team'] == team]['conference_losses'].values[0]\n",
    "\n",
    "    # for team in win_df.columns:\n",
    "    #     team_games_played = records[records['team'] == team]['games_played'].values[0]\n",
    "    #     if (team_games_played+game_counts[team]) == 11:\n",
    "    #         win_df[team] += 1\n",
    "    #     if (team_games_played+game_counts[team]) == 10:\n",
    "    #         win_df[team] += 2\n",
    "        \n",
    "    # Calculate average win totals for each team\n",
    "    avg_wins = win_df.mean(axis=0)\n",
    "    \n",
    "    # Calculate average loss totals for each team\n",
    "    avg_losses = loss_df.mean(axis=0)\n",
    "    \n",
    "    # Calculate the mode (most frequent number of wins) for each team\n",
    "    most_common_wins = win_df.mode(axis=0).iloc[0]  # mode() returns a DataFrame, take the first row\n",
    "    \n",
    "    # Calculate the mode (most frequent number of losses) for each team\n",
    "    most_common_losses = loss_df.mode(axis=0).iloc[0]  # mode() returns a DataFrame, take the first row\n",
    "    \n",
    "    # Combine wins and losses into records\n",
    "    most_common_records = pd.DataFrame({\n",
    "        'Wins': most_common_wins,\n",
    "        'Losses': most_common_losses\n",
    "    })\n",
    "    \n",
    "    win_thresholds = {}\n",
    "    for wins in range(10):  # 0 to 12 wins\n",
    "        win_thresholds[f'win_{wins}'] = win_df.apply(lambda x: (x == wins).sum() / len(x), axis=0)\n",
    "    \n",
    "    # Create the win threshold DataFrame\n",
    "    win_thresholds_df = pd.DataFrame(win_thresholds)\n",
    "    win_thresholds_df.insert(0, 'team', win_df.columns)\n",
    "    win_thresholds_df = win_thresholds_df.reset_index(drop=True)\n",
    "    win_thresholds_df['expected_wins'] = list(avg_wins)\n",
    "    win_thresholds_df['expected_loss'] = list(avg_losses)\n",
    "    win_thresholds_df['projected_wins'] = list(most_common_records['Wins'])\n",
    "    win_thresholds_df['projected_losses'] = list(most_common_records['Losses'])\n",
    "\n",
    "    return win_thresholds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conference_list = list(team_data['conference'].unique())\n",
    "all_conference_wins = pd.DataFrame()\n",
    "# Filter year_long_schedule where both home_conference and away_conference match conference_list[0]\n",
    "for i in range(len(conference_list)):\n",
    "    conference_schedule = year_long_schedule[\n",
    "        (year_long_schedule['home_conference'] == conference_list[i]) &\n",
    "        (year_long_schedule['away_conference'] == conference_list[i])\n",
    "    ]\n",
    "    conference_team_data = team_data[team_data['conference'] == conference_list[i]]\n",
    "    uncompleted_conference_games = conference_schedule[conference_schedule['home_points'].isna()]\n",
    "    wins, losses = monte_carlo_simulation_conference(1000, uncompleted_conference_games, conference_team_data)\n",
    "    conference_wins = analyze_simulation_conference(wins, losses, uncompleted_conference_games, records)\n",
    "    conference_wins['conference'] = conference_list[i]\n",
    "    conference_wins = conference_wins.sort_values('expected_wins', ascending=False).reset_index(drop=True)\n",
    "    all_conference_wins = pd.concat([all_conference_wins, conference_wins])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Conference Standings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.font_manager as fm\n",
    "checkmark_font = fm.FontProperties(family='DejaVu Sans')\n",
    "\n",
    "def conference_standings():\n",
    "    conference_list = list(team_data['conference'].unique())\n",
    "    all_figs = []\n",
    "    num_conference_games = {\n",
    "        'SEC':8,\n",
    "        'Big Ten':9,\n",
    "        'ACC':8,\n",
    "        'Big 12':9,\n",
    "        'Mountain West':7,\n",
    "        'American Athletic':9,\n",
    "        'Pac-12':1,\n",
    "        'Sun Belt':8,\n",
    "        'Mid-American':8,\n",
    "        'Conference USA':8\n",
    "    }\n",
    "\n",
    "    import matplotlib.colors as mcolors\n",
    "\n",
    "    dark_green = '#1D4D00'\n",
    "    medium_green = '#3C7300'\n",
    "    orange = '#D2691E'\n",
    "    black = 'black'\n",
    "\n",
    "    # Function to interpolate between colors\n",
    "    def interpolate_color(c1, c2, factor):\n",
    "        \"\"\"Interpolate between two colors c1 and c2 based on factor (0 to 1).\"\"\"\n",
    "        color1 = mcolors.hex2color(c1)\n",
    "        color2 = mcolors.hex2color(c2)\n",
    "        return mcolors.rgb2hex([(1 - factor) * a + factor * b for a, b in zip(color1, color2)])\n",
    "\n",
    "    # Function to get color based on percentage\n",
    "    def get_color_percentage(percentage):\n",
    "        if 40 <= percentage <= 60:\n",
    "            return dark_green  # Dark green is constant in this range\n",
    "        elif 30 <= percentage < 40:\n",
    "            # Transition from orange to medium green as percentage increases from 30 to 45\n",
    "            factor = (percentage - 30) / (40 - 30)\n",
    "            return interpolate_color(orange, medium_green, factor)\n",
    "        elif 60 < percentage <= 70:\n",
    "            # Transition from medium green to orange as percentage increases from 55 to 70\n",
    "            factor = (percentage - 60) / (70 - 60)\n",
    "            return interpolate_color(medium_green, orange, factor)\n",
    "        elif 15 <= percentage < 30:\n",
    "            # Transition from black to orange as percentage increases from 15 to 30\n",
    "            factor = (percentage - 15) / (30 - 15)\n",
    "            return interpolate_color(black, orange, factor)\n",
    "        elif 70 < percentage <= 85:\n",
    "            # Transition from orange to black as percentage increases from 70 to 85\n",
    "            factor = (percentage - 70) / (85 - 70)\n",
    "            return interpolate_color(orange, black, factor)\n",
    "        else:\n",
    "            return black  # Anything outside the defined ranges is black\n",
    "\n",
    "    for conference in conference_list:\n",
    "        if (conference == 'FBS Independents') | (conference == 'Pac-12'):\n",
    "            continue\n",
    "        this_conference_wins = all_conference_wins[all_conference_wins['conference'] == conference]\n",
    "\n",
    "        this_conference = conference\n",
    "        this_conference_games = num_conference_games[this_conference]\n",
    "        # Create a figure with a reduced height and smaller logos\n",
    "        fig, axs = plt.subplots(len(this_conference_wins), 1, figsize=(4, len(this_conference_wins) * 0.4))  # Adjusted height\n",
    "        fig.patch.set_facecolor('#5fa391')\n",
    "\n",
    "        # Loop through each team in the conference\n",
    "        for i, ax in enumerate(axs.ravel()):\n",
    "            # Get the team logo URL\n",
    "            logo_url = logos[logos['team'] == this_conference_wins.loc[i, 'team']]['logo'].values[0][0]\n",
    "            response = requests.get(logo_url)\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            \n",
    "            # Display the team logo with smaller size\n",
    "            ax.imshow(img, extent=(1,1.01,1.01,1), alpha=0.9)  # Adjust extent for smaller logo\n",
    "            ax.set_facecolor('#f0f0f0')\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Get the actual number of conference wins for the team\n",
    "            games_won = records[records['team'] == this_conference_wins.loc[i, 'team']]['conference_wins'].values[0]\n",
    "            games_lost = records[records['team'] == this_conference_wins.loc[i, 'team']]['conference_losses'].values[0]\n",
    "            expected_conference_wins = round(this_conference_wins.loc[i, 'expected_wins'], 1)\n",
    "\n",
    "            # Calculate cumulative probabilities of winning at least X games\n",
    "            win_columns = [f'win_{j}' for j in range(10)]  # win_0 to win_9\n",
    "            cumulative_probs = this_conference_wins.loc[i, win_columns].values[::-1].cumsum()[::-1] * 100  # Reverse, cumulative sum, and multiply by 100\n",
    "            \n",
    "            # Display cumulative win probabilities (at least X games)\n",
    "            for j in range(this_conference_games, games_won - 1, -1):  # Only for win totals >= games_won\n",
    "                if j == games_won:\n",
    "                    ax.text(15 + 2 * (this_conference_games - j), 0.5, \"✔\", transform=ax.transAxes, fontsize=12, ha='center', color='green', va='center', fontproperties=checkmark_font)  # Display checkmark\n",
    "                elif cumulative_probs[j] == 0:\n",
    "                    ax.text(15 + 2 * (this_conference_games - j), 0.5, \"X\", transform=ax.transAxes, fontsize=12, ha='center', color='red', va='center', fontweight='bold')  # Display X if probability is zero\n",
    "                elif round(cumulative_probs[j]) == 100:\n",
    "                    continue\n",
    "                elif round(cumulative_probs[j]) == 0:\n",
    "                    ax.text(15 + 2 * (num_conference_games[this_conference] - j), 0.5, f\"<1%\", transform=ax.transAxes, fontsize=12, ha='center', va='center', fontweight='bold')\n",
    "                else:\n",
    "                    ax.text(15 + 2 * (num_conference_games[this_conference] - j), 0.5, f\"{round(cumulative_probs[j])}%\", transform=ax.transAxes, fontweight='bold', fontsize=12, ha='center', va='center', color = get_color_percentage(cumulative_probs[j]))\n",
    "\n",
    "            ax.text(-1.25, 0.5, f\"{i+1}\", transform=ax.transAxes, fontsize=12, va='center', fontweight='bold', ha='center')\n",
    "            ax.text(9, 0.5, f\"{games_won} - {games_lost}\", transform=ax.transAxes, fontsize=12, va='center')\n",
    "            ax.text(12, 0.5, f\"{expected_conference_wins}\", transform=ax.transAxes, fontsize=12, va='center')\n",
    "            # Display the team name next to the logo\n",
    "            ax.text(1.5, 0.5, f\"{this_conference_wins.loc[i, 'team']}\", transform=ax.transAxes, fontsize=12, va='center', fontweight='bold')\n",
    "        fig.text(0.41, 0.9, f\"RK\", fontsize=12, fontweight='bold', ha='center')\n",
    "        fig.text(0.64, 0.9, f\"TEAM\", fontsize=12, fontweight='bold', ha='center')\n",
    "        fig.text(1.11, 0.9, f\"REC\", fontsize=12, fontweight='bold', ha='center')\n",
    "        fig.text(1.29, 0.9, f\"AVG\", fontsize=12, fontweight='bold', ha='center')\n",
    "\n",
    "        j=0\n",
    "        while this_conference_games >= 0:\n",
    "            fig.text(1.44 + 0.132*j, 0.9, f\"{this_conference_games}\", fontsize=12, fontweight='bold', ha='center')\n",
    "            this_conference_games -= 1\n",
    "            j+=1\n",
    "        fig.text(0.38, 0.98, f\"ESCAPE PROJECTED {this_conference.upper()} STANDINGS\", fontsize=16, fontweight='bold', ha='left')\n",
    "        fig.text(0.38, 0.95, \"PERCENT CHANCE TO WIN AT LEAST _ CONFERENCE GAMES\", fontsize =10, ha='left')\n",
    "        # Adjust layout and display the plot\n",
    "        all_figs.append(fig)\n",
    "    return all_figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_figs = conference_standings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Spreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cfbd\n",
    "import statistics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "current_week = 17\n",
    "current_year = 2024\n",
    "post_season_week = 1\n",
    "postseason = True\n",
    "team_data = pd.read_csv(f'./ESCAPE Ratings/Ratings/y{current_year}/ESCAPE_week{current_week}.csv').drop(columns=['Unnamed: 0'])\n",
    "all_data = pd.read_csv(f\"./ESCAPE Ratings/Data/y{current_year}/team_data_week{current_week}.csv\").drop(columns=['Unnamed: 0'])\n",
    "\n",
    "offensive_scaler = MinMaxScaler(feature_range=(35,70))\n",
    "defensive_scaler = MinMaxScaler(feature_range=(15,40))\n",
    "all_data['offensive_total'] = offensive_scaler.fit_transform(all_data[['offensive_total']])\n",
    "all_data['defensive_total'] = defensive_scaler.fit_transform(all_data[['defensive_total']])\n",
    "\n",
    "# team_data.loc[team_data['team'] == 'Arkansas State', 'power_rating'] += -7\n",
    "# team_data.loc[team_data['team'] == 'San Diego State', 'power_rating'] += -3\n",
    "# team_data = team_data.sort_values('power_rating', ascending=False).reset_index(drop=True)\n",
    "# team_data.index = team_data.index + 1\n",
    "# team_data.to_csv(f'./ESCAPE Ratings/Ratings/y{current_year}/ESCAPE_week{current_week}.csv')\n",
    "\n",
    "# all_data.loc[all_data['team'] == 'San Diego State', 'power_rating'] += -3\n",
    "# all_data = all_data.sort_values('power_rating', ascending=False).reset_index(drop=True)\n",
    "# # all_data.index = all_data.index + 1\n",
    "# all_data.to_csv(f\"./ESCAPE Ratings/Data/y{current_year}/team_data_week{current_week}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### game info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "configuration = cfbd.Configuration()\n",
    "configuration.api_key['Authorization'] = '7vGedNNOrnl0NGcSvt92FcVahY602p7IroVBlCA1Tt+WI/dCwtT7Gj5VzmaHrrxS'\n",
    "configuration.api_key_prefix['Authorization'] = 'Bearer'\n",
    "api_client = cfbd.ApiClient(configuration)\n",
    "\n",
    "advanced_instance = cfbd.StatsApi(api_client)\n",
    "\n",
    "games_api = cfbd.GamesApi(api_client)\n",
    "\n",
    "betting_api = cfbd.BettingApi(api_client)\n",
    "\n",
    "ratings_api = cfbd.RatingsApi(api_client)\n",
    "\n",
    "teams_api = cfbd.TeamsApi(api_client)\n",
    "\n",
    "metrics_api = cfbd.MetricsApi(api_client)\n",
    "\n",
    "players_api = cfbd.PlayersApi(api_client)\n",
    "\n",
    "recruiting_api = cfbd.RecruitingApi(api_client)\n",
    "def date_sort(game):\n",
    "    game_date = datetime.datetime.strptime(game['start_date'], \"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "    return game_date\n",
    "\n",
    "if postseason:\n",
    "    games = []\n",
    "    response = games_api.get_games(year=current_year, division = 'fbs', season_type='postseason')\n",
    "    games = [*games, *response]\n",
    "else:\n",
    "    games = []\n",
    "    response = games_api.get_games(year=current_year, week = current_week, division = 'fbs')\n",
    "    games = [*games, *response]\n",
    "\n",
    "\n",
    "games_dict = [dict(\n",
    "            id=g.id,\n",
    "            season=g.season,\n",
    "            week=g.week,\n",
    "            start_date=g.start_date,\n",
    "            home_team=g.home_team,\n",
    "            home_conference=g.home_conference,\n",
    "            home_points=g.home_points,\n",
    "            home_elo=g.home_pregame_elo,\n",
    "            away_team=g.away_team,\n",
    "            away_conference=g.away_conference,\n",
    "            away_points=g.away_points,\n",
    "            away_elo=g.away_pregame_elo,\n",
    "            neutral = g.neutral_site\n",
    "            ) for g in games]\n",
    "games_dict.sort(key=date_sort)\n",
    "week_games = pd.DataFrame(games_dict)\n",
    "\n",
    "elo_ratings_list = [*ratings_api.get_elo_ratings(year=current_year, week=current_week)]\n",
    "elo_ratings_dict = [dict(\n",
    "    team = e.team,\n",
    "    elo = e.elo\n",
    ") for e in elo_ratings_list]\n",
    "elo_ratings = pd.DataFrame(elo_ratings_dict)\n",
    "\n",
    "week_games['home_elo'] = week_games.apply(\n",
    "    lambda row: elo_ratings.loc[elo_ratings['team'] == row['home_team'], 'elo'].values[0]\n",
    "    if pd.isna(row['home_elo']) else row['home_elo'], axis=1\n",
    ")\n",
    "\n",
    "# Update `away_elo` where it is NaN or None\n",
    "week_games['away_elo'] = week_games.apply(\n",
    "    lambda row: elo_ratings.loc[elo_ratings['team'] == row['away_team'], 'elo'].values[0]\n",
    "    if pd.isna(row['away_elo']) else row['away_elo'], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "def round_to_nearest_half(x):\n",
    "    return np.round(x * 2) / 2\n",
    "week_games = week_games.merge(\n",
    "    team_data[['team', 'power_rating']],\n",
    "    left_on='home_team',\n",
    "    right_on='team',\n",
    "    how='left'\n",
    ").rename(columns={'power_rating': 'home_pr'})\n",
    "week_games = week_games.merge(\n",
    "    team_data[['team', 'power_rating']],\n",
    "    left_on='away_team',\n",
    "    right_on='team',\n",
    "    how='left'\n",
    ").rename(columns={'power_rating': 'away_pr'})\n",
    "week_games = week_games.drop(columns=['team_x', 'team_y'])\n",
    "\n",
    "\n",
    "week_games = week_games.merge(\n",
    "    all_data[['team', 'offensive_total', 'defensive_total']],\n",
    "    left_on='home_team',\n",
    "    right_on='team',\n",
    "    how='left'\n",
    ").rename(columns={'offensive_total':'home_offense', 'defensive_total':'home_defense'})\n",
    "week_games = week_games.merge(\n",
    "    all_data[['team', 'offensive_total', 'defensive_total']],\n",
    "    left_on='away_team',\n",
    "    right_on='team',\n",
    "    how='left'\n",
    ").rename(columns={'offensive_total':'away_offense', 'defensive_total':'away_defense'})\n",
    "week_games = week_games.drop(columns=['team_x', 'team_y'])\n",
    "week_games['xhome_points'] = round((week_games['home_offense'] - week_games['away_defense'] + (4.6/2)),1)\n",
    "week_games['xaway_points'] = round((week_games['away_offense'] - week_games['home_defense'] - (4.6/2)),1)\n",
    "week_games['predicted_over_under'] = week_games['xhome_points'] + week_games['xaway_points']\n",
    "\n",
    "def adjust_home_pr(home_win_prob):\n",
    "    return ((home_win_prob - 50) / 50) * 5\n",
    "week_games['home_win_prob'] = round((10**((week_games['home_elo'] - week_games['away_elo']) / 400)) / ((10**((week_games['home_elo'] - week_games['away_elo']) / 400)) + 1)*100,2)\n",
    "week_games['pr_spread'] = (4.6 + week_games['home_pr'] + (week_games['home_win_prob'].apply(adjust_home_pr)) - week_games['away_pr']).round(1)\n",
    "week_games['pr_spread'] = np.where(week_games['neutral'], week_games['pr_spread'] - 4.6, week_games['pr_spread']).round(1)\n",
    "# week_games['pr_spread'] = week_games['pr_spread'].apply(round_to_nearest_half)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler10 = MinMaxScaler(feature_range=(1,10))\n",
    "week_games['game_quality'] = ((week_games['home_pr'] + week_games['away_pr']) / 2) - abs(week_games['pr_spread'] * 0.5)\n",
    "week_games['game_quality'] = round(week_games['game_quality'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betting Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Comparing Prediction to Vegas Spread\n",
    "\n",
    "if postseason:\n",
    "    betting = []\n",
    "    response = betting_api.get_lines(year=current_year, week=post_season_week, season_type=\"postseason\")\n",
    "    betting.extend(response)  # Use extend for list concatenation\n",
    "else:\n",
    "    betting = []\n",
    "    response = betting_api.get_lines(year=current_year, week=current_week)\n",
    "    betting.extend(response)  # Use extend for list concatenation\n",
    "\n",
    "\n",
    "betting_info_list = []\n",
    "\n",
    "for bet in betting:\n",
    "    data = bet.to_dict() if hasattr(bet, 'to_dict') else vars(bet)\n",
    "    lines = pd.DataFrame(data['lines'])\n",
    "\n",
    "    if not lines.empty:\n",
    "        # Try to get consensus lines first\n",
    "        consensus_lines = lines[lines['provider'] == 'consensus']\n",
    "        \n",
    "        if consensus_lines.empty:\n",
    "            consensus_lines = lines[lines['provider'] == 'DraftKings']\n",
    "        if consensus_lines.empty:\n",
    "            consensus_lines = lines[lines['provider'] == 'ESPN Bet']\n",
    "        if consensus_lines.empty:\n",
    "            consensus_lines = lines[lines['provider'] == 'Bovada']\n",
    "        \n",
    "\n",
    "\n",
    "        if not consensus_lines.empty:\n",
    "            consensus_lines = consensus_lines[['spread', 'formatted_spread','spread_open', 'over_under']]\n",
    "            combined_data = {\n",
    "                'id': data['id'],\n",
    "                'season_type': data['season_type']\n",
    "            }\n",
    "            df = pd.DataFrame([combined_data])\n",
    "            full_df = pd.concat([df.reset_index(drop=True), consensus_lines.reset_index(drop=True)], axis=1)\n",
    "            betting_info_list.append(full_df)\n",
    "\n",
    "betting_info = pd.concat(betting_info_list, ignore_index=True)\n",
    "week_games = pd.merge(week_games, betting_info, on='id', how='left')\n",
    "week_games['spread'] = week_games['spread'] * -1\n",
    "week_games['spread_open'] = week_games['spread_open'] * -1\n",
    "\n",
    "# if current_week == 7:\n",
    "#     week_games.loc[week_games['home_team'] == 'Western Kentucky', 'pr_spread'] += 0.5\n",
    "\n",
    "# Capping predictions that are more than 15 points away from the Vegas Spread\n",
    "threshold = 10\n",
    "capped_preds = np.clip(week_games['pr_spread'], week_games['spread'] - threshold, week_games['spread'] + threshold)\n",
    "week_games['pr_spread'] = capped_preds\n",
    "\n",
    "# Function to find out if PR predicts the favorite or underdog\n",
    "def calculate_pr_prediction(row, pr_spread_col, vegas_spread_col):\n",
    "    if (row[vegas_spread_col] < 0) and (row[pr_spread_col] < 0) and (row[pr_spread_col] < row[vegas_spread_col]):\n",
    "        return 'Favorite'\n",
    "    elif (row[vegas_spread_col] > 0) and (row[pr_spread_col] > 0) and (row[pr_spread_col] > row[vegas_spread_col]):\n",
    "        return 'Favorite'\n",
    "    elif (row[vegas_spread_col] == row[pr_spread_col]):\n",
    "        return 'Exact'\n",
    "    else:\n",
    "        return 'Underdog'\n",
    "\n",
    "week_games['formatted_open'] = week_games.apply(\n",
    "    lambda row: f\"{row['away_team']} {row['spread_open']}\" if row['spread_open'] < 0 \n",
    "                else f\"{row['home_team']} -{row['spread_open']}\", axis=1\n",
    ")\n",
    "\n",
    "# Use the above function\n",
    "def add_pr_prediction(week_games, pr_spread_col, vegas_spread_col, prediction_col_name='pr_prediction'):\n",
    "    week_games[prediction_col_name] = week_games.apply(calculate_pr_prediction, axis=1, args=(pr_spread_col,vegas_spread_col,))\n",
    "    return week_games\n",
    "week_games = add_pr_prediction(week_games, 'pr_spread', 'spread', 'pr_prediction')\n",
    "week_games = add_pr_prediction(week_games, 'pr_spread', 'spread_open', 'opening_spread_prediction')\n",
    "\n",
    "# Formatting the KRATOS Power Rating Spread\n",
    "week_games['ESCAPE'] = week_games.apply(\n",
    "    lambda row: f\"{row['away_team']} {-abs(row['pr_spread'])}\" if ((row['pr_spread'] <= 0)) \n",
    "    else f\"{row['home_team']} {-abs(row['pr_spread'])}\", axis=1)\n",
    "\n",
    "week_games['difference'] = abs(week_games['pr_spread'] - week_games['spread'])\n",
    "week_games['opening_difference'] = abs(week_games['pr_spread'] - week_games['spread_open'])\n",
    "week_games['over_under_difference'] = abs(week_games['over_under'] - week_games['predicted_over_under'])\n",
    "week_games = week_games.sort_values(by=[\"difference\", \"home_win_prob\"], ascending=False).reset_index(drop=True)\n",
    "week_games = week_games.drop_duplicates(subset='home_team')\n",
    "prediction_information = week_games[['home_team', 'away_team', 'game_quality', 'home_win_prob','difference', 'formatted_open', 'formatted_spread', 'ESCAPE', 'pr_prediction', 'home_pr', 'away_pr']]\n",
    "prediction_information = prediction_information.dropna()\n",
    "print(\"Total Difference from Vegas Spread:\", round(sum(prediction_information['difference']),1))\n",
    "print(\"Average Difference from Vegas Spread:\", round(sum(prediction_information['difference'])/len(prediction_information), 2))\n",
    "print(\"Average Over Under Difference\", round(sum(week_games['over_under_difference'])/len(week_games), 2))\n",
    "\n",
    "# Graphing the spread\n",
    "spreads_sorted = prediction_information['difference'].sort_values()\n",
    "count_below_3 = len(spreads_sorted[spreads_sorted <= 4.5])\n",
    "count_above_7 = len(spreads_sorted[spreads_sorted >= 5])\n",
    "x_values = range(1, len(spreads_sorted) + 1)\n",
    "y_min = spreads_sorted.min()\n",
    "y_max = spreads_sorted.max()\n",
    "y_ticks = np.arange(np.floor(y_min), np.ceil(y_max) + 0.5, 0.5)\n",
    "plt.figure(figsize=(8, 4))  # Increase figure size for better visibility\n",
    "plt.plot(x_values, spreads_sorted, marker='o', linestyle='-', color='b', markersize=4)\n",
    "plt.axhspan(ymin=y_min, ymax=4.5, color='blue', alpha=0.2)  # Green shade for y < 3\n",
    "plt.axhline(y=4.5, linestyle = '--', color = 'darkgreen')\n",
    "if y_max > 4.5:\n",
    "    plt.axhspan(ymin=4.5, ymax=y_max, color='darkgreen', alpha=0.2)     # Red shade for y > 7\n",
    "    plt.axhline(y=4.5, linestyle = '--', color = 'darkgreen')\n",
    "    plt.text(len(x_values) * 0.05, 5.5, f'{count_above_7}', color='black', fontsize=10)\n",
    "# Display the count of games in each range on the plot\n",
    "plt.text(len(x_values) * 0.05, 1.5, f'{count_below_3}', color='black', fontsize=10)\n",
    "plt.title('Difference from Vegas Spread Tracked by Game')\n",
    "plt.xlabel('Game')\n",
    "plt.ylabel('Difference from Vegas Spread')\n",
    "plt.grid(True)\n",
    "plt.yticks(y_ticks)\n",
    "plt.tick_params(axis='y', labelsize=7)\n",
    "plt.show()\n",
    "\n",
    "prediction_information[0:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### formatting game results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import explained_variance_score\n",
    "week_games['actual_margin'] = week_games['home_points'] - week_games['away_points']\n",
    "def calculate_margin_team(row):\n",
    "    if row['actual_margin'] > 0:\n",
    "        return f\"{row['home_team']} -{row['actual_margin']}\"  # If actual_margin is positive\n",
    "    elif row['actual_margin'] < 0:\n",
    "        return f\"{row['away_team']} {row['actual_margin']}\"  # If actual_margin is negative\n",
    "    else:\n",
    "        return ''\n",
    "week_games['actual_spread'] = week_games.apply(calculate_margin_team, axis=1)\n",
    "week_games = add_pr_prediction(week_games, 'actual_margin', 'spread', 'CLOSE ATS RESULT')\n",
    "week_games = add_pr_prediction(week_games, 'actual_margin', 'spread_open', 'OPEN ATS RESULT')\n",
    "\n",
    "def check_prediction_correct(row, prediction_col, ats_tester):\n",
    "    if row['actual_spread'] == '':\n",
    "        return ''\n",
    "    if row[prediction_col] == row[ats_tester]:\n",
    "        return 1\n",
    "    elif 'Exact' in (row[prediction_col], row[ats_tester]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "# Apply the check prediction function and store the result in a new column\n",
    "week_games['ESCAPE ATS CLOSE'] = week_games.apply(lambda row: check_prediction_correct(row, 'pr_prediction', 'CLOSE ATS RESULT'), axis=1)\n",
    "week_games['ESCAPE ATS OPEN'] = week_games.apply(lambda row: check_prediction_correct(row, 'opening_spread_prediction', 'OPEN ATS RESULT'), axis=1)\n",
    "\n",
    "def check_straight_up(row, prediction_col):\n",
    "    if row['actual_spread'] == '':\n",
    "        return ''\n",
    "    if (row['actual_margin'] < 0) and (row[prediction_col] < 0):\n",
    "        return 1\n",
    "    elif (row['actual_margin'] > 0) and (row[prediction_col] > 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "week_games['ESCAPE SU'] = week_games.apply(lambda row: check_straight_up(row, 'pr_spread'), axis = 1)\n",
    "game_completion_info = week_games[['home_team', 'away_team', 'difference', 'formatted_open', 'formatted_spread', 'ESCAPE', 'spread', 'actual_margin', 'actual_spread', 'ESCAPE ATS OPEN', 'ESCAPE ATS CLOSE', 'ESCAPE SU']]\n",
    "completed = game_completion_info[game_completion_info[\"ESCAPE ATS CLOSE\"] != '']\n",
    "no_pushes = completed[completed['difference'] != 0]\n",
    "no_pushes = no_pushes[no_pushes['spread'] != no_pushes['actual_margin']]\n",
    "\n",
    "X = 10\n",
    "if len(completed) > 0:\n",
    "    win_difference = completed.loc[completed[\"ESCAPE ATS CLOSE\"] == 1, \"difference\"].sum()\n",
    "    total_difference = completed['difference'].sum()\n",
    "    MAE = round(abs(week_games['actual_margin'] - week_games['pr_spread']).mean(),2)\n",
    "    DAE = round(abs(week_games['actual_margin'] - week_games['pr_spread']).median(),2)\n",
    "    RMSE = round(math.sqrt(((week_games['actual_margin'] - week_games['pr_spread']) ** 2).mean()),2)\n",
    "    count = (abs(week_games['actual_margin'] - week_games['pr_spread']) < X).sum()\n",
    "    MAE_plus = 0.5 * MAE + 0.25 * DAE + 0.25 * RMSE\n",
    "    wATS = round(win_difference/total_difference * 100, 2)\n",
    "    print(f\"SU: {round(100*sum(completed['ESCAPE SU'] / len(completed)),2)}%  -  {sum(completed['ESCAPE SU'])}/{len(completed)}\")\n",
    "    print(f\"ATS: {round(100 * sum(no_pushes['ESCAPE ATS CLOSE']) / len(no_pushes),2)}%  -  {sum(no_pushes['ESCAPE ATS CLOSE'])}/{len(no_pushes)}\")\n",
    "    print(f'wATS: {wATS}%')\n",
    "    print(f\"MAE: {MAE}\")\n",
    "    print(f\"DAE: {DAE}\")\n",
    "    print(f\"RMSE: {RMSE}\")\n",
    "    print(f\"MAE+: {round(100-MAE_plus,2)}%\")\n",
    "    print(f\"AE < {X}: {round(count/len(completed)*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_completion_info.to_excel(f'./ESCAPE Ratings/Spreads/y{current_year}/spreads_tracker_week{current_week}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Functions / Excursions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATS, SU, MAE, DAE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cfbd\n",
    "import statistics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "week_list = [9,10,11,12,13,14,15,16]\n",
    "current_year = 2024\n",
    "all_week_games = pd.DataFrame()\n",
    "for week in week_list:\n",
    "    current_week = week\n",
    "    current_year = 2024\n",
    "    team_data = pd.read_csv(f'./ESCAPE Ratings/Ratings/y{current_year}/ESCAPE_week{week}.csv').drop(columns=['Unnamed: 0'])\n",
    "    import datetime\n",
    "    configuration = cfbd.Configuration()\n",
    "    configuration.api_key['Authorization'] = '7vGedNNOrnl0NGcSvt92FcVahY602p7IroVBlCA1Tt+WI/dCwtT7Gj5VzmaHrrxS'\n",
    "    configuration.api_key_prefix['Authorization'] = 'Bearer'\n",
    "    api_client = cfbd.ApiClient(configuration)\n",
    "    advanced_instance = cfbd.StatsApi(api_client)\n",
    "    games_api = cfbd.GamesApi(api_client)\n",
    "    betting_api = cfbd.BettingApi(api_client)\n",
    "    ratings_api = cfbd.RatingsApi(api_client)\n",
    "    teams_api = cfbd.TeamsApi(api_client)\n",
    "    metrics_api = cfbd.MetricsApi(api_client)\n",
    "    players_api = cfbd.PlayersApi(api_client)\n",
    "    recruiting_api = cfbd.RecruitingApi(api_client)\n",
    "    def date_sort(game):\n",
    "        game_date = datetime.datetime.strptime(game['start_date'], \"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "        return game_date\n",
    "    games = []\n",
    "    response = games_api.get_games(year=current_year, week = current_week, division = 'fbs')\n",
    "    games = [*games, *response]\n",
    "    games = [dict(\n",
    "                id=g.id,\n",
    "                season=g.season,\n",
    "                week=g.week,\n",
    "                start_date=g.start_date,\n",
    "                home_team=g.home_team,\n",
    "                home_conference=g.home_conference,\n",
    "                home_points=g.home_points,\n",
    "                home_elo=g.home_pregame_elo,\n",
    "                away_team=g.away_team,\n",
    "                away_conference=g.away_conference,\n",
    "                away_points=g.away_points,\n",
    "                away_elo=g.away_pregame_elo,\n",
    "                neutral = g.neutral_site\n",
    "                ) for g in games if g.home_pregame_elo is not None and g.away_pregame_elo is not None]\n",
    "    games.sort(key=date_sort)\n",
    "    week_games = pd.DataFrame(games)\n",
    "    if current_week == 5:\n",
    "        week_games = week_games.dropna()\n",
    "    week_games.loc[week_games['home_team'] == \"Florida International\", 'neutral'] = False\n",
    "    import numpy as np\n",
    "    import math\n",
    "    def round_to_nearest_half(x):\n",
    "        return np.round(x * 2) / 2\n",
    "    week_games = week_games.merge(\n",
    "        team_data[['team', 'power_rating']],\n",
    "        left_on='home_team',\n",
    "        right_on='team',\n",
    "        how='left'\n",
    "    ).rename(columns={'power_rating': 'home_pr'})\n",
    "    week_games = week_games.merge(\n",
    "        team_data[['team', 'power_rating']],\n",
    "        left_on='away_team',\n",
    "        right_on='team',\n",
    "        how='left'\n",
    "    ).rename(columns={'power_rating': 'away_pr'})\n",
    "    week_games = week_games.drop(columns=['team_x', 'team_y'])\n",
    "\n",
    "    def ESCAPE_Win_Prob(home_pr, away_pr):\n",
    "        rating_diff = home_pr - away_pr\n",
    "        win_prob = round(1 / (1 + 10 ** (-rating_diff / 20)) * 100, 2)\n",
    "        return win_prob\n",
    "    week_games['ESCAPE_win_prob'] = ESCAPE_Win_Prob(week_games['home_pr'], week_games['away_pr'])\n",
    "    def adjust_home_pr(home_win_prob):\n",
    "        return ((home_win_prob - 50) / 50) * 5\n",
    "    \n",
    "    if current_week == 12:\n",
    "        week_games.loc[week_games['home_team'] == 'Buffalo', 'neutral'] = True\n",
    "\n",
    "\n",
    "    week_games['home_win_prob'] = round((10**((week_games['home_elo'] - week_games['away_elo']) / 400)) / ((10**((week_games['home_elo'] - week_games['away_elo']) / 400)) + 1)*100,2)\n",
    "    week_games['pr_spread'] = (4.6 + week_games['home_pr'] + (week_games['home_win_prob'].apply(adjust_home_pr)) - week_games['away_pr']).round(1)\n",
    "    week_games['pr_spread'] = np.where(week_games['neutral'], week_games['pr_spread'] - 4.6, week_games['pr_spread'])\n",
    "    # week_games['pr_spread'] = week_games['pr_spread'].apply(round_to_nearest_half)\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler10 = MinMaxScaler(feature_range=(1,10))\n",
    "    week_games['game_quality'] = ((week_games['home_pr'] + week_games['away_pr']) / 2) - abs(week_games['pr_spread'] * 0.5)\n",
    "    import matplotlib.pyplot as plt\n",
    "    # Comparing Prediction to Vegas Spread\n",
    "    betting = []\n",
    "    response = betting_api.get_lines(year=current_year, week=current_week)\n",
    "    betting.extend(response)  # Use extend for list concatenation\n",
    "\n",
    "    betting_info_list = []\n",
    "\n",
    "    for bet in betting:\n",
    "        data = bet.to_dict() if hasattr(bet, 'to_dict') else vars(bet)\n",
    "        lines = pd.DataFrame(data['lines'])\n",
    "\n",
    "        if not lines.empty:\n",
    "            # Try to get consensus lines first\n",
    "            consensus_lines = lines[lines['provider'] == 'consensus']\n",
    "            \n",
    "            if consensus_lines.empty:\n",
    "                consensus_lines = lines[lines['provider'] == 'DraftKings']\n",
    "            if consensus_lines.empty:\n",
    "                consensus_lines = lines[lines['provider'] == 'ESPN Bet']\n",
    "            if consensus_lines.empty:\n",
    "                consensus_lines = lines[lines['provider'] == 'Bovada']\n",
    "            \n",
    "\n",
    "\n",
    "            if not consensus_lines.empty:\n",
    "                consensus_lines = consensus_lines[['spread', 'formatted_spread','spread_open', 'over_under']]\n",
    "                combined_data = {\n",
    "                    'id': data['id'],\n",
    "                    'season_type': data['season_type']\n",
    "                }\n",
    "                df = pd.DataFrame([combined_data])\n",
    "                full_df = pd.concat([df.reset_index(drop=True), consensus_lines.reset_index(drop=True)], axis=1)\n",
    "                betting_info_list.append(full_df)\n",
    "\n",
    "    betting_info = pd.concat(betting_info_list, ignore_index=True)\n",
    "    week_games = pd.merge(week_games, betting_info, on='id', how='left')\n",
    "    week_games['spread'] = week_games['spread'] * -1\n",
    "    week_games['spread_open'] = week_games['spread_open'] * -1\n",
    "\n",
    "    # if current_week == 7:\n",
    "    #     week_games.loc[week_games['home_team'] == 'Western Kentucky', 'pr_spread'] += 0.5\n",
    "\n",
    "    # Capping predictions that are more than 15 points away from the Vegas Spread\n",
    "    threshold = 15\n",
    "    capped_preds = np.clip(week_games['pr_spread'], week_games['spread'] - threshold, week_games['spread'] + threshold)\n",
    "    week_games['pr_spread'] = capped_preds\n",
    "\n",
    "    # Function to find out if PR predicts the favorite or underdog\n",
    "    def calculate_pr_prediction(row, pr_spread_col, vegas_spread_col):\n",
    "        if (row[vegas_spread_col] < 0) and (row[pr_spread_col] < 0) and (row[pr_spread_col] < row[vegas_spread_col]):\n",
    "            return 'Favorite'\n",
    "        elif (row[vegas_spread_col] > 0) and (row[pr_spread_col] > 0) and (row[pr_spread_col] > row[vegas_spread_col]):\n",
    "            return 'Favorite'\n",
    "        elif (row[vegas_spread_col] == row[pr_spread_col]):\n",
    "            return 'Exact'\n",
    "        else:\n",
    "            return 'Underdog'\n",
    "\n",
    "    week_games['formatted_open'] = week_games.apply(\n",
    "        lambda row: f\"{row['away_team']} {row['spread_open']}\" if row['spread_open'] < 0 \n",
    "                    else f\"{row['home_team']} -{row['spread_open']}\", axis=1\n",
    "    )\n",
    "\n",
    "    def add_pr_prediction(week_games, pr_spread_col, vegas_spread_col, prediction_col_name='pr_prediction'):\n",
    "        week_games[prediction_col_name] = week_games.apply(calculate_pr_prediction, axis=1, args=(pr_spread_col,vegas_spread_col,))\n",
    "        return week_games\n",
    "    week_games = add_pr_prediction(week_games, 'pr_spread', 'spread', 'pr_prediction')\n",
    "    week_games = add_pr_prediction(week_games, 'pr_spread', 'spread_open', 'opening_spread_prediction')\n",
    "\n",
    "    week_games['ESCAPE'] = week_games.apply(\n",
    "        lambda row: f\"{row['away_team']} {-abs(row['pr_spread'])}\" if ((row['pr_spread'] <= 0)) \n",
    "        else f\"{row['home_team']} {-abs(row['pr_spread'])}\", axis=1)\n",
    "\n",
    "    week_games['difference'] = abs(week_games['pr_spread'] - week_games['spread'])\n",
    "    week_games['opening_difference'] = abs(week_games['pr_spread'] - week_games['spread_open'])\n",
    "    week_games = week_games.sort_values(by=[\"difference\", \"home_win_prob\"], ascending=False).reset_index(drop=True)\n",
    "    week_games = week_games.drop_duplicates(subset='home_team')\n",
    "    all_week_games = pd.concat([all_week_games, week_games])\n",
    "\n",
    "import math\n",
    "all_week_games['actual_margin'] = all_week_games['home_points'] - all_week_games['away_points']\n",
    "def calculate_margin_team(row):\n",
    "    if row['actual_margin'] > 0:\n",
    "        return f\"{row['home_team']} -{row['actual_margin']}\"  # If actual_margin is positive\n",
    "    elif row['actual_margin'] < 0:\n",
    "        return f\"{row['away_team']} {row['actual_margin']}\"  # If actual_margin is negative\n",
    "    else:\n",
    "        return ''\n",
    "all_week_games['actual_spread'] = all_week_games.apply(calculate_margin_team, axis=1)\n",
    "all_week_games = add_pr_prediction(all_week_games, 'actual_margin', 'spread', 'CLOSE ATS RESULT')\n",
    "all_week_games = add_pr_prediction(all_week_games, 'actual_margin', 'spread_open', 'OPEN ATS RESULT')\n",
    "\n",
    "def check_prediction_correct(row, prediction_col, ats_tester):\n",
    "    if row['actual_spread'] == '':\n",
    "        return ''\n",
    "    if row[prediction_col] == row[ats_tester]:\n",
    "        return 1\n",
    "    elif 'Exact' in (row[prediction_col], row[ats_tester]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "# Apply the check prediction function and store the result in a new column\n",
    "all_week_games['ESCAPE ATS CLOSE'] = all_week_games.apply(lambda row: check_prediction_correct(row, 'pr_prediction', 'CLOSE ATS RESULT'), axis=1)\n",
    "all_week_games['ESCAPE ATS OPEN'] = all_week_games.apply(lambda row: check_prediction_correct(row, 'opening_spread_prediction', 'OPEN ATS RESULT'), axis=1)\n",
    "\n",
    "def check_straight_up(row, prediction_col):\n",
    "    if row['actual_spread'] == '':\n",
    "        return ''\n",
    "    if (row['actual_margin'] < 0) and (row[prediction_col] < 0):\n",
    "        return 1\n",
    "    elif (row['actual_margin'] > 0) and (row[prediction_col] > 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "all_week_games['ESCAPE SU'] = all_week_games.apply(lambda row: check_straight_up(row, 'pr_spread'), axis = 1)\n",
    "completed = all_week_games[all_week_games[\"ESCAPE ATS CLOSE\"] != '']\n",
    "\n",
    "X = 10\n",
    "MAE = round(abs(all_week_games['actual_margin'] - all_week_games['pr_spread']).mean(),2)\n",
    "range_of_margin = abs(all_week_games['actual_margin']).max() - abs(all_week_games['actual_margin']).min()\n",
    "NMAE = round(100*MAE/range_of_margin,2)\n",
    "DAE = round(abs(all_week_games['actual_margin'] - all_week_games['pr_spread']).median(),2)\n",
    "NMDE = round(100*DAE/range_of_margin,2)\n",
    "RMSE = round(math.sqrt(((all_week_games['actual_margin'] - all_week_games['pr_spread']) ** 2).mean()),2)\n",
    "count = (abs(all_week_games['actual_margin'] - all_week_games['pr_spread']) < X).sum()\n",
    "MAE_plus = 0.5 * MAE + 0.25 * DAE + 0.25 * RMSE\n",
    "mbd = (completed['pr_spread'] - completed['actual_margin']).mean()\n",
    "mape = (completed.assign(\n",
    "            abs_pct_error=lambda x: abs((x['actual_margin'] - x['pr_spread']) / x['actual_margin'])\n",
    "        )['abs_pct_error'].mean() * 100)\n",
    "\n",
    "high_value = 6.4\n",
    "no_pushes = completed[completed['difference'] != 0.0]\n",
    "no_pushes = no_pushes[no_pushes['spread'] != no_pushes['actual_margin']]\n",
    "high_value_games = completed[completed['difference'] >= high_value]\n",
    "hv_MAE = round(abs(high_value_games['actual_margin'] - high_value_games['pr_spread']).mean(),2)\n",
    "hv_range = abs(high_value_games['actual_margin']).max() - abs(high_value_games['actual_margin']).min()\n",
    "hv_NMAE = round(100*hv_MAE/hv_range,2)\n",
    "hv_DAE = round(abs(high_value_games['actual_margin'] - high_value_games['pr_spread']).median(),2)\n",
    "hv_RMSE = round(math.sqrt(((high_value_games['actual_margin'] - high_value_games['pr_spread']) ** 2).mean()),2)\n",
    "hv_count = (abs(high_value_games['actual_margin'] - high_value_games['pr_spread']) < X).sum()\n",
    "\n",
    "print(f\"SU: {round(100*sum(completed['ESCAPE SU']) / len(completed),1)}% - {sum(completed['ESCAPE SU'])}/{len(completed)}\")\n",
    "print(f\"ATS: {round(100 * sum(no_pushes['ESCAPE ATS CLOSE']) / len(no_pushes),1)}% - {sum(no_pushes['ESCAPE ATS CLOSE'])}/{len(no_pushes)}\")\n",
    "# print(f\"MAPE: {mape}\")\n",
    "print(f\"MAE: {MAE}\")\n",
    "print(f\"NMAE: {NMAE}%\")\n",
    "print(f\"DAE: {DAE}\")\n",
    "print(f\"NMDE: {NMDE}%\")\n",
    "print(f\"RMSE: {RMSE}\")\n",
    "print(f\"MAE+: {round(100-MAE_plus,1)}%\")\n",
    "print(f\"AE < {X}: {round(count/len(completed)*100,1)}%\")\n",
    "print(\"------------------------------------\")\n",
    "print(f\"High Value Games with Difference Above {high_value}\")\n",
    "print(f\"High Value Percent: {round(100*len(high_value_games)/len(completed),1)}%\")\n",
    "print(f\"SU: {round(100*sum(high_value_games['ESCAPE SU']) / len(high_value_games),1)}% - {sum(high_value_games['ESCAPE SU'])}/{len(high_value_games)}\")\n",
    "print(f\"ATS: {round(100 * sum(high_value_games['ESCAPE ATS CLOSE']) / len(high_value_games),1)}% - {sum(high_value_games['ESCAPE ATS CLOSE'])}/{len(high_value_games)}\")\n",
    "print(f\"MAE: {hv_MAE}\")\n",
    "print(f\"NMAE: {hv_NMAE}%\")\n",
    "print(f\"DAE: {hv_DAE}\")\n",
    "print(f\"RMSE: {hv_RMSE}\")\n",
    "print(f\"AE < {X}: {round(hv_count/len(high_value_games)*100, 1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Value Game Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "numbers = np.arange(0, 15.1, 0.1).tolist()\n",
    "best_ats = 0\n",
    "best_high_value = 0\n",
    "least_amount_games = max(math.ceil(0.1 * len(completed)), 1)\n",
    "for high_value in numbers:\n",
    "    high_value_games = completed[completed['difference'] >= high_value]\n",
    "    if len(high_value_games) >= least_amount_games:\n",
    "        ats = sum(high_value_games['ESCAPE ATS CLOSE']) / len(high_value_games)\n",
    "        if ats > best_ats:\n",
    "            best_ats = ats\n",
    "            best_high_value = high_value\n",
    "print(f\"Best ATS: {round(100*best_ats,1)}%, Best Value: Diff >= {round(best_high_value,1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent of Results Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "mean_actual = abs(all_week_games['actual_margin']).mean()\n",
    "std_actual = abs(all_week_games['actual_margin']).std()\n",
    "# Adjusting x values to stop at 0\n",
    "x_values = np.linspace(0, mean_actual + 4 * std_actual, 1000)\n",
    "y_values = (1 / (std_actual * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x_values - mean_actual) / std_actual)**2)\n",
    "\n",
    "# Calculate the cumulative probability within +/- MAE\n",
    "cdf_low = norm.cdf(-MAE, loc=mean_actual, scale=std_actual)  # CDF at -MAE\n",
    "cdf_high = norm.cdf(MAE, loc=mean_actual, scale=std_actual)  # CDF at +MAE\n",
    "\n",
    "# Total percentage of results explained by MAE\n",
    "percent_explained = (cdf_high - cdf_low) * 100\n",
    "print(100 - percent_explained)\n",
    "\n",
    "# Plotting the adjusted normal distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_values, y_values, label=f\"Mean: {mean_actual:.2f}, Std Dev: {std_actual:.2f}\")\n",
    "plt.title(\"Normal Distribution of Absolute Actual Margin (Truncated at 0)\")\n",
    "plt.axvline(x=mean_actual + MAE, color=\"red\", linestyle=\"--\")\n",
    "plt.axvline(x=mean_actual - MAE, color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"Margin\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cfbd\n",
    "import statistics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "backtesting_week = 16\n",
    "week_list = [9,10,11,12,13,14,15,16]\n",
    "all_week_games = pd.DataFrame()\n",
    "for week in week_list:\n",
    "    current_week = week\n",
    "    current_year = 2024\n",
    "    team_data = pd.read_csv(f'./ESCAPE Ratings/ESCAPE_week{backtesting_week}_{current_year}.csv').drop(columns=['Unnamed: 0'])\n",
    "    import datetime\n",
    "    configuration = cfbd.Configuration()\n",
    "    configuration.api_key['Authorization'] = '7vGedNNOrnl0NGcSvt92FcVahY602p7IroVBlCA1Tt+WI/dCwtT7Gj5VzmaHrrxS'\n",
    "    configuration.api_key_prefix['Authorization'] = 'Bearer'\n",
    "    api_client = cfbd.ApiClient(configuration)\n",
    "    advanced_instance = cfbd.StatsApi(api_client)\n",
    "    games_api = cfbd.GamesApi(api_client)\n",
    "    betting_api = cfbd.BettingApi(api_client)\n",
    "    ratings_api = cfbd.RatingsApi(api_client)\n",
    "    teams_api = cfbd.TeamsApi(api_client)\n",
    "    metrics_api = cfbd.MetricsApi(api_client)\n",
    "    players_api = cfbd.PlayersApi(api_client)\n",
    "    recruiting_api = cfbd.RecruitingApi(api_client)\n",
    "    def date_sort(game):\n",
    "        game_date = datetime.datetime.strptime(game['start_date'], \"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "        return game_date\n",
    "    games = []\n",
    "    response = games_api.get_games(year=current_year, week = current_week, division = 'fbs')\n",
    "    games = [*games, *response]\n",
    "    games = [dict(\n",
    "                id=g.id,\n",
    "                season=g.season,\n",
    "                week=g.week,\n",
    "                start_date=g.start_date,\n",
    "                home_team=g.home_team,\n",
    "                home_conference=g.home_conference,\n",
    "                home_points=g.home_points,\n",
    "                home_elo=g.home_pregame_elo,\n",
    "                away_team=g.away_team,\n",
    "                away_conference=g.away_conference,\n",
    "                away_points=g.away_points,\n",
    "                away_elo=g.away_pregame_elo,\n",
    "                neutral = g.neutral_site\n",
    "                ) for g in games if g.home_pregame_elo is not None and g.away_pregame_elo is not None]\n",
    "    games.sort(key=date_sort)\n",
    "    week_games = pd.DataFrame(games)\n",
    "    if current_week == 5:\n",
    "        week_games = week_games.dropna()\n",
    "    week_games.loc[week_games['home_team'] == \"Florida International\", 'neutral'] = False\n",
    "    import numpy as np\n",
    "    import math\n",
    "    def round_to_nearest_half(x):\n",
    "        return np.round(x * 2) / 2\n",
    "    week_games = week_games.merge(\n",
    "        team_data[['team', 'power_rating']],\n",
    "        left_on='home_team',\n",
    "        right_on='team',\n",
    "        how='left'\n",
    "    ).rename(columns={'power_rating': 'home_pr'})\n",
    "    week_games = week_games.merge(\n",
    "        team_data[['team', 'power_rating']],\n",
    "        left_on='away_team',\n",
    "        right_on='team',\n",
    "        how='left'\n",
    "    ).rename(columns={'power_rating': 'away_pr'})\n",
    "    week_games = week_games.drop(columns=['team_x', 'team_y'])\n",
    "\n",
    "    def ESCAPE_Win_Prob(home_pr, away_pr):\n",
    "        rating_diff = home_pr - away_pr\n",
    "        win_prob = round(1 / (1 + 10 ** (-rating_diff / 20)) * 100, 2)\n",
    "        return win_prob\n",
    "    week_games['ESCAPE_win_prob'] = ESCAPE_Win_Prob(week_games['home_pr'], week_games['away_pr'])\n",
    "    def adjust_home_pr(home_win_prob):\n",
    "        return ((home_win_prob - 50) / 50) * 5\n",
    "    \n",
    "    if current_week == 12:\n",
    "        week_games.loc[week_games['home_team'] == 'Buffalo', 'neutral'] = True\n",
    "\n",
    "\n",
    "    week_games['home_win_prob'] = round((10**((week_games['home_elo'] - week_games['away_elo']) / 400)) / ((10**((week_games['home_elo'] - week_games['away_elo']) / 400)) + 1)*100,2)\n",
    "    week_games['pr_spread'] = (4.6 + week_games['home_pr'] + (week_games['home_win_prob'].apply(adjust_home_pr)) - week_games['away_pr']).round(1)\n",
    "    week_games['pr_spread'] = np.where(week_games['neutral'], week_games['pr_spread'] - 4.6, week_games['pr_spread'])\n",
    "    # week_games['pr_spread'] = week_games['pr_spread'].apply(round_to_nearest_half)\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler10 = MinMaxScaler(feature_range=(1,10))\n",
    "    week_games['game_quality'] = ((week_games['home_pr'] + week_games['away_pr']) / 2) - abs(week_games['pr_spread'] * 0.5)\n",
    "    import matplotlib.pyplot as plt\n",
    "    # Comparing Prediction to Vegas Spread\n",
    "    betting = []\n",
    "    response = betting_api.get_lines(year=current_year, week=current_week)\n",
    "    betting.extend(response)  # Use extend for list concatenation\n",
    "\n",
    "    betting_info_list = []\n",
    "\n",
    "    for bet in betting:\n",
    "        data = bet.to_dict() if hasattr(bet, 'to_dict') else vars(bet)\n",
    "        lines = pd.DataFrame(data['lines'])\n",
    "\n",
    "        if not lines.empty:\n",
    "            # Try to get consensus lines first\n",
    "            consensus_lines = lines[lines['provider'] == 'consensus']\n",
    "            \n",
    "            if consensus_lines.empty:\n",
    "                consensus_lines = lines[lines['provider'] == 'DraftKings']\n",
    "            if consensus_lines.empty:\n",
    "                consensus_lines = lines[lines['provider'] == 'ESPN Bet']\n",
    "            if consensus_lines.empty:\n",
    "                consensus_lines = lines[lines['provider'] == 'Bovada']\n",
    "            \n",
    "\n",
    "\n",
    "            if not consensus_lines.empty:\n",
    "                consensus_lines = consensus_lines[['spread', 'formatted_spread','spread_open', 'over_under']]\n",
    "                combined_data = {\n",
    "                    'id': data['id'],\n",
    "                    'season_type': data['season_type']\n",
    "                }\n",
    "                df = pd.DataFrame([combined_data])\n",
    "                full_df = pd.concat([df.reset_index(drop=True), consensus_lines.reset_index(drop=True)], axis=1)\n",
    "                betting_info_list.append(full_df)\n",
    "\n",
    "    betting_info = pd.concat(betting_info_list, ignore_index=True)\n",
    "    week_games = pd.merge(week_games, betting_info, on='id', how='left')\n",
    "    week_games['spread'] = week_games['spread'] * -1\n",
    "    week_games['spread_open'] = week_games['spread_open'] * -1\n",
    "\n",
    "    # if current_week == 7:\n",
    "    #     week_games.loc[week_games['home_team'] == 'Western Kentucky', 'pr_spread'] += 0.5\n",
    "\n",
    "    # Capping predictions that are more than 15 points away from the Vegas Spread\n",
    "    threshold = 15\n",
    "    capped_preds = np.clip(week_games['pr_spread'], week_games['spread'] - threshold, week_games['spread'] + threshold)\n",
    "    week_games['pr_spread'] = capped_preds\n",
    "\n",
    "    # Function to find out if PR predicts the favorite or underdog\n",
    "    def calculate_pr_prediction(row, pr_spread_col, vegas_spread_col):\n",
    "        if (row[vegas_spread_col] < 0) and (row[pr_spread_col] < 0) and (row[pr_spread_col] < row[vegas_spread_col]):\n",
    "            return 'Favorite'\n",
    "        elif (row[vegas_spread_col] > 0) and (row[pr_spread_col] > 0) and (row[pr_spread_col] > row[vegas_spread_col]):\n",
    "            return 'Favorite'\n",
    "        elif (row[vegas_spread_col] == row[pr_spread_col]):\n",
    "            return 'Exact'\n",
    "        else:\n",
    "            return 'Underdog'\n",
    "\n",
    "    week_games['formatted_open'] = week_games.apply(\n",
    "        lambda row: f\"{row['away_team']} {row['spread_open']}\" if row['spread_open'] < 0 \n",
    "                    else f\"{row['home_team']} -{row['spread_open']}\", axis=1\n",
    "    )\n",
    "\n",
    "    def add_pr_prediction(week_games, pr_spread_col, vegas_spread_col, prediction_col_name='pr_prediction'):\n",
    "        week_games[prediction_col_name] = week_games.apply(calculate_pr_prediction, axis=1, args=(pr_spread_col,vegas_spread_col,))\n",
    "        return week_games\n",
    "    week_games = add_pr_prediction(week_games, 'pr_spread', 'spread', 'pr_prediction')\n",
    "    week_games = add_pr_prediction(week_games, 'pr_spread', 'spread_open', 'opening_spread_prediction')\n",
    "\n",
    "    week_games['ESCAPE'] = week_games.apply(\n",
    "        lambda row: f\"{row['away_team']} {-abs(row['pr_spread'])}\" if ((row['pr_spread'] <= 0)) \n",
    "        else f\"{row['home_team']} {-abs(row['pr_spread'])}\", axis=1)\n",
    "\n",
    "    week_games['difference'] = abs(week_games['pr_spread'] - week_games['spread'])\n",
    "    week_games['opening_difference'] = abs(week_games['pr_spread'] - week_games['spread_open'])\n",
    "    week_games = week_games.sort_values(by=[\"difference\", \"home_win_prob\"], ascending=False).reset_index(drop=True)\n",
    "    week_games = week_games.drop_duplicates(subset='home_team')\n",
    "    all_week_games = pd.concat([all_week_games, week_games])\n",
    "\n",
    "import math\n",
    "all_week_games['actual_margin'] = all_week_games['home_points'] - all_week_games['away_points']\n",
    "def calculate_margin_team(row):\n",
    "    if row['actual_margin'] > 0:\n",
    "        return f\"{row['home_team']} -{row['actual_margin']}\"  # If actual_margin is positive\n",
    "    elif row['actual_margin'] < 0:\n",
    "        return f\"{row['away_team']} {row['actual_margin']}\"  # If actual_margin is negative\n",
    "    else:\n",
    "        return ''\n",
    "all_week_games['actual_spread'] = all_week_games.apply(calculate_margin_team, axis=1)\n",
    "all_week_games = add_pr_prediction(all_week_games, 'actual_margin', 'spread', 'CLOSE ATS RESULT')\n",
    "all_week_games = add_pr_prediction(all_week_games, 'actual_margin', 'spread_open', 'OPEN ATS RESULT')\n",
    "\n",
    "def check_prediction_correct(row, prediction_col, ats_tester):\n",
    "    if row['actual_spread'] == '':\n",
    "        return ''\n",
    "    if row[prediction_col] == row[ats_tester]:\n",
    "        return 1\n",
    "    elif 'Exact' in (row[prediction_col], row[ats_tester]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "# Apply the check prediction function and store the result in a new column\n",
    "all_week_games['ESCAPE ATS CLOSE'] = all_week_games.apply(lambda row: check_prediction_correct(row, 'pr_prediction', 'CLOSE ATS RESULT'), axis=1)\n",
    "all_week_games['ESCAPE ATS OPEN'] = all_week_games.apply(lambda row: check_prediction_correct(row, 'opening_spread_prediction', 'OPEN ATS RESULT'), axis=1)\n",
    "\n",
    "def check_straight_up(row, prediction_col):\n",
    "    if row['actual_spread'] == '':\n",
    "        return ''\n",
    "    if (row['actual_margin'] < 0) and (row[prediction_col] < 0):\n",
    "        return 1\n",
    "    elif (row['actual_margin'] > 0) and (row[prediction_col] > 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "all_week_games['ESCAPE SU'] = all_week_games.apply(lambda row: check_straight_up(row, 'pr_spread'), axis = 1)\n",
    "completed = all_week_games[all_week_games[\"ESCAPE ATS CLOSE\"] != '']\n",
    "\n",
    "X = 10\n",
    "MAE = round(abs(all_week_games['actual_margin'] - all_week_games['pr_spread']).mean(),2)\n",
    "range_of_margin = abs(all_week_games['actual_margin']).max() - abs(all_week_games['actual_margin']).min()\n",
    "NMAE = round(100*MAE/range_of_margin,2)\n",
    "DAE = round(abs(all_week_games['actual_margin'] - all_week_games['pr_spread']).median(),2)\n",
    "NMDE = round(100*DAE/range_of_margin,2)\n",
    "RMSE = round(math.sqrt(((all_week_games['actual_margin'] - all_week_games['pr_spread']) ** 2).mean()),2)\n",
    "count = (abs(all_week_games['actual_margin'] - all_week_games['pr_spread']) < X).sum()\n",
    "MAE_plus = 0.5 * MAE + 0.25 * DAE + 0.25 * RMSE\n",
    "mbd = (completed['pr_spread'] - completed['actual_margin']).mean()\n",
    "mape = (completed.assign(\n",
    "            abs_pct_error=lambda x: abs((x['actual_margin'] - x['pr_spread']) / x['actual_margin'])\n",
    "        )['abs_pct_error'].mean() * 100)\n",
    "\n",
    "high_value = 6.4\n",
    "no_pushes = completed[completed['difference'] != 0.0]\n",
    "no_pushes = no_pushes[no_pushes['spread'] != no_pushes['actual_margin']]\n",
    "high_value_games = completed[completed['difference'] >= high_value]\n",
    "hv_MAE = round(abs(high_value_games['actual_margin'] - high_value_games['pr_spread']).mean(),2)\n",
    "hv_range = abs(high_value_games['actual_margin']).max() - abs(high_value_games['actual_margin']).min()\n",
    "hv_NMAE = round(100*hv_MAE/hv_range,2)\n",
    "hv_DAE = round(abs(high_value_games['actual_margin'] - high_value_games['pr_spread']).median(),2)\n",
    "hv_RMSE = round(math.sqrt(((high_value_games['actual_margin'] - high_value_games['pr_spread']) ** 2).mean()),2)\n",
    "hv_count = (abs(high_value_games['actual_margin'] - high_value_games['pr_spread']) < X).sum()\n",
    "\n",
    "print(f\"SU: {round(100*sum(completed['ESCAPE SU']) / len(completed),1)}% - {sum(completed['ESCAPE SU'])}/{len(completed)}\")\n",
    "print(f\"ATS: {round(100 * sum(no_pushes['ESCAPE ATS CLOSE']) / len(no_pushes),1)}% - {sum(no_pushes['ESCAPE ATS CLOSE'])}/{len(no_pushes)}\")\n",
    "# print(f\"MAPE: {mape}\")\n",
    "print(f\"MAE: {MAE}\")\n",
    "print(f\"NMAE: {NMAE}%\")\n",
    "print(f\"DAE: {DAE}\")\n",
    "print(f\"NMDE: {NMDE}%\")\n",
    "print(f\"RMSE: {RMSE}\")\n",
    "print(f\"MAE+: {round(100-MAE_plus,1)}%\")\n",
    "print(f\"AE < {X}: {round(count/len(completed)*100,1)}%\")\n",
    "print(\"------------------------------------\")\n",
    "print(f\"High Value Games with Difference Above {high_value}\")\n",
    "print(f\"High Value Percent: {round(100*len(high_value_games)/len(completed),1)}%\")\n",
    "print(f\"SU: {round(100*sum(high_value_games['ESCAPE SU']) / len(high_value_games),1)}% - {sum(high_value_games['ESCAPE SU'])}/{len(high_value_games)}\")\n",
    "print(f\"ATS: {round(100 * sum(high_value_games['ESCAPE ATS CLOSE']) / len(high_value_games),1)}% - {sum(high_value_games['ESCAPE ATS CLOSE'])}/{len(high_value_games)}\")\n",
    "print(f\"MAE: {hv_MAE}\")\n",
    "print(f\"NMAE: {hv_NMAE}%\")\n",
    "print(f\"DAE: {hv_DAE}\")\n",
    "print(f\"RMSE: {hv_RMSE}\")\n",
    "print(f\"AE < {X}: {round(hv_count/len(high_value_games)*100, 1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Year Long Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of weeks to process\n",
    "week_list = [9, 10, 11, 12, 13, 14, 15, 16]\n",
    "current_year = 2024\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Loop through the week_list\n",
    "for week in week_list:\n",
    "    file_path = f'./ESCAPE Ratings/Ratings/y{current_year}/ESCAPE_week{week}.csv'\n",
    "    # Read the dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Add the week as a column for identification\n",
    "    df[\"Week\"] = f\"Week {week}\"\n",
    "    \n",
    "    # Keep only necessary columns\n",
    "    df = df[[\"team\", \"power_rating\", \"Week\"]]\n",
    "    \n",
    "    # Append to all_data\n",
    "    all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "# Pivot the combined data\n",
    "pivot_df = all_data.pivot(index=\"team\", columns=\"Week\", values=\"power_rating\").reset_index()\n",
    "pivot_df.columns.name = None\n",
    "\n",
    "# Ensure column order with \"Team\" followed by weeks\n",
    "column_order = [\"Team\"] + [f\"Week {week}\" for week in week_list]\n",
    "\n",
    "# Ensure column order with \"Team\" followed by weeks\n",
    "column_order = [\"team\"] + [f\"Week {week}\" for week in week_list]\n",
    "year_long_ratings = pivot_df[column_order]\n",
    "top_25 = year_long_ratings.sort_values('Week 16', ascending=False)[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df = year_long_ratings.melt(id_vars=\"team\", var_name=\"Week\", value_name=\"Power Rating\")\n",
    "melted_df[\"Week Number\"] = melted_df[\"Week\"].str.extract(r\"(\\d+)\").astype(int)\n",
    "\n",
    "# Calculate rank within each week\n",
    "melted_df[\"Rank\"] = melted_df.groupby(\"Week Number\")[\"Power Rating\"].rank(ascending=False, method=\"first\")\n",
    "\n",
    "# Sort for plotting\n",
    "melted_df = melted_df.sort_values(by=[\"team\", \"Week Number\"])\n",
    "plt.figure(figsize=(28, 16))\n",
    "\n",
    "# Iterate over each team and plot their rank\n",
    "for team in melted_df[\"team\"].unique():\n",
    "    team_data = melted_df[melted_df[\"team\"] == team]\n",
    "    weeks = team_data[\"Week\"]\n",
    "    ratings = team_data[\"Power Rating\"]\n",
    "    plt.plot(weeks, ratings, marker='o', label=team)  # Line with dots\n",
    "\n",
    "    # Add a label for the team at the last week\n",
    "    last_week = weeks.iloc[-1]\n",
    "    last_rank = ratings.iloc[-1]\n",
    "    plt.annotate(team, (last_week, last_rank), textcoords=\"offset points\", xytext=(5, -5), fontsize=10)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Rank of Power Ratings Over Weeks for All Teams\", fontsize=16)\n",
    "plt.xlabel(\"Week\", fontsize=12)\n",
    "plt.ylabel(\"Rank (Lower is Better)\", fontsize=12)\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to make rank 1 at the top\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `pivot_df` is already created as above\n",
    "# pivot_df = pd.read_csv('your_final_csv.csv')\n",
    "\n",
    "# Melt the DataFrame to make it easier for plotting\n",
    "melted_df = year_long_ratings.melt(id_vars=\"team\", var_name=\"Week\", value_name=\"Power Rating\")\n",
    "melted_df[\"Week Number\"] = melted_df[\"Week\"].str.extract(r\"(\\d+)\").astype(int)\n",
    "\n",
    "# Calculate rank within each week\n",
    "melted_df[\"Rank\"] = melted_df.groupby(\"Week Number\")[\"Power Rating\"].rank(ascending=False, method=\"first\")\n",
    "\n",
    "# Sort for plotting\n",
    "melted_df = melted_df.sort_values(by=[\"team\", \"Week Number\"])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(28, 16))\n",
    "\n",
    "# Iterate over each team and plot their rank\n",
    "for team in melted_df[\"team\"].unique():\n",
    "    team_data = melted_df[melted_df[\"team\"] == team]\n",
    "    weeks = team_data[\"Week\"]\n",
    "    ranks = team_data[\"Rank\"]\n",
    "    plt.plot(weeks, ranks, marker='o', label=team)  # Line with dots\n",
    "\n",
    "    # Add a label for the team at the last week\n",
    "    last_week = weeks.iloc[-1]\n",
    "    last_rank = ranks.iloc[-1]\n",
    "    plt.annotate(team, (last_week, last_rank), textcoords=\"offset points\", xytext=(5, -5), fontsize=10)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Rank of Power Ratings Over Weeks for All Teams\", fontsize=16)\n",
    "plt.xlabel(\"Week\", fontsize=12)\n",
    "plt.ylabel(\"Rank (Lower is Better)\", fontsize=12)\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to make rank 1 at the top\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df = year_long_ratings.melt(id_vars=\"team\", var_name=\"Week\", value_name=\"Power Rating\")\n",
    "melted_df[\"Week Number\"] = melted_df[\"Week\"].str.extract(r\"(\\d+)\").astype(int)\n",
    "\n",
    "# Calculate rank within each week, ensuring no ties\n",
    "melted_df[\"Rank\"] = melted_df.groupby(\"Week Number\")[\"Power Rating\"].rank(ascending=False, method=\"first\")\n",
    "\n",
    "# Compute week-to-week rank change\n",
    "melted_df[\"Rank Change\"] = melted_df.groupby(\"team\")[\"Rank\"].diff().abs()\n",
    "\n",
    "# Identify teams with a rank change > 5 in any one-week span\n",
    "teams_to_plot = melted_df.loc[melted_df[\"Rank Change\"] > 20, \"team\"].unique()\n",
    "\n",
    "# Filter data to include only these teams\n",
    "filtered_df = melted_df[melted_df[\"team\"].isin(teams_to_plot)]\n",
    "\n",
    "# Sort for plotting\n",
    "filtered_df = filtered_df.sort_values(by=[\"team\", \"Week Number\"])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Iterate over the filtered teams and plot their rank\n",
    "for team in teams_to_plot:\n",
    "    team_data = filtered_df[filtered_df[\"team\"] == team]\n",
    "    weeks = team_data[\"Week\"]\n",
    "    ranks = team_data[\"Rank\"]\n",
    "    plt.plot(weeks, ranks, marker='o', label=team)  # Line with dots\n",
    "\n",
    "    # Add a label for the team at the last week\n",
    "    last_week = weeks.iloc[-1]\n",
    "    last_rank = ranks.iloc[-1]\n",
    "    plt.annotate(team, (last_week, last_rank), textcoords=\"offset points\", xytext=(5, -10), fontsize=10)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Rank of Power Ratings Over Weeks (Teams with Rank Change > 5)\", fontsize=16)\n",
    "plt.xlabel(\"Week\", fontsize=12)\n",
    "plt.ylabel(\"Rank (Lower is Better)\", fontsize=12)\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to make rank 1 at the top\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1), title=\"Teams\")  # Legend outside the plot\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excursions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimize HFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cfbd\n",
    "import statistics\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "week_list = [9,10,11,12,13,14,15,16]\n",
    "current_year = 2024\n",
    "all_team_data = pd.DataFrame()\n",
    "for week in week_list:\n",
    "    team_data = pd.read_csv(f'./ESCAPE Ratings/Ratings/y{current_year}/ESCAPE_week{week}.csv').drop(columns=['Unnamed: 0'])\n",
    "    all_team_data = pd.concat([all_team_data, team_data])\n",
    "configuration = cfbd.Configuration()\n",
    "configuration.api_key['Authorization'] = '7vGedNNOrnl0NGcSvt92FcVahY602p7IroVBlCA1Tt+WI/dCwtT7Gj5VzmaHrrxS'\n",
    "configuration.api_key_prefix['Authorization'] = 'Bearer'\n",
    "api_client = cfbd.ApiClient(configuration)\n",
    "advanced_instance = cfbd.StatsApi(api_client)\n",
    "games_api = cfbd.GamesApi(api_client)\n",
    "betting_api = cfbd.BettingApi(api_client)\n",
    "ratings_api = cfbd.RatingsApi(api_client)\n",
    "teams_api = cfbd.TeamsApi(api_client)\n",
    "metrics_api = cfbd.MetricsApi(api_client)\n",
    "players_api = cfbd.PlayersApi(api_client)\n",
    "recruiting_api = cfbd.RecruitingApi(api_client)\n",
    "def date_sort(game):\n",
    "    game_date = datetime.datetime.strptime(game['start_date'], \"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "    return game_date\n",
    "games = []\n",
    "for week in week_list:\n",
    "    response = games_api.get_games(year=current_year, week = week, division = 'fbs')\n",
    "    games = [*games, *response]\n",
    "games = [dict(\n",
    "            id=g.id,\n",
    "            season=g.season,\n",
    "            week=g.week,\n",
    "            start_date=g.start_date,\n",
    "            home_team=g.home_team,\n",
    "            home_conference=g.home_conference,\n",
    "            home_points=g.home_points,\n",
    "            home_elo=g.home_pregame_elo,\n",
    "            away_team=g.away_team,\n",
    "            away_conference=g.away_conference,\n",
    "            away_points=g.away_points,\n",
    "            away_elo=g.away_pregame_elo,\n",
    "            neutral=g.neutral_site\n",
    "            ) for g in games if g.home_pregame_elo is not None and g.away_pregame_elo is not None]\n",
    "games.sort(key=date_sort)\n",
    "games_info = pd.DataFrame(games)\n",
    "games_info = games_info.dropna(subset=['home_points'])\n",
    "\n",
    "betting = []\n",
    "for week in week_list:\n",
    "    response = betting_api.get_lines(year=current_year, week=week)\n",
    "    betting.extend(response)  # Use extend for list concatenation\n",
    "\n",
    "betting_info_list = []\n",
    "\n",
    "for bet in betting:\n",
    "    data = bet.to_dict() if hasattr(bet, 'to_dict') else vars(bet)\n",
    "    lines = pd.DataFrame(data['lines'])\n",
    "\n",
    "    if not lines.empty:\n",
    "        # Try to get consensus lines first\n",
    "        consensus_lines = lines[lines['provider'] == 'consensus']\n",
    "        \n",
    "        if consensus_lines.empty:\n",
    "            consensus_lines = lines[lines['provider'] == 'DraftKings']\n",
    "\n",
    "        if consensus_lines.empty:\n",
    "            consensus_lines = lines[lines['provider'] == 'Bovada']\n",
    "        \n",
    "        if consensus_lines.empty:\n",
    "            consensus_lines = lines[lines['provider'] == 'ESPN Bet']\n",
    "\n",
    "\n",
    "        if not consensus_lines.empty:\n",
    "            consensus_lines = consensus_lines[['spread', 'formatted_spread']]\n",
    "            combined_data = {\n",
    "                'id': data['id'],\n",
    "                'season_type': data['season_type'],\n",
    "            }\n",
    "            df = pd.DataFrame([combined_data])\n",
    "            full_df = pd.concat([df.reset_index(drop=True), consensus_lines.reset_index(drop=True)], axis=1)\n",
    "            betting_info_list.append(full_df)\n",
    "\n",
    "betting_info = pd.concat(betting_info_list, ignore_index=True)\n",
    "\n",
    "def round_to_nearest_half(x):\n",
    "    return np.round(x * 2) / 2\n",
    "def adjust_home_pr(home_win_prob):\n",
    "    return ((home_win_prob - 50) / 50) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_HFA = 100\n",
    "best_adjustment = -1\n",
    "best_percentage = 0\n",
    "\n",
    "HFA_list = np.arange(0, 10.1, 0.1).round(1).tolist()\n",
    "# HFA = 2.6\n",
    "adjustment_list = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "best_MAE = 100\n",
    "\n",
    "for HFA in HFA_list:\n",
    "    week_games = games_info.copy()\n",
    "    week_games = week_games.merge(\n",
    "        all_team_data[['team', 'power_rating', 'week']],\n",
    "        left_on=['home_team', 'week'],\n",
    "        right_on=['team', 'week'],\n",
    "        how='left'\n",
    "    ).rename(columns={'power_rating': 'home_pr'})\n",
    "    week_games = week_games.merge(\n",
    "        all_team_data[['team', 'power_rating', 'week']],\n",
    "        left_on=['away_team', 'week'],\n",
    "        right_on=['team', 'week'],\n",
    "        how='left'\n",
    "    ).rename(columns={'power_rating': 'away_pr'})\n",
    "    def adjust_home_pr(home_win_prob):\n",
    "        return ((home_win_prob - 50) / 50) * 5\n",
    "    week_games = week_games.drop(columns=['team_x', 'team_y'])\n",
    "    week_games['home_win_prob'] = round((10**((week_games['home_elo'] - week_games['away_elo']) / 400)) / ((10**((week_games['home_elo'] - week_games['away_elo']) / 400)) + 1)*100,2)\n",
    "    week_games['pr_spread'] = (HFA + week_games['home_pr'] + (week_games['home_win_prob'].apply(adjust_home_pr)) - week_games['away_pr']).round(1)\n",
    "    week_games['pr_spread'] = np.where(week_games['neutral'], week_games['pr_spread'] - HFA, week_games['pr_spread'])\n",
    "    # week_games['pr_spread'] = week_games['pr_spread'].apply(round_to_nearest_half)\n",
    "\n",
    "    week_games = pd.merge(week_games, betting_info, on='id', how='left')\n",
    "    week_games['spread'] = week_games['spread'] * -1\n",
    "\n",
    "    # Capping predictions that are more than 15 points away from the Vegas Spread\n",
    "    threshold = 10\n",
    "    capped_preds = np.clip(week_games['pr_spread'], week_games['spread'] - threshold, week_games['spread'] + threshold)\n",
    "    week_games['pr_spread'] = capped_preds\n",
    "\n",
    "    # Function to find out if PR predicts the favorite or underdog\n",
    "    def calculate_pr_prediction(row, pr_spread_col):\n",
    "        if (row['spread'] < 0) and (row[pr_spread_col] < 0) and (row[pr_spread_col] < row['spread']):\n",
    "            return 'Favorite'\n",
    "        elif (row['spread'] > 0) and (row[pr_spread_col] > 0) and (row[pr_spread_col] > row['spread']):\n",
    "            return 'Favorite'\n",
    "        elif (row['spread'] == row[pr_spread_col]):\n",
    "            return 'Exact'\n",
    "        else:\n",
    "            return 'Underdog'\n",
    "\n",
    "    # Use the above function\n",
    "    def add_pr_prediction(week_games, pr_spread_col, prediction_col_name='pr_prediction'):\n",
    "        week_games[prediction_col_name] = week_games.apply(calculate_pr_prediction, axis=1, args=(pr_spread_col,))\n",
    "        return week_games\n",
    "    week_games = add_pr_prediction(week_games, 'pr_spread', 'pr_prediction')\n",
    "\n",
    "    # Formatting the KRATOS Power Rating Spread\n",
    "    week_games['ESCAPE'] = week_games.apply(\n",
    "        lambda row: f\"{row['away_team']} {-abs(row['pr_spread'])}\" if ((row['pr_spread'] <= 0)) \n",
    "        else f\"{row['home_team']} {-abs(row['pr_spread'])}\", axis=1)\n",
    "    week_games['difference'] = abs(week_games['pr_spread'] - week_games['spread'])\n",
    "    week_games = week_games.sort_values(by=[\"difference\", \"home_win_prob\"], ascending=False).reset_index(drop=True)\n",
    "    week_games['actual_margin'] = week_games['home_points'] - week_games['away_points']\n",
    "    def calculate_margin_team(row):\n",
    "        if row['actual_margin'] > 0:\n",
    "            return f\"{row['home_team']} -{row['actual_margin']}\"  # If actual_margin is positive\n",
    "        elif row['actual_margin'] < 0:\n",
    "            return f\"{row['away_team']} {row['actual_margin']}\"  # If actual_margin is negative\n",
    "        else:\n",
    "            return ''\n",
    "    week_games['actual_spread'] = week_games.apply(calculate_margin_team, axis=1)\n",
    "    week_games = add_pr_prediction(week_games, 'actual_margin', 'ATS_result')\n",
    "    def check_prediction_correct(row, prediction_col):\n",
    "        if row['actual_spread'] == '':\n",
    "            return ''\n",
    "        if row[prediction_col] == row['ATS_result']:\n",
    "            return 1\n",
    "        elif 'Exact' in (row[prediction_col], row['ATS_result']):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    # Apply the check prediction function and store the result in a new column\n",
    "    week_games['ESCAPE ATS'] = week_games.apply(lambda row: check_prediction_correct(row, 'pr_prediction'), axis=1)\n",
    "\n",
    "    def check_straight_up(row, prediction_col):\n",
    "        if row['actual_spread'] == '':\n",
    "            return ''\n",
    "        if (row['actual_margin'] < 0) and (row[prediction_col] < 0):\n",
    "            return 1\n",
    "        elif (row['actual_margin'] > 0) and (row[prediction_col] > 0):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    week_games['ESCAPE SU'] = week_games.apply(lambda row: check_straight_up(row, 'pr_spread'), axis = 1)\n",
    "\n",
    "    game_completion_info = week_games[['home_team', 'away_team', 'difference', 'formatted_spread', 'ESCAPE', 'actual_spread', 'actual_margin', 'pr_spread', 'ESCAPE ATS', 'ESCAPE SU']]\n",
    "    MAE = round(abs(game_completion_info['actual_margin'] - game_completion_info['pr_spread']).mean(),2)\n",
    "    game_completion_info = game_completion_info[game_completion_info['difference'] != 0.0]\n",
    "    game_completion_info = game_completion_info[game_completion_info['pr_spread'] != game_completion_info['actual_margin']]\n",
    "    correct_percentage = sum(game_completion_info['ESCAPE ATS']) / len(game_completion_info)\n",
    "    if correct_percentage > best_percentage:\n",
    "        best_sum = sum(game_completion_info['ESCAPE ATS'])\n",
    "        best_len = len(game_completion_info)\n",
    "        best_percentage = correct_percentage\n",
    "        best_HFA = HFA\n",
    "        best_MAE = MAE\n",
    "\n",
    "    # if MAE < best_MAE:\n",
    "    #     best_sum = sum(game_completion_info['ESCAPE ATS'])\n",
    "    #     best_len = len(game_completion_info)\n",
    "    #     best_percentage = correct_percentage\n",
    "    #     best_HFA = HFA\n",
    "    #     best_MAE = MAE\n",
    "print(best_percentage)\n",
    "print(best_HFA)\n",
    "print(best_MAE)\n",
    "print(best_sum, best_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated Expected Winnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statistics\n",
    "from scipy.stats import norm\n",
    "\n",
    "def simulate_bets_with_known_outcomes(initial_balance, bet_amount, odds, win_probability, num_bets, known_correct_bets, known_total_bets):\n",
    "    balance = initial_balance\n",
    "    correct_bets = known_correct_bets  # Start with known correct bets\n",
    "\n",
    "    # Simulate the known outcomes first\n",
    "    for _ in range(known_correct_bets):\n",
    "        balance += bet_amount * (odds / bet_amount)  # Win\n",
    "    \n",
    "    for _ in range(known_total_bets - known_correct_bets):\n",
    "        balance -= bet_amount  # Loss\n",
    "    \n",
    "    # Simulate the remaining bets\n",
    "    remaining_bets = num_bets - known_total_bets\n",
    "    for _ in range(remaining_bets):\n",
    "        if np.random.rand() < win_probability:\n",
    "            balance += bet_amount * (odds / bet_amount)  # Win\n",
    "            correct_bets += 1  # Increment correct bet count\n",
    "        else:\n",
    "            balance -= bet_amount  # Loss\n",
    "    \n",
    "    # Return final balance and percentage of correct bets\n",
    "    return balance, correct_bets / num_bets * 100\n",
    "\n",
    "def run_simulations_with_known_outcomes(num_simulations, initial_balance, bet_amount, odds, win_probability, num_bets, known_correct_bets, known_total_bets):\n",
    "    num_profitable_simulations = 0\n",
    "    balance_list = []\n",
    "    correct_bet_percentages = []\n",
    "    \n",
    "    for _ in range(num_simulations):\n",
    "        final_balance, correct_bet_percentage = simulate_bets_with_known_outcomes(initial_balance, bet_amount, odds, win_probability, num_bets, known_correct_bets, known_total_bets)\n",
    "        balance_list.append(final_balance)\n",
    "        correct_bet_percentages.append(correct_bet_percentage)\n",
    "        if final_balance > initial_balance:\n",
    "            num_profitable_simulations += 1\n",
    "    \n",
    "    proportion_profitable = num_profitable_simulations / num_simulations\n",
    "    return proportion_profitable * 100, balance_list, correct_bet_percentages\n",
    "\n",
    "# Parameters\n",
    "initial_balance = 0         # Starting balance\n",
    "bet_amount = 1              # Amount bet per game\n",
    "odds = .9                   # Profit from a win (at -110 odds)\n",
    "win_probability = 0.649    # Probability of winning\n",
    "num_bets = 70              # Number of bets to simulate\n",
    "num_simulations = 100000    # Number of simulations to run\n",
    "known_correct_bets = 24      # Known correct bets\n",
    "known_total_bets = 37        # Total number of bets known\n",
    "\n",
    "# Run simulations and calculate percentage of profitable outcomes and correct bet percentages\n",
    "percentage_profitable, balance_list, correct_bet_percentages = run_simulations_with_known_outcomes(num_simulations, initial_balance, bet_amount, odds, win_probability, num_bets, known_correct_bets, known_total_bets)\n",
    "lower_correct = np.percentile(correct_bet_percentages, 2.5)\n",
    "upper_correct = np.percentile(correct_bet_percentages, 97.5)\n",
    "\n",
    "# Output results\n",
    "print(f'Percentage of time making money after {num_bets} bets: {round(percentage_profitable, 2)}%')\n",
    "print(f'95% Confidence Interval for Percentage Correct: ({round(lower_correct, 2)}%, {round(upper_correct, 2)}%)')\n",
    "print(f'95% Confidence Interval for Balance (in units): ({round(np.percentile(balance_list, 2.5), 2)}u, {round(np.percentile(balance_list, 97.5), 2)}u)')\n",
    "print(f'Mean Balance: {round(statistics.mean(balance_list),2)}u \\nStandard Deviation: {round(statistics.stdev(balance_list),2)}u')\n",
    "print(f\"ROI: {round(100 * statistics.mean(balance_list) / (bet_amount*num_bets),2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Winnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_amount = 1\n",
    "odds = .9\n",
    "correct_bets = 69\n",
    "total_bets = 108\n",
    "\n",
    "winnings = (bet_amount*correct_bets) * (odds/bet_amount)\n",
    "losings = (total_bets-correct_bets) * bet_amount\n",
    "balance = winnings - losings\n",
    "print(f'Winnings: {round(balance,2)}u')\n",
    "print(f'Total Risked: {bet_amount*total_bets}u')\n",
    "print(f'ROI: {round(100*balance/(bet_amount*total_bets),1)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conference Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "team_data = pd.read_csv(\"./ESCAPE Ratings/ESCAPE_week17_2024.csv\")\n",
    "conference_stats = team_data.groupby('conference')['power_rating'].agg(['mean', 'min', 'max']).reset_index()\n",
    "conference_stats = conference_stats.sort_values(by='mean', ascending=False)\n",
    "conference_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Interval of Known ATS Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "x = 193\n",
    "n = 338\n",
    "p = x / n\n",
    "z = 1.96\n",
    "me = z * math.sqrt((p*(1-p))/n)\n",
    "lower = round(100*(p - me),1)\n",
    "upper = round(100*(p + me),1)\n",
    "print(f\"ATS: {round(100*p,1)}%\")\n",
    "print(f\"95% Confidence Interval: [{lower}%, {upper}%]\")\n",
    "\n",
    "std_error = np.sqrt((p * (1 - p)) / n)\n",
    "x = np.linspace(0, 1, 1000)\n",
    "pdf = norm.pdf(x, loc=p, scale=std_error)\n",
    "mean_samples = round(100*np.random.normal(loc=p, scale=std_error, size=100).mean(),1)\n",
    "print(f\"Sampled Percentage: {mean_samples}%\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, pdf, label=\"Normal Approximation\", color='blue')\n",
    "plt.axvline(p, color='red', linestyle='--', label=f'Sample Proportion {round(p,3)}')\n",
    "plt.axvline(p - z * std_error, color='green', linestyle='--', label=f'Lower Bound {round(lower/100,3)}')\n",
    "plt.axvline(p + z * std_error, color='green', linestyle='--', label=f'Upper Bound {round(upper/100,3)}')\n",
    "plt.title(\"Distribution Around the Proportion\")\n",
    "plt.xlabel(\"Proportion\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.xlim(p-.15, p+.15)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing automatic week grabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cfbd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "configuration = cfbd.Configuration()\n",
    "configuration.api_key['Authorization'] = '7vGedNNOrnl0NGcSvt92FcVahY602p7IroVBlCA1Tt+WI/dCwtT7Gj5VzmaHrrxS'\n",
    "configuration.api_key_prefix['Authorization'] = 'Bearer'\n",
    "api_client = cfbd.ApiClient(configuration)\n",
    "\n",
    "advanced_instance = cfbd.StatsApi(api_client)\n",
    "\n",
    "games_api = cfbd.GamesApi(api_client)\n",
    "\n",
    "betting_api = cfbd.BettingApi(api_client)\n",
    "\n",
    "ratings_api = cfbd.RatingsApi(api_client)\n",
    "\n",
    "teams_api = cfbd.TeamsApi(api_client)\n",
    "\n",
    "metrics_api = cfbd.MetricsApi(api_client)\n",
    "\n",
    "players_api = cfbd.PlayersApi(api_client)\n",
    "\n",
    "recruiting_api = cfbd.RecruitingApi(api_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_start_list = [*games_api.get_calendar(year = 2024)]\n",
    "calendar_dict = [dict(\n",
    "    first_game_start = c.first_game_start,\n",
    "    last_game_start = c.last_game_start,\n",
    "    season = c.season,\n",
    "    season_type = c.season_type,\n",
    "    week = c.week\n",
    ") for c in week_start_list]\n",
    "calendar = pd.DataFrame(calendar_dict)\n",
    "calendar['first_game_start'] = pd.to_datetime(calendar['first_game_start'])\n",
    "calendar['last_game_start'] = pd.to_datetime(calendar['last_game_start'])\n",
    "current_year = int(calendar.loc[0, 'season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "current_time = datetime.now(pytz.UTC)\n",
    "first_game_start = calendar['first_game_start'].iloc[0]\n",
    "last_game_start = calendar['last_game_start'].iloc[-1]\n",
    "current_week = None\n",
    "if current_time < first_game_start:\n",
    "    current_week = 1\n",
    "elif current_time > last_game_start:\n",
    "    current_week = calendar.iloc[-2, -1] + 1\n",
    "else:\n",
    "    condition_1 = (calendar['first_game_start'] <= current_time) & (calendar['last_game_start'] >= current_time)\n",
    "    condition_2 = (calendar['last_game_start'].shift(1) < current_time) & (calendar['first_game_start'] > current_time)\n",
    "\n",
    "    # Combine conditions\n",
    "    result = calendar[condition_1 | condition_2].reset_index(drop=True)\n",
    "    if result['season_type'][0] == 'regular':\n",
    "        current_week = result['week'][0]\n",
    "        postseason = False\n",
    "    else:\n",
    "        current_week = calendar.iloc[-2, -1] + 1\n",
    "        postseason = True\n",
    "    print(result)\n",
    "\n",
    "print(current_week, current_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Season Win Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import result\n",
    "import pandas as pd\n",
    "import cfbd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import ImageGrab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from base64 import b64decode\n",
    "from io import BytesIO\n",
    "from IPython import get_ipython\n",
    "from IPython.core.magic import register_cell_magic\n",
    "import PIL\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from matplotlib.lines import Line2D\n",
    "import cfbd\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from matplotlib import gridspec\n",
    "import datetime\n",
    "np.random.seed(42)\n",
    "configuration = cfbd.Configuration()\n",
    "configuration.api_key['Authorization'] = '7vGedNNOrnl0NGcSvt92FcVahY602p7IroVBlCA1Tt+WI/dCwtT7Gj5VzmaHrrxS'\n",
    "configuration.api_key_prefix['Authorization'] = 'Bearer'\n",
    "api_client = cfbd.ApiClient(configuration)\n",
    "advanced_instance = cfbd.StatsApi(api_client)\n",
    "games_api = cfbd.GamesApi(api_client)\n",
    "betting_api = cfbd.BettingApi(api_client)\n",
    "ratings_api = cfbd.RatingsApi(api_client)\n",
    "teams_api = cfbd.TeamsApi(api_client)\n",
    "metrics_api = cfbd.MetricsApi(api_client)\n",
    "players_api = cfbd.PlayersApi(api_client)\n",
    "recruiting_api = cfbd.RecruitingApi(api_client)\n",
    "\n",
    "week_start_list = [*games_api.get_calendar(year = 2024)]\n",
    "calendar_dict = [dict(\n",
    "    first_game_start = c.first_game_start,\n",
    "    last_game_start = c.last_game_start,\n",
    "    season = c.season,\n",
    "    season_type = c.season_type,\n",
    "    week = c.week\n",
    ") for c in week_start_list]\n",
    "calendar = pd.DataFrame(calendar_dict)\n",
    "calendar['first_game_start'] = pd.to_datetime(calendar['first_game_start'])\n",
    "calendar['last_game_start'] = pd.to_datetime(calendar['last_game_start'])\n",
    "current_year = int(calendar.loc[0, 'season'])\n",
    "\n",
    "import pytz\n",
    "\n",
    "current_time = datetime.datetime.now(pytz.UTC)\n",
    "first_game_start = calendar['first_game_start'].iloc[0]\n",
    "last_game_start = calendar['last_game_start'].iloc[-1]\n",
    "current_week = None\n",
    "if current_time < first_game_start:\n",
    "    current_week = 1\n",
    "elif current_time > last_game_start:\n",
    "    current_week = calendar.iloc[-2, -1] + 1\n",
    "else:\n",
    "    condition_1 = (calendar['first_game_start'] <= current_time) & (calendar['last_game_start'] >= current_time)\n",
    "    condition_2 = (calendar['last_game_start'].shift(1) < current_time) & (calendar['first_game_start'] > current_time)\n",
    "\n",
    "    # Combine conditions\n",
    "    result = calendar[condition_1 | condition_2].reset_index(drop=True)\n",
    "    if result['season_type'][0] == 'regular':\n",
    "        current_week = result['week'][0]\n",
    "        postseason = False\n",
    "    else:\n",
    "        current_week = calendar.iloc[-2, -1] + 1\n",
    "        postseason = True\n",
    "\n",
    "current_week = int(current_week)\n",
    "current_year = int(current_year)\n",
    "print(current_week, current_year)\n",
    "\n",
    "logos_info_list = []\n",
    "response = teams_api.get_teams()\n",
    "logos_info_list = [*logos_info_list, *response]\n",
    "logos_info_dict = [dict(\n",
    "    team = l.school,\n",
    "    color = l.color,\n",
    "    alt_color = l.alt_color,\n",
    "    logo = l.logos\n",
    ") for l in logos_info_list]\n",
    "logos = pd.DataFrame(logos_info_dict)\n",
    "logos = logos.dropna(subset=['logo', 'color'])\n",
    "\n",
    "records_list = []\n",
    "response = games_api.get_team_records(year=current_year)\n",
    "records_list = [*records_list, *response]\n",
    "records_dict = [dict(\n",
    "    team = r.team,\n",
    "    games_played = r.total.games,\n",
    "    wins = r.total.wins,\n",
    "    losses = r.total.losses,\n",
    "    conference_games = r.conference_games.games,\n",
    "    conference_wins = r.conference_games.wins,\n",
    "    conference_losses = r.conference_games.losses\n",
    ") for r in records_list]\n",
    "records = pd.DataFrame(records_dict)\n",
    "records.at[records[records['team'] == 'Kansas State'].index[0], 'conference_wins'] -= 1\n",
    "records.at[records[records['team'] == 'Utah'].index[0], 'conference_wins'] -= 1\n",
    "records.at[records[records['team'] == 'Baylor'].index[0], 'conference_losses'] -= 1\n",
    "records.at[records[records['team'] == 'Arizona'].index[0], 'conference_losses'] -= 1\n",
    "\n",
    "team_data = pd.read_csv(f'./ESCAPE Ratings/Ratings/y{current_year}/ESCAPE_week{current_week}.csv')\n",
    "\n",
    "def date_sort(game):\n",
    "    game_date = datetime.datetime.strptime(game['start_date'], \"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "    return game_date\n",
    "\n",
    "def ESCAPE_Win_Prob(home_power_rating, away_power_rating):\n",
    "    return round((1 / (1 + 10 ** ((away_power_rating - (home_power_rating)) / 20.5))) * 100, 2)\n",
    "\n",
    "def round_to_nearest_half(x):\n",
    "    return np.round(x * 2) / 2\n",
    " \n",
    "start_week = 1\n",
    "end_week = 17\n",
    "\n",
    "games_list = []\n",
    "for week in range(start_week,end_week):\n",
    "    response = games_api.get_games(year=current_year, week=week,division = 'fbs')\n",
    "    games_list = [*games_list, *response]\n",
    "games = [dict(\n",
    "            id=g.id,\n",
    "            season=g.season,\n",
    "            week=g.week,\n",
    "            start_date=g.start_date,\n",
    "            home_team=g.home_team,\n",
    "            home_elo=g.home_pregame_elo,\n",
    "            away_team=g.away_team,\n",
    "            away_elo=g.away_pregame_elo,\n",
    "            home_points = g.home_points,\n",
    "            away_points = g.away_points,\n",
    "            neutral = g.neutral_site\n",
    "            ) for g in games_list if g.home_pregame_elo is not None and g.away_pregame_elo is not None]\n",
    "games.sort(key=date_sort)\n",
    "year_long_schedule = pd.DataFrame(games)\n",
    "\n",
    "year_long_schedule = year_long_schedule.merge(team_data[['team', 'power_rating']], \n",
    "                                    left_on='home_team', \n",
    "                                    right_on='team', \n",
    "                                    how='left').rename(columns={'power_rating': 'home_pr'})\n",
    "year_long_schedule = year_long_schedule.drop(columns=['team'])\n",
    "year_long_schedule = year_long_schedule.merge(team_data[['team', 'power_rating']], \n",
    "                                    left_on='away_team', \n",
    "                                    right_on='team', \n",
    "                                    how='left').rename(columns={'power_rating': 'away_pr'})\n",
    "year_long_schedule = year_long_schedule.drop(columns=['team'])\n",
    "\n",
    "# Apply the ESCAPE_Win_Prob function to the schedule_info DataFrame\n",
    "year_long_schedule['escape_win_prob'] = year_long_schedule.apply(\n",
    "    lambda row: ESCAPE_Win_Prob(row['home_pr'], row['away_pr']), axis=1\n",
    ")\n",
    "\n",
    "year_long_schedule['home_win_prob'] = round((10**((year_long_schedule['home_elo'] - year_long_schedule['away_elo']) / 400)) / ((10**((year_long_schedule['home_elo'] - year_long_schedule['away_elo']) / 400)) + 1)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "power_ratings = team_data.set_index('team')['power_rating'].to_dict()\n",
    "# Function to calculate pre-season win totals with simulations\n",
    "def calculate_preseason_win_totals_simulations(schedule, power_ratings):\n",
    "    # Initialize win totals for this simulation\n",
    "    simulated_wins = {team: 0.0 for team in power_ratings.keys()}\n",
    "    games_played = {team: 0 for team in power_ratings.keys()}\n",
    "    \n",
    "    for _, game in schedule.iterrows():\n",
    "        home_team = game['home_team']\n",
    "        away_team = game['away_team']\n",
    "        \n",
    "        # Increment the number of games played\n",
    "        games_played[home_team] += 1\n",
    "        games_played[away_team] += 1\n",
    "        \n",
    "        # Calculate win probabilities\n",
    "        home_win_prob = ESCAPE_Win_Prob(power_ratings[home_team], power_ratings[away_team]) / 100\n",
    "        away_win_prob = 1 - home_win_prob\n",
    "        simulated_wins[home_team] += home_win_prob\n",
    "        simulated_wins[away_team] += away_win_prob\n",
    "    \n",
    "    # Add 0.95 wins for every game under 12\n",
    "    for team, games in games_played.items():\n",
    "        if games < 12:\n",
    "            simulated_wins[team] += 0.95 * (12 - games)\n",
    "    \n",
    "    return simulated_wins\n",
    "\n",
    "# Example usage\n",
    "preseason_win_totals = calculate_preseason_win_totals_simulations(year_long_schedule, power_ratings)\n",
    "preseason_win_totals = {team: round_to_nearest_half(wins) for team, wins in preseason_win_totals.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does ESCAPE Win Probability Correlate to Actual Win Probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cfbd\n",
    "import statistics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score, brier_score_loss, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "configuration = cfbd.Configuration()\n",
    "configuration.api_key['Authorization'] = '7vGedNNOrnl0NGcSvt92FcVahY602p7IroVBlCA1Tt+WI/dCwtT7Gj5VzmaHrrxS'\n",
    "configuration.api_key_prefix['Authorization'] = 'Bearer'\n",
    "api_client = cfbd.ApiClient(configuration)\n",
    "advanced_instance = cfbd.StatsApi(api_client)\n",
    "games_api = cfbd.GamesApi(api_client)\n",
    "betting_api = cfbd.BettingApi(api_client)\n",
    "ratings_api = cfbd.RatingsApi(api_client)\n",
    "teams_api = cfbd.TeamsApi(api_client)\n",
    "metrics_api = cfbd.MetricsApi(api_client)\n",
    "players_api = cfbd.PlayersApi(api_client)\n",
    "recruiting_api = cfbd.RecruitingApi(api_client)\n",
    "\n",
    "week_start_list = [*games_api.get_calendar(year = 2024)]\n",
    "calendar_dict = [dict(\n",
    "    first_game_start = c.first_game_start,\n",
    "    last_game_start = c.last_game_start,\n",
    "    season = c.season,\n",
    "    season_type = c.season_type,\n",
    "    week = c.week\n",
    ") for c in week_start_list]\n",
    "calendar = pd.DataFrame(calendar_dict)\n",
    "calendar['first_game_start'] = pd.to_datetime(calendar['first_game_start'])\n",
    "calendar['last_game_start'] = pd.to_datetime(calendar['last_game_start'])\n",
    "current_year = int(calendar.loc[0, 'season'])\n",
    "\n",
    "import pytz\n",
    "\n",
    "current_time = datetime.datetime.now(pytz.UTC)\n",
    "first_game_start = calendar['first_game_start'].iloc[0]\n",
    "last_game_start = calendar['last_game_start'].iloc[-1]\n",
    "current_week = None\n",
    "if current_time < first_game_start:\n",
    "    current_week = 1\n",
    "elif current_time > last_game_start:\n",
    "    current_week = calendar.iloc[-2, -1] + 1\n",
    "else:\n",
    "    condition_1 = (calendar['first_game_start'] <= current_time) & (calendar['last_game_start'] >= current_time)\n",
    "    condition_2 = (calendar['last_game_start'].shift(1) < current_time) & (calendar['first_game_start'] > current_time)\n",
    "\n",
    "    # Combine conditions\n",
    "    result = calendar[condition_1 | condition_2].reset_index(drop=True)\n",
    "    if result['season_type'][0] == 'regular':\n",
    "        current_week = result['week'][0]\n",
    "        postseason = False\n",
    "    else:\n",
    "        current_week = calendar.iloc[-2, -1] + 1\n",
    "        postseason = True\n",
    "\n",
    "current_week = int(current_week)\n",
    "current_year = int(current_year)\n",
    "\n",
    "def ESCAPE_Win_Prob(home_power_rating, away_power_rating):\n",
    "    return round((1 / (1 + 10 ** ((away_power_rating - (home_power_rating)) / 20.5))) * 100, 2)\n",
    "\n",
    "def date_sort(game):\n",
    "    game_date = datetime.datetime.strptime(game['start_date'], \"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "    return game_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_list = [9,10,11,12,13,14,15,16]\n",
    "all_week_games = pd.DataFrame()\n",
    "for week in week_list:\n",
    "    team_data = pd.read_csv(f'./ESCAPE Ratings/Ratings/y{current_year}/ESCAPE_week{week}.csv').drop(columns=['Unnamed: 0'])\n",
    "    games = []\n",
    "    response = games_api.get_games(year=current_year, week = week, division = 'fbs')\n",
    "    games = [*games, *response]\n",
    "    games = [dict(\n",
    "                id=g.id,\n",
    "                season=g.season,\n",
    "                week=g.week,\n",
    "                start_date=g.start_date,\n",
    "                home_team=g.home_team,\n",
    "                home_conference=g.home_conference,\n",
    "                home_points=g.home_points,\n",
    "                home_elo=g.home_pregame_elo,\n",
    "                away_team=g.away_team,\n",
    "                away_conference=g.away_conference,\n",
    "                away_points=g.away_points,\n",
    "                away_elo=g.away_pregame_elo,\n",
    "                neutral = g.neutral_site\n",
    "                ) for g in games if g.home_pregame_elo is not None and g.away_pregame_elo is not None]\n",
    "    games.sort(key=date_sort)\n",
    "    week_games = pd.DataFrame(games)\n",
    "    if week == 5:\n",
    "        week_games = week_games.dropna()\n",
    "    week_games.loc[week_games['home_team'] == \"Florida International\", 'neutral'] = False\n",
    "    import numpy as np\n",
    "    import math\n",
    "    def round_to_nearest_half(x):\n",
    "        return np.round(x * 2) / 2\n",
    "    week_games = week_games.merge(\n",
    "        team_data[['team', 'power_rating']],\n",
    "        left_on='home_team',\n",
    "        right_on='team',\n",
    "        how='left'\n",
    "    ).rename(columns={'power_rating': 'home_pr'})\n",
    "    week_games = week_games.merge(\n",
    "        team_data[['team', 'power_rating']],\n",
    "        left_on='away_team',\n",
    "        right_on='team',\n",
    "        how='left'\n",
    "    ).rename(columns={'power_rating': 'away_pr'})\n",
    "    week_games = week_games.drop(columns=['team_x', 'team_y'])\n",
    "\n",
    "    week_games['ESCAPE_win_prob'] = ESCAPE_Win_Prob(week_games['home_pr'], week_games['away_pr'])\n",
    "    all_week_games = pd.concat([all_week_games, week_games])\n",
    "    all_week_games = all_week_games.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_week_games['margin'] = all_week_games['home_points'] - all_week_games['away_points']\n",
    "all_week_games['actual_winner'] = (all_week_games['margin'] > 0).astype(int)\n",
    "all_week_games['predicted_winner'] = (all_week_games['ESCAPE_win_prob'] > 50).astype(int)\n",
    "binary_accuracy = accuracy_score(all_week_games['actual_winner'], all_week_games['predicted_winner'])\n",
    "brier_score = brier_score_loss(all_week_games['actual_winner'], all_week_games['ESCAPE_win_prob'] / 100)\n",
    "log_loss_value = log_loss(all_week_games['actual_winner'], all_week_games['ESCAPE_win_prob'] / 100)\n",
    "print(f\"Binary Accuracy: {binary_accuracy:.2f}\")\n",
    "print(f\"Brier Score: {brier_score:.4f}\")\n",
    "print(f\"Log Loss: {log_loss_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Compute calibration curve\n",
    "prob_true, prob_pred = calibration_curve(all_week_games['actual_winner'], \n",
    "                                         all_week_games['ESCAPE_win_prob'] / 100, \n",
    "                                         n_bins=10)\n",
    "\n",
    "# Plot calibration curve\n",
    "plt.plot(prob_pred, prob_true, marker='o', label=\"Calibration Curve\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label=\"Perfect Calibration\")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Actual Win Rate\")\n",
    "plt.legend()\n",
    "plt.title(\"Calibration Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### across year rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file with invalid week number: team_data_week17_no_adjustments.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the main folder path\n",
    "main_folder = \"./ESCAPE Ratings/Data\"\n",
    "\n",
    "# Initialize a list to store data from the selected files\n",
    "combined_data = []\n",
    "\n",
    "for year_folder in os.listdir(main_folder):\n",
    "    if year_folder != 'y2013':\n",
    "        year_path = os.path.join(main_folder, year_folder)\n",
    "        if os.path.isdir(year_path) and year_folder.startswith(\"y\"):  # Check if it's a year folder\n",
    "            max_week = -1\n",
    "            max_week_file = None\n",
    "            \n",
    "            # Find the file with the highest week value\n",
    "            for file in os.listdir(year_path):\n",
    "                if file.startswith(\"team_data_week\") and file.endswith(\".csv\"):\n",
    "                    try:\n",
    "                        # Safely extract the week number\n",
    "                        week_number = int(file.split(\"team_data_week\")[1].split(\".csv\")[0])\n",
    "                        if week_number > max_week:\n",
    "                            max_week = week_number\n",
    "                            max_week_file = os.path.join(year_path, file)\n",
    "                    except ValueError:\n",
    "                        # Skip files with invalid week numbers\n",
    "                        print(f\"Skipping file with invalid week number: {file}\")\n",
    "            \n",
    "            # Read the file with the highest week value\n",
    "            if max_week_file:\n",
    "                try:\n",
    "                    data = pd.read_csv(max_week_file)\n",
    "                    combined_data.append(data)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to read file {max_week_file}: {e}\")\n",
    "\n",
    "# Combine all selected data into a single DataFrame\n",
    "combined_dataset = pd.concat(combined_data, ignore_index=True)\n",
    "combined_dataset = combined_dataset.sort_values('power_rating', ascending=False).reset_index(drop=True).drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# # Perform z-score normalization grouped by \"season\"\n",
    "# combined_dataset['norm_power_rank'] = combined_dataset.groupby('season')['power_ranking'].transform(\n",
    "#     lambda x: (x - x.mean()) / x.std()\n",
    "# )\n",
    "# combined_dataset = combined_dataset.sort_values('norm_power_rank', ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# combined_dataset['norm_pr'] = combined_dataset['norm_power_rank'] - combined_dataset['norm_power_rank'].mean()\n",
    "# current_range = combined_dataset['norm_pr'].max() - combined_dataset['norm_pr'].min()\n",
    "# desired_range = 55  # The target range\n",
    "# scaling_factor = desired_range / current_range\n",
    "# combined_dataset['norm_pr'] = round(combined_dataset['norm_pr'] * scaling_factor,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power_ratings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
