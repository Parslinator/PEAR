{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def PEAR_Win_Prob(home_pr, away_pr):\n",
    "    rating_diff = home_pr - away_pr\n",
    "    win_prob = round(1 / (1 + 10 ** (-rating_diff / 10)) * 100, 2)\n",
    "    return win_prob\n",
    "\n",
    "# Base URL for NCAA stats\n",
    "base_url = \"https://www.ncaa.com\"\n",
    "stats_page = f\"{base_url}/stats/baseball/d1\"\n",
    "\n",
    "# Function to get page content\n",
    "def get_soup(url):\n",
    "    response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    response.raise_for_status()  # Ensure request was successful\n",
    "    return BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Get main page content\n",
    "soup = get_soup(stats_page)\n",
    "\n",
    "# Find the dropdown container and extract stat URLs\n",
    "dropdown = soup.find(\"select\", {\"id\": \"select-container-team\"})\n",
    "options = dropdown.find_all(\"option\")\n",
    "\n",
    "# Extract stat names and links\n",
    "stat_links = {\n",
    "    option.text.strip(): base_url + option[\"value\"]\n",
    "    for option in options if option.get(\"value\")\n",
    "}\n",
    "\n",
    "url = \"https://www.ncaa.com/rankings/baseball/d1/rpi\"\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Ensure request was successful\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "table = soup.find(\"table\", class_=\"sticky\")\n",
    "if table:\n",
    "    headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "    data = []\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "        cols = row.find_all(\"td\")\n",
    "        data.append([col.text.strip() for col in cols])\n",
    "    rpi = pd.DataFrame(data, columns=headers)\n",
    "    rpi = rpi.drop(columns = ['Previous'])\n",
    "    rpi.rename(columns={\"School\": \"Team\"}, inplace=True)\n",
    "else:\n",
    "    print(\"Table not found.\")\n",
    "\n",
    "url = \"https://www.collegebaseballratings.com/\"\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Raise an error for failed requests\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "table = soup.find(\"table\", {\"id\": \"teamList\"})\n",
    "headers = [th.text.strip() for th in table.find(\"thead\").find_all(\"th\")]\n",
    "data = []\n",
    "for row in table.find(\"tbody\").find_all(\"tr\"):\n",
    "    cells = [td.text.strip() for td in row.find_all(\"td\")]\n",
    "    data.append(cells)\n",
    "cbr = pd.DataFrame(data, columns=headers[1:])\n",
    "cbr.rename(columns={\"Rank\":\"CBRank\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batting Average Done\n",
      "Base on Balls Done\n",
      "Double Plays Per Game Done\n",
      "Earned Run Average Done\n",
      "Fielding Percentage Done\n",
      "Hits Allowed Per Nine Innings Done\n",
      "Home Runs Per Game Done\n",
      "On Base Percentage Done\n",
      "Runs Done\n",
      "Sacrifice Bunts Done\n",
      "Sacrifice Flies Done\n",
      "Slugging Percentage Done\n",
      "Stolen Bases Done\n",
      "Strikeout-to-Walk Ratio Done\n",
      "Strikeouts Per Nine Innings Done\n",
      "Walks Allowed Per Nine Innings Done\n",
      "WHIP Done\n"
     ]
    }
   ],
   "source": [
    "def get_stat_dataframe(stat_name):\n",
    "    \"\"\"Fetches the specified stat table from multiple pages and returns a combined DataFrame,\n",
    "    keeps 'Team' as string, and converts all other columns to float.\"\"\"\n",
    "    \n",
    "    if stat_name not in stat_links:\n",
    "        print(f\"Stat '{stat_name}' not found. Available stats: {list(stat_links.keys())}\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize the DataFrame to store all pages' data\n",
    "    all_data = []\n",
    "    page_num = 1  # Start from the first page\n",
    "\n",
    "    while True:\n",
    "        url = stat_links[stat_name]\n",
    "        if page_num > 1:\n",
    "            # Modify the URL to include the page number\n",
    "            url = f\"{url}/p{page_num}\"\n",
    "        \n",
    "        # print(f\"Fetching data for: {stat_name} (Page {page_num} - {url})\")\n",
    "\n",
    "        try:\n",
    "            # Get stats page content\n",
    "            soup = get_soup(url)\n",
    "\n",
    "            # Locate table\n",
    "            table = soup.find(\"table\")\n",
    "            if not table:\n",
    "                print(f\"No table found for {stat_name} on page {page_num}\")\n",
    "                break  # Exit the loop if no table is found (end of valid pages)\n",
    "\n",
    "            # Extract table headers\n",
    "            headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "\n",
    "            # Extract table rows\n",
    "            data = []\n",
    "            for row in table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "                cols = row.find_all(\"td\")\n",
    "                data.append([col.text.strip() for col in cols])\n",
    "\n",
    "            all_data.extend(data)  # Add the data from this page to the list of all data\n",
    "        \n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(f\"{stat_name} Done\")\n",
    "            break  # Exit the loop on HTTPError (page doesn't exist)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break  # Exit the loop on any other error\n",
    "\n",
    "        page_num += 1  # Go to the next page\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data, columns=headers)\n",
    "\n",
    "        # Convert all columns to float except \"Team\"\n",
    "        for col in df.columns:\n",
    "            if col != \"Team\":\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\")  # Converts to float, invalid values become NaN\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No data collected.\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "stat_name_input = \"Batting Average\"  # Change this to the desired stat\n",
    "ba = get_stat_dataframe(stat_name_input)\n",
    "ba[\"HPG\"] = ba[\"H\"] / ba[\"G\"]\n",
    "ba[\"ABPG\"] = ba[\"AB\"] / ba[\"G\"]\n",
    "ba[\"HPAB\"] = ba[\"H\"] / ba[\"AB\"]\n",
    "ba = ba.drop(columns=['Rank'])\n",
    "\n",
    "stat_name_input = \"Base on Balls\"\n",
    "bb = get_stat_dataframe(stat_name_input)\n",
    "bb[\"BBPG\"] = bb[\"BB\"] / bb[\"G\"]\n",
    "bb = bb.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Double Plays Per Game\"\n",
    "dp = get_stat_dataframe(stat_name_input)\n",
    "dp.rename(columns={\"PG\": \"DPPG\"}, inplace=True)\n",
    "dp = dp.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Earned Run Average\"\n",
    "era = get_stat_dataframe(stat_name_input)\n",
    "era.rename(columns={\"R\":\"RA\"}, inplace=True)\n",
    "era = era.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Fielding Percentage\"\n",
    "fp = get_stat_dataframe(stat_name_input)\n",
    "fp[\"APG\"] = fp[\"A\"] / fp[\"G\"]\n",
    "fp[\"EPG\"] = fp[\"E\"] / fp[\"G\"]\n",
    "fp = fp.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Hits Allowed Per Nine Innings\"\n",
    "ha = get_stat_dataframe(stat_name_input)\n",
    "ha.rename(columns={\"PG\": \"HAPG\"}, inplace=True)\n",
    "ha = ha.drop(columns=['Rank', 'G', 'IP'])\n",
    "\n",
    "stat_name_input = \"Home Runs Per Game\"\n",
    "hr = get_stat_dataframe(stat_name_input)\n",
    "hr.rename(columns={\"PG\": \"HRPG\"}, inplace=True)\n",
    "hr = hr.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"On Base Percentage\"\n",
    "obp = get_stat_dataframe(stat_name_input)\n",
    "obp.rename(columns={\"PCT\": \"OBP\"}, inplace=True)\n",
    "obp[\"HBPPG\"] = obp[\"HBP\"] / obp[\"G\"]\n",
    "obp = obp.drop(columns=['Rank', 'G', 'AB', 'H', 'BB', 'SF', 'SH'])\n",
    "\n",
    "stat_name_input = \"Runs\"\n",
    "runs = get_stat_dataframe(stat_name_input)\n",
    "runs[\"RPG\"] = runs[\"R\"] / runs[\"G\"]\n",
    "runs.rename(columns={\"R\": \"RS\"}, inplace=True)\n",
    "runs = runs.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Sacrifice Bunts\"\n",
    "sb = get_stat_dataframe(stat_name_input)\n",
    "sb.rename(columns={\"SH\": \"SB\"}, inplace=True)\n",
    "sb[\"SBPG\"] = sb[\"SB\"] / sb[\"G\"]\n",
    "sb = sb.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Sacrifice Flies\"\n",
    "sf = get_stat_dataframe(stat_name_input)\n",
    "sf[\"SFPG\"] = sf[\"SF\"] / sf[\"G\"]\n",
    "sf = sf.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Slugging Percentage\"\n",
    "slg = get_stat_dataframe(stat_name_input)\n",
    "slg.rename(columns={\"SLG PCT\": \"SLG\"}, inplace=True)\n",
    "slg = slg.drop(columns=['Rank', 'G', 'AB'])\n",
    "\n",
    "stat_name_input = \"Stolen Bases\"\n",
    "stl = get_stat_dataframe(stat_name_input)\n",
    "stl[\"STLP\"] = stl[\"SB\"] / (stl[\"SB\"] + stl[\"CS\"])\n",
    "stl[\"STLPG\"] = stl[\"SB\"] / stl[\"G\"]\n",
    "stl[\"CSPG\"] = stl[\"CS\"] / stl[\"G\"]\n",
    "stl[\"SAPG\"] = (stl[\"SB\"] + stl[\"CS\"]) / stl[\"G\"]\n",
    "stl.rename(columns={\"SB\": \"STL\"}, inplace=True)\n",
    "stl = stl.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Strikeout-to-Walk Ratio\"\n",
    "kbb = get_stat_dataframe(stat_name_input)\n",
    "kbb[\"IP\"] = round(kbb[\"IP\"])\n",
    "kbb.rename(columns={\"K/BB\": \"KBB\"}, inplace=True)\n",
    "kbb.rename(columns={\"BB\": \"PBB\"}, inplace=True)\n",
    "kbb = kbb.drop(columns=['Rank', 'App', 'IP'])\n",
    "\n",
    "stat_name_input = \"Strikeouts Per Nine Innings\"\n",
    "kp9 = get_stat_dataframe(stat_name_input)\n",
    "kp9.rename(columns={\"K/9\": \"KP9\"}, inplace=True)\n",
    "kp9 = kp9.drop(columns=['Rank', 'G', 'IP', 'SO'])\n",
    "\n",
    "stat_name_input = \"Walks Allowed Per Nine Innings\"\n",
    "wp9 = get_stat_dataframe(stat_name_input)\n",
    "wp9.rename(columns={\"PG\": \"WP9\"}, inplace=True)\n",
    "wp9 = wp9.drop(columns=['Rank', 'G', 'IP', 'BB'])\n",
    "\n",
    "stat_name_input = \"WHIP\"\n",
    "whip = get_stat_dataframe(stat_name_input)\n",
    "whip = whip.drop(columns=['Rank', 'HA', 'IP', 'BB'])\n",
    "\n",
    "dfs = [ba, bb, dp, era, fp, ha, hr, obp, runs, sb, sf, slg, stl, kbb, kp9, wp9, whip, rpi, cbr]\n",
    "df_combined = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    df_combined = pd.merge(df_combined, df, on=\"Team\", how=\"inner\")\n",
    "baseball_stats = df_combined.loc[:, ~df_combined.columns.duplicated()].sort_values('Team').reset_index(drop=True)\n",
    "baseball_stats['OPS'] = baseball_stats['SLG'] + baseball_stats['OBP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_stats = baseball_stats[['Team', 'HPG', 'ABPG', 'HPAB', \n",
    "                'BBPG', 'ERA', 'PCT', 'APG', \n",
    "                'EPG', 'HAPG', 'HRPG', 'OBP', \n",
    "                'HBPPG', 'RPG', 'SBPG', 'SFPG', \n",
    "                'SLG', 'STLP', 'STLPG', 'CSPG', \n",
    "                'SAPG', 'KP9', 'WP9', 'OPS', 'WHIP', 'Rank', 'CBRank']]\n",
    "modeling_stats[\"Rank\"] = modeling_stats[\"Rank\"].apply(pd.to_numeric, errors='coerce')\n",
    "modeling_stats[\"CBRank\"] = modeling_stats[\"CBRank\"].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "higher_better = [\"HPG\", \"ABPG\", \"HPAB\", \"BBPG\", \"PCT\", \"APG\", \"HRPG\", \"OBP\", \"HBPPG\", \"RPG\", \"SBPG\", \"SFPG\", \"SLG\", \"STLP\", \"STLPG\", \"CSPG\", \"SAPG\", \"KP9\", \"OPS\"]\n",
    "lower_better = [\"ERA\", \"EPG\", \"HAPG\", \"WP9\", \"WHIP\"]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(1, 100))\n",
    "modeling_stats[higher_better] = scaler.fit_transform(modeling_stats[higher_better])\n",
    "modeling_stats[lower_better] = scaler.fit_transform(-modeling_stats[lower_better])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:   0%|          | 1/500 [00:00<07:08,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from scipy.optimize import differential_evolution\n",
    "from tqdm import tqdm\n",
    "pbar = tqdm(total=500, desc=\"Optimization Progress\")\n",
    "def progress_callback(xk, convergence):\n",
    "    \"\"\"Callback to update the progress bar after each iteration.\"\"\"\n",
    "    pbar.update(1)\n",
    "    if convergence < 1e-4:  # Close bar if convergence is achieved early\n",
    "        pbar.close()\n",
    "\n",
    "def objective_function(weights):\n",
    "    (w_hpb, w_bbpg, w_era, w_pct, w_hrpg, w_rpg, w_kp9, w_wp9, w_whip, w_ops, w_rank, w_cbrank) = weights\n",
    "    \n",
    "    modeling_stats['power_ranking'] = (\n",
    "        w_hpb * modeling_stats['HPG'] +\n",
    "        w_bbpg * modeling_stats['BBPG'] +\n",
    "        w_era * modeling_stats['ERA'] +\n",
    "        w_pct * modeling_stats['PCT'] +\n",
    "        w_hrpg * modeling_stats['HRPG'] +\n",
    "        w_rpg * modeling_stats['RPG'] +\n",
    "        w_kp9 * modeling_stats['KP9'] +\n",
    "        w_wp9 * modeling_stats['WP9'] +\n",
    "        w_whip * modeling_stats['WHIP'] +\n",
    "        w_ops * modeling_stats['OPS']\n",
    "    )\n",
    "\n",
    "    modeling_stats['calculated_rank'] = modeling_stats['power_ranking'].rank(ascending=False)\n",
    "    modeling_stats['combined_rank'] = (\n",
    "        w_rank * modeling_stats['Rank'] +\n",
    "        w_cbrank * modeling_stats['CBRank']\n",
    "    )\n",
    "    spearman_corr = modeling_stats[['calculated_rank', 'combined_rank']].corr(method='spearman').iloc[0,1]\n",
    "\n",
    "    return -spearman_corr\n",
    "\n",
    "bounds = [(-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (0,1),\n",
    "          (0,1)]\n",
    "result = differential_evolution(objective_function, bounds, strategy='best1bin', maxiter=500, tol=1e-4, seed=42, callback=progress_callback)\n",
    "optimized_weights = result.x\n",
    "modeling_stats = modeling_stats.sort_values('power_ranking', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_stats['Rating'] = modeling_stats['power_ranking'] - modeling_stats['power_ranking'].mean()\n",
    "current_range = modeling_stats['Rating'].max() - modeling_stats['Rating'].min()\n",
    "desired_range = 25\n",
    "scaling_factor = desired_range / current_range\n",
    "modeling_stats['Rating'] = round(modeling_stats['Rating'] * scaling_factor, 4)\n",
    "modeling_stats['Rating'] = modeling_stats['Rating'] - modeling_stats['Rating'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Dictionary\n",
    "\n",
    "- G: Games\n",
    "- AB: At Bats\n",
    "- H: Hits\n",
    "- BA: Batting Average\n",
    "- HPG: Hits Per Game\n",
    "- ABPG: At Bats Per Game\n",
    "- HPAB: Hits Per At Bat\n",
    "- BB: Walks\n",
    "- BBPG: Walks Per Game\n",
    "- DP: Double Plays\n",
    "- DPPG: Double Plays Per Game\n",
    "- IP: Innings Pitched\n",
    "- RA: Runs Allowed\n",
    "- ER: Earned Runs\n",
    "- ERA: Earned Runs Allowed\n",
    "- PO: Put Outs\n",
    "- A: Assists\n",
    "- E: Errors\n",
    "- PCT: Fielding Percentage\n",
    "- APG: Assists Per Game\n",
    "- EPG: Errors Per Game\n",
    "- HA: Hits Allowed\n",
    "- HAPG: Hits Allowed Per Game\n",
    "- HR: Home Runs Hit\n",
    "- HRPG: Home Runs Hit Per Game\n",
    "- HBP: Hit By Pitch\n",
    "- OBP: On Base Percentage\n",
    "- HBPPG: Hit By Pitch Per Game\n",
    "- RS: Runs Scored\n",
    "- RPG: Runs Scored Per Game\n",
    "- SB: Sacrifice Bunts\n",
    "- SBPG: Sacrifice Bunts Per Game\n",
    "- SF: Sacrifice Flies\n",
    "- SFPG: Sacrifice Flies Per Game\n",
    "- TB: Total Bases\n",
    "- SLG: Slugging Percentage\n",
    "- STL: Stolen Bases\n",
    "- CS: Caught Stealing\n",
    "- STLP: Stolen Bases Success Percentage\n",
    "- STLPG: Stolen Bases Per Game\n",
    "- CSPG: Caught Stealing Per Game\n",
    "- SAPG: Stealing Attempts Per Game\n",
    "- SO: Pitching Strike Outs\n",
    "- PBB: Pitching Walks\n",
    "- KBB: Strikeouts to Walk Ratio\n",
    "- KP9: Strikeouts Per Nine\n",
    "- WP9: Walks Allowed Per Nine\n",
    "- WHIP: Walks Hits Over Innings Pitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scrape all stats at once\n",
    "# for stat_name, url in stat_links.items():\n",
    "#     print(f\"Scraping: {stat_name} ({url})\")\n",
    "    \n",
    "#     # Get stats page content\n",
    "#     soup = get_soup(url)\n",
    "    \n",
    "#     # Locate table\n",
    "#     table = soup.find(\"table\")\n",
    "#     if not table:\n",
    "#         print(f\"No table found for {stat_name}\")\n",
    "#         continue\n",
    "\n",
    "#     # Extract table headers\n",
    "#     headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "\n",
    "#     # Extract table rows\n",
    "#     data = []\n",
    "#     for row in table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "#         cols = row.find_all(\"td\")\n",
    "#         data.append([col.text.strip() for col in cols])\n",
    "\n",
    "#     # Convert to DataFrame and save\n",
    "#     df = pd.DataFrame(data, columns=headers)\n",
    "#     # df.to_csv(f\"{stat_name}.csv\", index=False)\n",
    "#     print(f\"Saved {stat_name}.csv\")\n",
    "\n",
    "# print(\"Scraping completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power_ratings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
