{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def PEAR_Win_Prob(home_pr, away_pr):\n",
    "    rating_diff = home_pr - away_pr\n",
    "    win_prob = round(1 / (1 + 10 ** (-rating_diff / 10)) * 100, 2)\n",
    "    return win_prob\n",
    "\n",
    "# Base URL for NCAA stats\n",
    "base_url = \"https://www.ncaa.com\"\n",
    "stats_page = f\"{base_url}/stats/baseball/d1\"\n",
    "\n",
    "# Function to get page content\n",
    "def get_soup(url):\n",
    "    response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    response.raise_for_status()  # Ensure request was successful\n",
    "    return BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Get main page content\n",
    "soup = get_soup(stats_page)\n",
    "\n",
    "# Find the dropdown container and extract stat URLs\n",
    "dropdown = soup.find(\"select\", {\"id\": \"select-container-team\"})\n",
    "options = dropdown.find_all(\"option\")\n",
    "\n",
    "# Extract stat names and links\n",
    "stat_links = {\n",
    "    option.text.strip(): base_url + option[\"value\"]\n",
    "    for option in options if option.get(\"value\")\n",
    "}\n",
    "\n",
    "url = \"https://www.ncaa.com/rankings/baseball/d1/rpi\"\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Ensure request was successful\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "table = soup.find(\"table\", class_=\"sticky\")\n",
    "if table:\n",
    "    headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "    data = []\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "        cols = row.find_all(\"td\")\n",
    "        data.append([col.text.strip() for col in cols])\n",
    "    rpi = pd.DataFrame(data, columns=headers)\n",
    "    rpi = rpi.drop(columns = ['Previous'])\n",
    "    rpi.rename(columns={\"School\": \"Team\"}, inplace=True)\n",
    "else:\n",
    "    print(\"Table not found.\")\n",
    "\n",
    "url = \"https://www.collegebaseballratings.com/\"\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Raise an error for failed requests\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "table = soup.find(\"table\", {\"id\": \"teamList\"})\n",
    "headers = [th.text.strip() for th in table.find(\"thead\").find_all(\"th\")]\n",
    "data = []\n",
    "for row in table.find(\"tbody\").find_all(\"tr\"):\n",
    "    cells = [td.text.strip() for td in row.find_all(\"td\")]\n",
    "    data.append(cells)\n",
    "cbr = pd.DataFrame(data, columns=headers[1:])\n",
    "cbr.rename(columns={\"Rank\":\"CBRank\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batting Average Done\n",
      "Base on Balls Done\n",
      "Double Plays Per Game Done\n",
      "Earned Run Average Done\n",
      "Fielding Percentage Done\n",
      "Hits Allowed Per Nine Innings Done\n",
      "Home Runs Per Game Done\n",
      "On Base Percentage Done\n",
      "Runs Done\n",
      "Sacrifice Bunts Done\n",
      "Sacrifice Flies Done\n",
      "Slugging Percentage Done\n",
      "Stolen Bases Done\n",
      "Strikeout-to-Walk Ratio Done\n",
      "Strikeouts Per Nine Innings Done\n",
      "Walks Allowed Per Nine Innings Done\n",
      "WHIP Done\n"
     ]
    }
   ],
   "source": [
    "def get_stat_dataframe(stat_name):\n",
    "    \"\"\"Fetches the specified stat table from multiple pages and returns a combined DataFrame,\n",
    "    keeps 'Team' as string, and converts all other columns to float.\"\"\"\n",
    "    \n",
    "    if stat_name not in stat_links:\n",
    "        print(f\"Stat '{stat_name}' not found. Available stats: {list(stat_links.keys())}\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize the DataFrame to store all pages' data\n",
    "    all_data = []\n",
    "    page_num = 1  # Start from the first page\n",
    "\n",
    "    while True:\n",
    "        url = stat_links[stat_name]\n",
    "        if page_num > 1:\n",
    "            # Modify the URL to include the page number\n",
    "            url = f\"{url}/p{page_num}\"\n",
    "        \n",
    "        # print(f\"Fetching data for: {stat_name} (Page {page_num} - {url})\")\n",
    "\n",
    "        try:\n",
    "            # Get stats page content\n",
    "            soup = get_soup(url)\n",
    "\n",
    "            # Locate table\n",
    "            table = soup.find(\"table\")\n",
    "            if not table:\n",
    "                print(f\"No table found for {stat_name} on page {page_num}\")\n",
    "                break  # Exit the loop if no table is found (end of valid pages)\n",
    "\n",
    "            # Extract table headers\n",
    "            headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "\n",
    "            # Extract table rows\n",
    "            data = []\n",
    "            for row in table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "                cols = row.find_all(\"td\")\n",
    "                data.append([col.text.strip() for col in cols])\n",
    "\n",
    "            all_data.extend(data)  # Add the data from this page to the list of all data\n",
    "        \n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(f\"{stat_name} Done\")\n",
    "            break  # Exit the loop on HTTPError (page doesn't exist)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break  # Exit the loop on any other error\n",
    "\n",
    "        page_num += 1  # Go to the next page\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data, columns=headers)\n",
    "\n",
    "        # Convert all columns to float except \"Team\"\n",
    "        for col in df.columns:\n",
    "            if col != \"Team\":\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\")  # Converts to float, invalid values become NaN\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No data collected.\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "stat_name_input = \"Batting Average\"  # Change this to the desired stat\n",
    "ba = get_stat_dataframe(stat_name_input)\n",
    "ba[\"HPG\"] = ba[\"H\"] / ba[\"G\"]\n",
    "ba[\"ABPG\"] = ba[\"AB\"] / ba[\"G\"]\n",
    "ba[\"HPAB\"] = ba[\"H\"] / ba[\"AB\"]\n",
    "ba = ba.drop(columns=['Rank'])\n",
    "\n",
    "stat_name_input = \"Base on Balls\"\n",
    "bb = get_stat_dataframe(stat_name_input)\n",
    "bb[\"BBPG\"] = bb[\"BB\"] / bb[\"G\"]\n",
    "bb = bb.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Double Plays Per Game\"\n",
    "dp = get_stat_dataframe(stat_name_input)\n",
    "dp.rename(columns={\"PG\": \"DPPG\"}, inplace=True)\n",
    "dp = dp.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Earned Run Average\"\n",
    "era = get_stat_dataframe(stat_name_input)\n",
    "era.rename(columns={\"R\":\"RA\"}, inplace=True)\n",
    "era = era.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Fielding Percentage\"\n",
    "fp = get_stat_dataframe(stat_name_input)\n",
    "fp[\"APG\"] = fp[\"A\"] / fp[\"G\"]\n",
    "fp[\"EPG\"] = fp[\"E\"] / fp[\"G\"]\n",
    "fp = fp.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Hits Allowed Per Nine Innings\"\n",
    "ha = get_stat_dataframe(stat_name_input)\n",
    "ha.rename(columns={\"PG\": \"HAPG\"}, inplace=True)\n",
    "ha = ha.drop(columns=['Rank', 'G', 'IP'])\n",
    "\n",
    "stat_name_input = \"Home Runs Per Game\"\n",
    "hr = get_stat_dataframe(stat_name_input)\n",
    "hr.rename(columns={\"PG\": \"HRPG\"}, inplace=True)\n",
    "hr = hr.drop(columns=['Rank', 'G'])\n",
    "duplicate_teams = hr[hr.duplicated('Team', keep=False)]\n",
    "filtered_teams = duplicate_teams.loc[duplicate_teams.groupby('Team')[\"HR\"].idxmin()]\n",
    "hr_cleaned = hr[~hr[\"Team\"].isin(duplicate_teams[\"Team\"])]\n",
    "hr = pd.concat([hr_cleaned, filtered_teams], ignore_index=True)\n",
    "\n",
    "stat_name_input = \"On Base Percentage\"\n",
    "obp = get_stat_dataframe(stat_name_input)\n",
    "obp.rename(columns={\"PCT\": \"OBP\"}, inplace=True)\n",
    "obp[\"HBPPG\"] = obp[\"HBP\"] / obp[\"G\"]\n",
    "obp = obp.drop(columns=['Rank', 'G', 'AB', 'H', 'BB', 'SF', 'SH'])\n",
    "\n",
    "stat_name_input = \"Runs\"\n",
    "runs = get_stat_dataframe(stat_name_input)\n",
    "runs[\"RPG\"] = runs[\"R\"] / runs[\"G\"]\n",
    "runs.rename(columns={\"R\": \"RS\"}, inplace=True)\n",
    "runs = runs.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Sacrifice Bunts\"\n",
    "sb = get_stat_dataframe(stat_name_input)\n",
    "sb.rename(columns={\"SH\": \"SB\"}, inplace=True)\n",
    "sb[\"SBPG\"] = sb[\"SB\"] / sb[\"G\"]\n",
    "sb = sb.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Sacrifice Flies\"\n",
    "sf = get_stat_dataframe(stat_name_input)\n",
    "sf[\"SFPG\"] = sf[\"SF\"] / sf[\"G\"]\n",
    "sf = sf.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Slugging Percentage\"\n",
    "slg = get_stat_dataframe(stat_name_input)\n",
    "slg.rename(columns={\"SLG PCT\": \"SLG\"}, inplace=True)\n",
    "slg = slg.drop(columns=['Rank', 'G', 'AB'])\n",
    "\n",
    "stat_name_input = \"Stolen Bases\"\n",
    "stl = get_stat_dataframe(stat_name_input)\n",
    "stl[\"STLP\"] = stl[\"SB\"] / (stl[\"SB\"] + stl[\"CS\"])\n",
    "stl[\"STLPG\"] = stl[\"SB\"] / stl[\"G\"]\n",
    "stl[\"CSPG\"] = stl[\"CS\"] / stl[\"G\"]\n",
    "stl[\"SAPG\"] = (stl[\"SB\"] + stl[\"CS\"]) / stl[\"G\"]\n",
    "stl.rename(columns={\"SB\": \"STL\"}, inplace=True)\n",
    "stl = stl.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Strikeout-to-Walk Ratio\"\n",
    "kbb = get_stat_dataframe(stat_name_input)\n",
    "kbb[\"IP\"] = round(kbb[\"IP\"])\n",
    "kbb.rename(columns={\"K/BB\": \"KBB\"}, inplace=True)\n",
    "kbb.rename(columns={\"BB\": \"PBB\"}, inplace=True)\n",
    "kbb = kbb.drop(columns=['Rank', 'App', 'IP'])\n",
    "\n",
    "stat_name_input = \"Strikeouts Per Nine Innings\"\n",
    "kp9 = get_stat_dataframe(stat_name_input)\n",
    "kp9.rename(columns={\"K/9\": \"KP9\"}, inplace=True)\n",
    "kp9 = kp9.drop(columns=['Rank', 'G', 'IP', 'SO'])\n",
    "\n",
    "stat_name_input = \"Walks Allowed Per Nine Innings\"\n",
    "wp9 = get_stat_dataframe(stat_name_input)\n",
    "wp9.rename(columns={\"PG\": \"WP9\"}, inplace=True)\n",
    "wp9 = wp9.drop(columns=['Rank', 'G', 'IP', 'BB'])\n",
    "\n",
    "stat_name_input = \"WHIP\"\n",
    "whip = get_stat_dataframe(stat_name_input)\n",
    "whip = whip.drop(columns=['Rank', 'HA', 'IP', 'BB'])\n",
    "\n",
    "dfs = [ba, bb, era, fp, obp, runs, slg, kp9, wp9, whip, rpi, cbr]\n",
    "for df in dfs:\n",
    "    df[\"Team\"] = df[\"Team\"].str.strip()\n",
    "df_combined = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    df_combined = pd.merge(df_combined, df, on=\"Team\", how=\"inner\")\n",
    "baseball_stats = df_combined.loc[:, ~df_combined.columns.duplicated()].sort_values('Team').reset_index(drop=True)\n",
    "baseball_stats['OPS'] = baseball_stats['SLG'] + baseball_stats['OBP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_stats = baseball_stats[['Team', 'HPG',\n",
    "                'BBPG', 'ERA', 'PCT', \n",
    "                'KP9', 'WP9', 'OPS', \n",
    "                'WHIP', 'Rank', 'CBRank']]\n",
    "modeling_stats[\"Rank\"] = modeling_stats[\"Rank\"].apply(pd.to_numeric, errors='coerce')\n",
    "modeling_stats[\"CBRank\"] = modeling_stats[\"CBRank\"].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "higher_better = [\"HPG\", \"BBPG\", \"PCT\", \"KP9\", \"OPS\"]\n",
    "lower_better = [\"ERA\", \"WP9\", \"WHIP\"]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(1, 100))\n",
    "modeling_stats[higher_better] = scaler.fit_transform(modeling_stats[higher_better])\n",
    "modeling_stats[lower_better] = scaler.fit_transform(-modeling_stats[lower_better])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_stats['in_house_pr'] = 2 * modeling_stats['ERA'] + 0.1 * modeling_stats['BBPG'] + 0.5 * modeling_stats['HPG'] + 2 * modeling_stats['OPS'] + 0.5 * modeling_stats['WHIP']\n",
    "modeling_stats['in_house_pr'] = modeling_stats['in_house_pr'] - modeling_stats['in_house_pr'].mean()\n",
    "current_range = modeling_stats['in_house_pr'].max() - modeling_stats['in_house_pr'].min()\n",
    "desired_range = 25\n",
    "scaling_factor = desired_range / current_range\n",
    "modeling_stats['in_house_pr'] = round(modeling_stats['in_house_pr'] * scaling_factor, 4)\n",
    "modeling_stats['in_house_pr'] = modeling_stats['in_house_pr'] - modeling_stats['in_house_pr'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  54%|█████▍    | 269/500 [02:03<01:45,  2.19it/s]\n",
      "Optimization Progress:   0%|          | 1/500 [00:00<05:16,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from scipy.optimize import differential_evolution\n",
    "from tqdm import tqdm\n",
    "pbar = tqdm(total=500, desc=\"Optimization Progress\")\n",
    "def progress_callback(xk, convergence):\n",
    "    \"\"\"Callback to update the progress bar after each iteration.\"\"\"\n",
    "    pbar.update(1)\n",
    "    if convergence < 1e-4:  # Close bar if convergence is achieved early\n",
    "        pbar.close()\n",
    "\n",
    "def objective_function(weights):\n",
    "    (w_hpb, w_bbpg, w_era, w_pct, w_kp9, w_wp9, w_whip, w_ops, w_in_house_pr, w_cbrank) = weights\n",
    "    \n",
    "    modeling_stats['power_ranking'] = (\n",
    "        w_hpb * modeling_stats['HPG'] +\n",
    "        w_bbpg * modeling_stats['BBPG'] +\n",
    "        w_era * modeling_stats['ERA'] +\n",
    "        w_pct * modeling_stats['PCT'] +\n",
    "        w_kp9 * modeling_stats['KP9'] +\n",
    "        w_wp9 * modeling_stats['WP9'] +\n",
    "        w_whip * modeling_stats['WHIP'] +\n",
    "        w_ops * modeling_stats['OPS'] +\n",
    "        w_in_house_pr * modeling_stats['in_house_pr']\n",
    "    )\n",
    "\n",
    "    modeling_stats['calculated_rank'] = modeling_stats['power_ranking'].rank(ascending=False)\n",
    "    modeling_stats['combined_rank'] = (\n",
    "        w_cbrank * modeling_stats['CBRank']\n",
    "    )\n",
    "    spearman_corr = modeling_stats[['calculated_rank', 'combined_rank']].corr(method='spearman').iloc[0,1]\n",
    "\n",
    "    return -spearman_corr\n",
    "\n",
    "bounds = [(-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (0,1),\n",
    "          (0,1)]\n",
    "result = differential_evolution(objective_function, bounds, strategy='best1bin', maxiter=500, tol=1e-4, seed=42, callback=progress_callback)\n",
    "optimized_weights = result.x\n",
    "modeling_stats = modeling_stats.sort_values('power_ranking', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_stats['Rating'] = modeling_stats['power_ranking'] - modeling_stats['power_ranking'].mean()\n",
    "current_range = modeling_stats['Rating'].max() - modeling_stats['Rating'].min()\n",
    "desired_range = 25\n",
    "scaling_factor = desired_range / current_range\n",
    "modeling_stats['Rating'] = round(modeling_stats['Rating'] * scaling_factor, 4)\n",
    "modeling_stats['Rating'] = modeling_stats['Rating'] - modeling_stats['Rating'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>G</th>\n",
       "      <th>AB</th>\n",
       "      <th>H</th>\n",
       "      <th>BA</th>\n",
       "      <th>HPG</th>\n",
       "      <th>ABPG</th>\n",
       "      <th>HPAB</th>\n",
       "      <th>BB</th>\n",
       "      <th>BBPG</th>\n",
       "      <th>...</th>\n",
       "      <th>vs 1-25</th>\n",
       "      <th>vs 26-50</th>\n",
       "      <th>vs 51-100</th>\n",
       "      <th>vs 101-200</th>\n",
       "      <th>vs 201+</th>\n",
       "      <th>RPI</th>\n",
       "      <th>Prev</th>\n",
       "      <th>Trend</th>\n",
       "      <th>OPS</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Florida</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>37</td>\n",
       "      <td>0.385</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.385417</td>\n",
       "      <td>14</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>3-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1.154</td>\n",
       "      <td>25.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSU</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>33</td>\n",
       "      <td>0.340</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>32.333333</td>\n",
       "      <td>0.340206</td>\n",
       "      <td>23</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>3-0</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.045</td>\n",
       "      <td>23.2102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "      <td>22</td>\n",
       "      <td>0.253</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>21</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>3-0</td>\n",
       "      <td></td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.812</td>\n",
       "      <td>23.0996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Miami (FL)</td>\n",
       "      <td>3</td>\n",
       "      <td>101</td>\n",
       "      <td>36</td>\n",
       "      <td>0.356</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>25</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>3-0</td>\n",
       "      <td></td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1.050</td>\n",
       "      <td>21.1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UC Santa Barbara</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>33</td>\n",
       "      <td>0.317</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>34.666667</td>\n",
       "      <td>0.317308</td>\n",
       "      <td>7</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>3-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td></td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.948</td>\n",
       "      <td>20.4146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Bellarmine</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>23</td>\n",
       "      <td>0.237</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>32.333333</td>\n",
       "      <td>0.237113</td>\n",
       "      <td>8</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-3</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td></td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>0.672</td>\n",
       "      <td>2.9734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Siena</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>17</td>\n",
       "      <td>0.177</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>8</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-3</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td></td>\n",
       "      <td>295</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.511</td>\n",
       "      <td>2.9731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Lehigh</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "      <td>0.148</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>12</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-3</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td></td>\n",
       "      <td>253</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.451</td>\n",
       "      <td>2.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Bucknell</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>12</td>\n",
       "      <td>0.135</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>0.134831</td>\n",
       "      <td>15</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>1-2</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td></td>\n",
       "      <td>239</td>\n",
       "      <td>3</td>\n",
       "      <td>0.458</td>\n",
       "      <td>1.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Fordham</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>15</td>\n",
       "      <td>0.195</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>0.194805</td>\n",
       "      <td>10</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0-3</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0-0</td>\n",
       "      <td></td>\n",
       "      <td>262</td>\n",
       "      <td>-2</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Team  G   AB   H     BA        HPG       ABPG      HPAB  BB  \\\n",
       "1             Florida  3   96  37  0.385  12.333333  32.000000  0.385417  14   \n",
       "2                 LSU  3   97  33  0.340  11.000000  32.333333  0.340206  23   \n",
       "3      South Carolina  3   87  22  0.253   7.333333  29.000000  0.252874  21   \n",
       "4          Miami (FL)  3  101  36  0.356  12.000000  33.666667  0.356436  25   \n",
       "5    UC Santa Barbara  3  104  33  0.317  11.000000  34.666667  0.317308   7   \n",
       "..                ... ..  ...  ..    ...        ...        ...       ...  ..   \n",
       "187        Bellarmine  3   97  23  0.237   7.666667  32.333333  0.237113   8   \n",
       "188             Siena  3   96  17  0.177   5.666667  32.000000  0.177083   8   \n",
       "189            Lehigh  3   81  12  0.148   4.000000  27.000000  0.148148  12   \n",
       "190          Bucknell  3   89  12  0.135   4.000000  29.666667  0.134831  15   \n",
       "191           Fordham  3   77  15  0.195   5.000000  25.666667  0.194805  10   \n",
       "\n",
       "         BBPG  ...  vs 1-25  vs 26-50  vs 51-100  vs 101-200  vs 201+  RPI  \\\n",
       "1    4.666667  ...      0-0       0-0        0-0         3-0      0-0        \n",
       "2    7.666667  ...      0-0       0-0        0-0         0-0      3-0        \n",
       "3    7.000000  ...      0-0       0-0        0-0         0-0      3-0        \n",
       "4    8.333333  ...      0-0       0-0        0-0         0-0      3-0        \n",
       "5    2.333333  ...      0-0       0-0        3-0         0-0      0-0        \n",
       "..        ...  ...      ...       ...        ...         ...      ...  ...   \n",
       "187  2.666667  ...      0-0       0-0        0-3         0-0      0-0        \n",
       "188  2.666667  ...      0-0       0-3        0-0         0-0      0-0        \n",
       "189  4.000000  ...      0-0       0-3        0-0         0-0      0-0        \n",
       "190  5.000000  ...      0-0       1-2        0-0         0-0      0-0        \n",
       "191  3.333333  ...      0-3       0-0        0-0         0-0      0-0        \n",
       "\n",
       "     Prev  Trend    OPS   Rating  \n",
       "1      12      2  1.154  25.0000  \n",
       "2       9      1  1.045  23.2102  \n",
       "3      25      1  0.812  23.0996  \n",
       "4      42      1  1.050  21.1965  \n",
       "5      24      2  0.948  20.4146  \n",
       "..    ...    ...    ...      ...  \n",
       "187   288      0  0.672   2.9734  \n",
       "188   295     -1  0.511   2.9731  \n",
       "189   253     -5  0.451   2.8750  \n",
       "190   239      3  0.458   1.9997  \n",
       "191   262     -2  0.651   0.0000  \n",
       "\n",
       "[191 rows x 54 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ending_data = pd.merge(baseball_stats, modeling_stats[['Team', 'Rating']], on=\"Team\", how=\"inner\").sort_values('Rating', ascending=False).reset_index(drop=True)\n",
    "ending_data.index = ending_data.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>CBRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Florida</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSU</td>\n",
       "      <td>23.2102</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>23.0996</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miami (FL)</td>\n",
       "      <td>21.1965</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UC Santa Barbara</td>\n",
       "      <td>20.4146</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mount St. Mary's</td>\n",
       "      <td>20.2708</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>19.8714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Winthrop</td>\n",
       "      <td>19.8543</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Virginia Tech</td>\n",
       "      <td>19.6522</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Samford</td>\n",
       "      <td>19.1072</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>18.7335</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Little Rock</td>\n",
       "      <td>18.7155</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Vanderbilt</td>\n",
       "      <td>18.5718</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>18.5686</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Baylor</td>\n",
       "      <td>18.5081</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mercer</td>\n",
       "      <td>18.5078</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Coastal Carolina</td>\n",
       "      <td>18.3113</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>18.2713</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>18.1248</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>UCF</td>\n",
       "      <td>18.1039</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>18.0376</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>South Alabama</td>\n",
       "      <td>17.9316</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Georgia Tech</td>\n",
       "      <td>17.8805</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>17.7439</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>17.6164</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Team   Rating  CBRank\n",
       "0            Florida  25.0000      10\n",
       "1                LSU  23.2102       8\n",
       "2     South Carolina  23.0996      24\n",
       "3         Miami (FL)  21.1965      41\n",
       "4   UC Santa Barbara  20.4146      22\n",
       "5   Mount St. Mary's  20.2708     282\n",
       "6          Tennessee  19.8714       1\n",
       "7           Winthrop  19.8543     211\n",
       "8      Virginia Tech  19.6522      38\n",
       "9            Samford  19.1072      75\n",
       "10            Oregon  18.7335      25\n",
       "11       Little Rock  18.7155     149\n",
       "12        Vanderbilt  18.5718       5\n",
       "13          Virginia  18.5686       7\n",
       "14            Baylor  18.5081      98\n",
       "15            Mercer  18.5078     101\n",
       "16  Coastal Carolina  18.3113      33\n",
       "17          Oklahoma  18.2713      29\n",
       "18          Arkansas  18.1248       2\n",
       "19               UCF  18.1039      47\n",
       "20          Michigan  18.0376      73\n",
       "21     South Alabama  17.9316      74\n",
       "22      Georgia Tech  17.8805      34\n",
       "23          Maryland  17.7439      50\n",
       "24    North Carolina  17.6164       9"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_stats[['Team', 'Rating', 'CBRank']][0:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Dictionary\n",
    "\n",
    "- G: Games\n",
    "- AB: At Bats\n",
    "- H: Hits\n",
    "- BA: Batting Average\n",
    "- HPG: Hits Per Game\n",
    "- ABPG: At Bats Per Game\n",
    "- HPAB: Hits Per At Bat\n",
    "- BB: Walks\n",
    "- BBPG: Walks Per Game\n",
    "- DP: Double Plays\n",
    "- DPPG: Double Plays Per Game\n",
    "- IP: Innings Pitched\n",
    "- RA: Runs Allowed\n",
    "- ER: Earned Runs\n",
    "- ERA: Earned Runs Allowed\n",
    "- PO: Put Outs\n",
    "- A: Assists\n",
    "- E: Errors\n",
    "- PCT: Fielding Percentage\n",
    "- APG: Assists Per Game\n",
    "- EPG: Errors Per Game\n",
    "- HA: Hits Allowed\n",
    "- HAPG: Hits Allowed Per Game\n",
    "- HR: Home Runs Hit\n",
    "- HRPG: Home Runs Hit Per Game\n",
    "- HBP: Hit By Pitch\n",
    "- OBP: On Base Percentage\n",
    "- HBPPG: Hit By Pitch Per Game\n",
    "- RS: Runs Scored\n",
    "- RPG: Runs Scored Per Game\n",
    "- SB: Sacrifice Bunts\n",
    "- SBPG: Sacrifice Bunts Per Game\n",
    "- SF: Sacrifice Flies\n",
    "- SFPG: Sacrifice Flies Per Game\n",
    "- TB: Total Bases\n",
    "- SLG: Slugging Percentage\n",
    "- STL: Stolen Bases\n",
    "- CS: Caught Stealing\n",
    "- STLP: Stolen Bases Success Percentage\n",
    "- STLPG: Stolen Bases Per Game\n",
    "- CSPG: Caught Stealing Per Game\n",
    "- SAPG: Stealing Attempts Per Game\n",
    "- SO: Pitching Strike Outs\n",
    "- PBB: Pitching Walks\n",
    "- KBB: Strikeouts to Walk Ratio\n",
    "- KP9: Strikeouts Per Nine\n",
    "- WP9: Walks Allowed Per Nine\n",
    "- WHIP: Walks Hits Over Innings Pitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scrape all stats at once\n",
    "# for stat_name, url in stat_links.items():\n",
    "#     print(f\"Scraping: {stat_name} ({url})\")\n",
    "    \n",
    "#     # Get stats page content\n",
    "#     soup = get_soup(url)\n",
    "    \n",
    "#     # Locate table\n",
    "#     table = soup.find(\"table\")\n",
    "#     if not table:\n",
    "#         print(f\"No table found for {stat_name}\")\n",
    "#         continue\n",
    "\n",
    "#     # Extract table headers\n",
    "#     headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "\n",
    "#     # Extract table rows\n",
    "#     data = []\n",
    "#     for row in table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "#         cols = row.find_all(\"td\")\n",
    "#         data.append([col.text.strip() for col in cols])\n",
    "\n",
    "#     # Convert to DataFrame and save\n",
    "#     df = pd.DataFrame(data, columns=headers)\n",
    "#     # df.to_csv(f\"{stat_name}.csv\", index=False)\n",
    "#     print(f\"Saved {stat_name}.csv\")\n",
    "\n",
    "# print(\"Scraping completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power_ratings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
