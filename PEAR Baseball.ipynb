{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Ratings Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "formatted_date = datetime.today().strftime('%m_%d_%Y')\n",
    "current_season = datetime.today().year\n",
    "\n",
    "def PEAR_Win_Prob(home_pr, away_pr):\n",
    "    rating_diff = home_pr - away_pr\n",
    "    win_prob = round(1 / (1 + 10 ** (-rating_diff / 7.5)) * 100, 2)\n",
    "    return win_prob\n",
    "\n",
    "# Base URL for NCAA stats\n",
    "base_url = \"https://www.ncaa.com\"\n",
    "stats_page = f\"{base_url}/stats/baseball/d1\"\n",
    "\n",
    "# Function to get page content\n",
    "def get_soup(url):\n",
    "    response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    response.raise_for_status()  # Ensure request was successful\n",
    "    return BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Get main page content\n",
    "soup = get_soup(stats_page)\n",
    "\n",
    "# Find the dropdown container and extract stat URLs\n",
    "dropdown = soup.find(\"select\", {\"id\": \"select-container-team\"})\n",
    "options = dropdown.find_all(\"option\")\n",
    "\n",
    "# Extract stat names and links\n",
    "stat_links = {\n",
    "    option.text.strip(): base_url + option[\"value\"]\n",
    "    for option in options if option.get(\"value\")\n",
    "}\n",
    "\n",
    "url = \"https://www.ncaa.com/rankings/baseball/d1/rpi\"\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Ensure request was successful\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "table = soup.find(\"table\", class_=\"sticky\")\n",
    "if table:\n",
    "    headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "    data = []\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "        cols = row.find_all(\"td\")\n",
    "        data.append([col.text.strip() for col in cols])\n",
    "    rpi = pd.DataFrame(data, columns=headers)\n",
    "    rpi = rpi.drop(columns = ['Previous'])\n",
    "    rpi.rename(columns={\"School\": \"Team\"}, inplace=True)\n",
    "else:\n",
    "    print(\"Table not found.\")\n",
    "\n",
    "url = \"https://www.collegebaseballratings.com/\"\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Raise an error for failed requests\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "table = soup.find(\"table\", {\"id\": \"teamList\"})\n",
    "headers = [th.text.strip() for th in table.find(\"thead\").find_all(\"th\")]\n",
    "data = []\n",
    "for row in table.find(\"tbody\").find_all(\"tr\"):\n",
    "    cells = [td.text.strip() for td in row.find_all(\"td\")]\n",
    "    data.append(cells)\n",
    "cbr = pd.DataFrame(data, columns=headers[1:])\n",
    "cbr.rename(columns={\"Rank\":\"CBRank\"}, inplace=True)\n",
    "cbr['Team'] = cbr['Team'].str.replace('State', 'St.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Southern Miss', 'Southern Miss.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('NC St.', 'NC State', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Appalachian St.', 'App State', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Dallas Baptist', 'DBU', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('USC', 'Southern California', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Charleston', 'Col. of Charleston', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Col. of Charleston Southern', 'Charleston So.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Georgia Southern', 'Ga. Southern', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('UNC Wilmington', 'UNCW', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Southern Illinois', 'Southern Ill.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Florida Atlantic', 'Fla. Atlantic', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Lamar', 'Lamar University', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Western Kentucky', 'Western Ky.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Southern California Upstate', 'USC Upstate', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Southeast Missouri', 'Southeast Mo. St.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace(\"St. John's\", \"St. John's (NY)\", regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Southeastern Louisiana', 'Southeastern La.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Kennesaw', 'Kennesaw St.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Louisiana Monroe', 'ULM', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Western Carolina', 'Western Caro.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('USF', 'South Fla.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Loyola Marymount', 'LMU (CA)', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Army', 'Army West Point', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Incarnate Word', 'UIW', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Central Michigan', 'Central Mich.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Eastern Illinois', 'Eastern Ill.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Western Michigan', 'Western Mich.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Central Arkansas', 'Central Ark.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Middle Tennessee', 'Middle Tenn.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Monmouth (NJ)', 'Monmouth', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Northern Kentucky', 'Northern Ky.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('North Carolina A&T', 'N.C. A&T', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Texas A&M-Corpus Christi', 'A&M-Corpus Christi', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace(\"Saint Joseph's (PA)\", \"Saint Joseph's\", regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Eastern Kentucky', 'Eastern Ky.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Seattle', 'Seattle U', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Eastern Michigan', 'Eastern Mich.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('North Alabama', 'North Ala.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Northern Colorado', 'Northern Colo.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Stephen F. Austin', 'SFA', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Western Illinois', 'Western Ill.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Prairie View A&M', 'Prairie View', regex=False)\n",
    "cbr['Team'] = cbr['Team'].apply(lambda x: 'Southern U.' if x == 'Southern' else x)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Arkansas-Pine Bluff', 'Ark.-Pine Bluff', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Maryland Eastern Shore', 'UMES', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Mississippi Valley St.', 'Mississippi Val.', regex=False)\n",
    "cbr['Team'] = cbr['Team'].str.replace('Alcorn St.', 'Alcorn', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batting Average Done\n",
      "Base on Balls Done\n",
      "Double Plays Per Game Done\n",
      "Earned Run Average Done\n",
      "Fielding Percentage Done\n",
      "Hits Allowed Per Nine Innings Done\n",
      "Home Runs Per Game Done\n",
      "On Base Percentage Done\n",
      "Runs Done\n",
      "Sacrifice Bunts Done\n",
      "Sacrifice Flies Done\n",
      "Slugging Percentage Done\n",
      "Stolen Bases Done\n",
      "Strikeout-to-Walk Ratio Done\n",
      "Strikeouts Per Nine Innings Done\n",
      "Walks Allowed Per Nine Innings Done\n",
      "WHIP Done\n"
     ]
    }
   ],
   "source": [
    "def get_stat_dataframe(stat_name):\n",
    "    \"\"\"Fetches the specified stat table from multiple pages and returns a combined DataFrame,\n",
    "    keeps 'Team' as string, and converts all other columns to float.\"\"\"\n",
    "    \n",
    "    if stat_name not in stat_links:\n",
    "        print(f\"Stat '{stat_name}' not found. Available stats: {list(stat_links.keys())}\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize the DataFrame to store all pages' data\n",
    "    all_data = []\n",
    "    page_num = 1  # Start from the first page\n",
    "\n",
    "    while True:\n",
    "        url = stat_links[stat_name]\n",
    "        if page_num > 1:\n",
    "            # Modify the URL to include the page number\n",
    "            url = f\"{url}/p{page_num}\"\n",
    "        \n",
    "        # print(f\"Fetching data for: {stat_name} (Page {page_num} - {url})\")\n",
    "\n",
    "        try:\n",
    "            # Get stats page content\n",
    "            soup = get_soup(url)\n",
    "\n",
    "            # Locate table\n",
    "            table = soup.find(\"table\")\n",
    "            if not table:\n",
    "                print(f\"No table found for {stat_name} on page {page_num}\")\n",
    "                break  # Exit the loop if no table is found (end of valid pages)\n",
    "\n",
    "            # Extract table headers\n",
    "            headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "\n",
    "            # Extract table rows\n",
    "            data = []\n",
    "            for row in table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "                cols = row.find_all(\"td\")\n",
    "                data.append([col.text.strip() for col in cols])\n",
    "\n",
    "            all_data.extend(data)  # Add the data from this page to the list of all data\n",
    "        \n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(f\"{stat_name} Done\")\n",
    "            break  # Exit the loop on HTTPError (page doesn't exist)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break  # Exit the loop on any other error\n",
    "\n",
    "        page_num += 1  # Go to the next page\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data, columns=headers)\n",
    "\n",
    "        # Convert all columns to float except \"Team\"\n",
    "        for col in df.columns:\n",
    "            if col != \"Team\":\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\")  # Converts to float, invalid values become NaN\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No data collected.\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "stat_name_input = \"Batting Average\"  # Change this to the desired stat\n",
    "ba = get_stat_dataframe(stat_name_input)\n",
    "ba[\"HPG\"] = ba[\"H\"] / ba[\"G\"]\n",
    "ba[\"ABPG\"] = ba[\"AB\"] / ba[\"G\"]\n",
    "ba[\"HPAB\"] = ba[\"H\"] / ba[\"AB\"]\n",
    "ba = ba.drop(columns=['Rank'])\n",
    "\n",
    "stat_name_input = \"Base on Balls\"\n",
    "bb = get_stat_dataframe(stat_name_input)\n",
    "bb[\"BBPG\"] = bb[\"BB\"] / bb[\"G\"]\n",
    "bb = bb.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Double Plays Per Game\"\n",
    "dp = get_stat_dataframe(stat_name_input)\n",
    "dp.rename(columns={\"PG\": \"DPPG\"}, inplace=True)\n",
    "dp = dp.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Earned Run Average\"\n",
    "era = get_stat_dataframe(stat_name_input)\n",
    "era.rename(columns={\"R\":\"RA\"}, inplace=True)\n",
    "era = era.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Fielding Percentage\"\n",
    "fp = get_stat_dataframe(stat_name_input)\n",
    "fp[\"APG\"] = fp[\"A\"] / fp[\"G\"]\n",
    "fp[\"EPG\"] = fp[\"E\"] / fp[\"G\"]\n",
    "fp = fp.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Hits Allowed Per Nine Innings\"\n",
    "ha = get_stat_dataframe(stat_name_input)\n",
    "ha.rename(columns={\"PG\": \"HAPG\"}, inplace=True)\n",
    "ha = ha.drop(columns=['Rank', 'G', 'IP'])\n",
    "\n",
    "stat_name_input = \"Home Runs Per Game\"\n",
    "hr = get_stat_dataframe(stat_name_input)\n",
    "hr.rename(columns={\"PG\": \"HRPG\"}, inplace=True)\n",
    "hr = hr.drop(columns=['Rank', 'G'])\n",
    "duplicate_teams = hr[hr.duplicated('Team', keep=False)]\n",
    "filtered_teams = duplicate_teams.loc[duplicate_teams.groupby('Team')[\"HR\"].idxmin()]\n",
    "hr_cleaned = hr[~hr[\"Team\"].isin(duplicate_teams[\"Team\"])]\n",
    "hr = pd.concat([hr_cleaned, filtered_teams], ignore_index=True)\n",
    "\n",
    "stat_name_input = \"On Base Percentage\"\n",
    "obp = get_stat_dataframe(stat_name_input)\n",
    "obp.rename(columns={\"PCT\": \"OBP\"}, inplace=True)\n",
    "obp[\"HBPPG\"] = obp[\"HBP\"] / obp[\"G\"]\n",
    "obp = obp.drop(columns=['Rank', 'G', 'AB', 'H', 'BB', 'SF', 'SH'])\n",
    "\n",
    "stat_name_input = \"Runs\"\n",
    "runs = get_stat_dataframe(stat_name_input)\n",
    "runs[\"RPG\"] = runs[\"R\"] / runs[\"G\"]\n",
    "runs.rename(columns={\"R\": \"RS\"}, inplace=True)\n",
    "runs = runs.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Sacrifice Bunts\"\n",
    "sb = get_stat_dataframe(stat_name_input)\n",
    "sb.rename(columns={\"SH\": \"SB\"}, inplace=True)\n",
    "sb[\"SBPG\"] = sb[\"SB\"] / sb[\"G\"]\n",
    "sb = sb.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Sacrifice Flies\"\n",
    "sf = get_stat_dataframe(stat_name_input)\n",
    "sf[\"SFPG\"] = sf[\"SF\"] / sf[\"G\"]\n",
    "sf = sf.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Slugging Percentage\"\n",
    "slg = get_stat_dataframe(stat_name_input)\n",
    "slg.rename(columns={\"SLG PCT\": \"SLG\"}, inplace=True)\n",
    "slg = slg.drop(columns=['Rank', 'G', 'AB'])\n",
    "\n",
    "stat_name_input = \"Stolen Bases\"\n",
    "stl = get_stat_dataframe(stat_name_input)\n",
    "stl[\"STLP\"] = stl[\"SB\"] / (stl[\"SB\"] + stl[\"CS\"])\n",
    "stl[\"STLPG\"] = stl[\"SB\"] / stl[\"G\"]\n",
    "stl[\"CSPG\"] = stl[\"CS\"] / stl[\"G\"]\n",
    "stl[\"SAPG\"] = (stl[\"SB\"] + stl[\"CS\"]) / stl[\"G\"]\n",
    "stl.rename(columns={\"SB\": \"STL\"}, inplace=True)\n",
    "stl = stl.drop(columns=['Rank', 'G'])\n",
    "\n",
    "stat_name_input = \"Strikeout-to-Walk Ratio\"\n",
    "kbb = get_stat_dataframe(stat_name_input)\n",
    "kbb[\"IP\"] = round(kbb[\"IP\"])\n",
    "kbb.rename(columns={\"K/BB\": \"KBB\"}, inplace=True)\n",
    "kbb.rename(columns={\"BB\": \"PBB\"}, inplace=True)\n",
    "kbb = kbb.drop(columns=['Rank', 'App', 'IP'])\n",
    "\n",
    "stat_name_input = \"Strikeouts Per Nine Innings\"\n",
    "kp9 = get_stat_dataframe(stat_name_input)\n",
    "kp9.rename(columns={\"K/9\": \"KP9\"}, inplace=True)\n",
    "kp9 = kp9.drop(columns=['Rank', 'G', 'IP', 'SO'])\n",
    "\n",
    "stat_name_input = \"Walks Allowed Per Nine Innings\"\n",
    "wp9 = get_stat_dataframe(stat_name_input)\n",
    "wp9.rename(columns={\"PG\": \"WP9\"}, inplace=True)\n",
    "wp9 = wp9.drop(columns=['Rank', 'G', 'IP', 'BB'])\n",
    "\n",
    "stat_name_input = \"WHIP\"\n",
    "whip = get_stat_dataframe(stat_name_input)\n",
    "whip = whip.drop(columns=['Rank', 'HA', 'IP', 'BB'])\n",
    "\n",
    "dfs = [ba, bb, era, fp, obp, runs, slg, kp9, wp9, whip, cbr]\n",
    "for df in dfs:\n",
    "    df[\"Team\"] = df[\"Team\"].str.strip()\n",
    "df_combined = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    df_combined = pd.merge(df_combined, df, on=\"Team\", how=\"inner\")\n",
    "baseball_stats = df_combined.loc[:, ~df_combined.columns.duplicated()].sort_values('Team').reset_index(drop=True)\n",
    "baseball_stats['OPS'] = baseball_stats['SLG'] + baseball_stats['OBP']\n",
    "baseball_stats['PYTHAG'] = (baseball_stats['RS'] ** 1.83) / ((baseball_stats['RS'] ** 1.83) + (baseball_stats['RA'] ** 1.83))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEAR Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpi_2024 = pd.read_csv(\"./PEAR/PEAR Baseball/rpi_end_2024.csv\")\n",
    "\n",
    "modeling_stats = baseball_stats[['Team', 'HPG',\n",
    "                'BBPG', 'ERA', 'PCT', \n",
    "                'KP9', 'WP9', 'OPS', \n",
    "                'WHIP', 'PYTHAG', 'CBRank']]\n",
    "modeling_stats = pd.merge(modeling_stats, rpi_2024[['Team', 'Rank']], on = 'Team', how='left')\n",
    "modeling_stats[\"Rank\"] = modeling_stats[\"Rank\"].apply(pd.to_numeric, errors='coerce')\n",
    "modeling_stats[\"CBRank\"] = modeling_stats[\"CBRank\"].apply(pd.to_numeric, errors='coerce')\n",
    "modeling_stats['Rank_pct'] = 1 - (modeling_stats['Rank'] - 1) / (len(modeling_stats) - 1)\n",
    "\n",
    "higher_better = [\"HPG\", \"BBPG\", \"PCT\", \"KP9\", \"OPS\", \"Rank_pct\", 'PYTHAG']\n",
    "lower_better = [\"ERA\", \"WP9\", \"WHIP\"]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(1, 100))\n",
    "modeling_stats[higher_better] = scaler.fit_transform(modeling_stats[higher_better])\n",
    "modeling_stats[lower_better] = scaler.fit_transform(-modeling_stats[lower_better])\n",
    "weights = {\n",
    "    'HPG': 8, 'BBPG': 8, 'ERA': 22, 'PCT': 8,\n",
    "    'KP9': 8, 'WP9': 8, 'OPS': 22, 'WHIP': 8, 'PYTHAG': 22, 'Rank_pct': 50\n",
    "}\n",
    "modeling_stats['in_house_pr'] = sum(modeling_stats[stat] * weight for stat, weight in weights.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_stats['in_house_pr'] = modeling_stats['in_house_pr'] - modeling_stats['in_house_pr'].mean()\n",
    "current_range = modeling_stats['in_house_pr'].max() - modeling_stats['in_house_pr'].min()\n",
    "desired_range = 25\n",
    "scaling_factor = desired_range / current_range\n",
    "modeling_stats['in_house_pr'] = round(modeling_stats['in_house_pr'] * scaling_factor, 4)\n",
    "modeling_stats['in_house_pr'] = modeling_stats['in_house_pr'] - modeling_stats['in_house_pr'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  55%|█████▍    | 274/500 [01:29<01:14,  3.05it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from scipy.optimize import differential_evolution\n",
    "from tqdm import tqdm\n",
    "pbar = tqdm(total=500, desc=\"Optimization Progress\")\n",
    "def progress_callback(xk, convergence):\n",
    "    \"\"\"Callback to update the progress bar after each iteration.\"\"\"\n",
    "    pbar.update(1)\n",
    "    if convergence < 1e-4:  # Close bar if convergence is achieved early\n",
    "        pbar.close()\n",
    "\n",
    "def objective_function(weights):\n",
    "    (w_hpb, w_bbpg, w_era, w_pct, w_kp9, w_wp9, w_whip, w_ops, w_pythag, w_in_house_pr) = weights\n",
    "    \n",
    "    modeling_stats['power_ranking'] = (\n",
    "        w_hpb * modeling_stats['HPG'] +\n",
    "        w_bbpg * modeling_stats['BBPG'] +\n",
    "        w_era * modeling_stats['ERA'] +\n",
    "        w_pct * modeling_stats['PCT'] +\n",
    "        w_kp9 * modeling_stats['KP9'] +\n",
    "        w_wp9 * modeling_stats['WP9'] +\n",
    "        w_whip * modeling_stats['WHIP'] +\n",
    "        w_ops * modeling_stats['OPS'] +\n",
    "        w_pythag * modeling_stats['PYTHAG'] + \n",
    "        w_in_house_pr * modeling_stats['in_house_pr']\n",
    "    )\n",
    "\n",
    "    modeling_stats['calculated_rank'] = modeling_stats['power_ranking'].rank(ascending=False)\n",
    "    modeling_stats['combined_rank'] = (\n",
    "        modeling_stats['CBRank']\n",
    "    )\n",
    "    spearman_corr = modeling_stats[['calculated_rank', 'combined_rank']].corr(method='spearman').iloc[0,1]\n",
    "\n",
    "    return -spearman_corr\n",
    "\n",
    "bounds = [(-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (-1,1),\n",
    "          (0,1)]\n",
    "result = differential_evolution(objective_function, bounds, strategy='best1bin', maxiter=500, tol=1e-4, seed=42, callback=progress_callback)\n",
    "optimized_weights = result.x\n",
    "modeling_stats = modeling_stats.sort_values('power_ranking', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_stats['Rating'] = modeling_stats['power_ranking'] - modeling_stats['power_ranking'].mean()\n",
    "current_range = modeling_stats['Rating'].max() - modeling_stats['Rating'].min()\n",
    "desired_range = 15\n",
    "scaling_factor = desired_range / current_range\n",
    "modeling_stats['Rating'] = round(modeling_stats['Rating'] * scaling_factor, 4)\n",
    "modeling_stats['Rating'] = modeling_stats['Rating'] - modeling_stats['Rating'].min()\n",
    "modeling_stats['Rating'] = round(modeling_stats['Rating'] - modeling_stats['Rating'].mean(),2)\n",
    "modeling_stats['Rating'] = round(modeling_stats['Rating'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ending_data = pd.merge(baseball_stats, modeling_stats[['Team', 'Rating']], on=\"Team\", how=\"inner\").sort_values('Rating', ascending=False).reset_index(drop=True)\n",
    "ending_data = ending_data.drop(columns=['SOR', 'SOS'])\n",
    "ending_data.index = ending_data.index + 1\n",
    "ending_data[['Wins', 'Losses']] = ending_data['Rec'].str.split('-', expand=True).astype(int)\n",
    "ending_data['WIN%'] = round(ending_data['Wins'] / (ending_data['Wins'] + ending_data['Losses']), 3)\n",
    "ending_data['Wins_Over_Pythag'] = ending_data['WIN%'] - ending_data['PYTHAG']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedule Info Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the page to scrape\n",
    "url = 'https://www.warrennolan.com/baseball/2025/elo'\n",
    "\n",
    "# Fetch the webpage content\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the table with the specified class\n",
    "table = soup.find('table', class_='normal-grid alternating-rows stats-table')\n",
    "\n",
    "if table:\n",
    "    # Extract table headers\n",
    "    headers = [th.text.strip() for th in table.find('thead').find_all('th')]\n",
    "    headers.insert(1, \"Team Link\")  # Adding extra column for team link\n",
    "\n",
    "    # Extract table rows\n",
    "    data = []\n",
    "    for row in table.find('tbody').find_all('tr'):\n",
    "        cells = row.find_all('td')\n",
    "        row_data = []\n",
    "        for i, cell in enumerate(cells):\n",
    "            # If it's the first cell, extract team name and link from 'name-subcontainer'\n",
    "            if i == 0:\n",
    "                name_container = cell.find('div', class_='name-subcontainer')\n",
    "                if name_container:\n",
    "                    team_name = name_container.text.strip()\n",
    "                    team_link_tag = name_container.find('a')\n",
    "                    team_link = team_link_tag['href'] if team_link_tag else ''\n",
    "                else:\n",
    "                    team_name = cell.text.strip()\n",
    "                    team_link = ''\n",
    "                row_data.append(team_name)\n",
    "                row_data.append(team_link)  # Add team link separately\n",
    "            else:\n",
    "                row_data.append(cell.text.strip())\n",
    "        data.append(row_data)\n",
    "\n",
    "\n",
    "    elo_data = pd.DataFrame(data, columns=[headers])\n",
    "    elo_data.columns = elo_data.columns.get_level_values(0)\n",
    "    elo_data = elo_data.drop_duplicates(subset='Team', keep='first')\n",
    "    elo_data = elo_data.astype({col: 'str' for col in elo_data.columns if col not in ['ELO', 'Rank']})\n",
    "    elo_data['ELO'] = elo_data['ELO'].astype(float, errors='ignore')\n",
    "    elo_data['Rank'] = elo_data['Rank'].astype(int, errors='ignore')\n",
    "\n",
    "else:\n",
    "    print(\"Table not found on the page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texas A&M\n",
      "Tennessee\n",
      "North Carolina\n",
      "LSU\n",
      "Oregon State\n",
      "Arkansas\n",
      "Florida State\n",
      "Virginia\n",
      "Florida\n",
      "Georgia\n",
      "Vanderbilt\n",
      "Oregon\n",
      "Wake Forest\n",
      "Duke\n",
      "Clemson\n",
      "TCU\n",
      "North Carolina State\n",
      "Texas\n",
      "Mississippi State\n",
      "Southern Miss\n",
      "South Carolina\n",
      "USC\n",
      "UC Santa Barbara\n",
      "Georgia Tech\n",
      "Dallas Baptist\n",
      "Arizona State\n",
      "Michigan\n",
      "Hawaii\n",
      "Oklahoma\n",
      "Charleston\n",
      "Oklahoma State\n",
      "Alabama\n",
      "West Virginia\n",
      "Louisiana Tech\n",
      "Coastal Carolina\n",
      "Troy\n",
      "UCF\n",
      "Kansas\n",
      "California\n",
      "Nebraska\n",
      "Louisville\n",
      "High Point\n",
      "Tulane\n",
      "Cincinnati\n",
      "Georgia Southern\n",
      "Auburn\n",
      "Indiana State\n",
      "Stetson\n",
      "Arizona\n",
      "UNCG\n",
      "UC Irvine\n",
      "Kentucky\n",
      "Wofford\n",
      "Ole Miss\n",
      "Illinois\n",
      "Miami (FL)\n",
      "Liberty\n",
      "Pittsburgh\n",
      "South Alabama\n",
      "UNCW\n",
      "East Tennessee State\n",
      "Lamar\n",
      "Texas State\n",
      "Utah\n",
      "Saint Mary's College\n",
      "Michigan State\n",
      "East Carolina\n",
      "Louisiana\n",
      "Western Kentucky\n",
      "Virginia Tech\n",
      "Murray State\n",
      "Northeastern\n",
      "Penn State\n",
      "FAU\n",
      "California Baptist\n",
      "Grand Canyon\n",
      "Samford\n",
      "James Madison\n",
      "Baylor\n",
      "Purdue\n",
      "UCLA\n",
      "Xavier\n",
      "Georgetown\n",
      "San Diego\n",
      "Portland\n",
      "Stanford\n",
      "Houston\n",
      "McNeese\n",
      "Notre Dame\n",
      "Maryland\n",
      "Wichita State\n",
      "Kansas State\n",
      "Creighton\n",
      "FIU\n",
      "Connecticut\n",
      "Little Rock\n",
      "UTRGV\n",
      "Texas Tech\n",
      "Ball State\n",
      "Nicholls\n",
      "Missouri\n",
      "San Jose State\n",
      "Fairfield\n",
      "Southeast Missouri\n",
      "Campbell\n",
      "Evansville\n",
      "Appalachian State\n",
      "Cal Poly\n",
      "Iowa\n",
      "Morehead State\n",
      "VCU\n",
      "UC Davis\n",
      "Old Dominion\n",
      "Saint John's\n",
      "Cal State Northridge\n",
      "Washington\n",
      "Rutgers\n",
      "Bowling Green\n",
      "Bryant\n",
      "South Carolina Upstate\n",
      "Tarleton State\n",
      "Indiana\n",
      "Columbia\n",
      "Richmond\n",
      "Minnesota\n",
      "Santa Clara\n",
      "Southeastern Louisiana\n",
      "Georgia State\n",
      "Sam Houston State\n",
      "UAB\n",
      "ULM\n",
      "Charlotte\n",
      "Mercer\n",
      "Boston College\n",
      "Western Carolina\n",
      "Ohio State\n",
      "Wright State\n",
      "FGCU\n",
      "Long Island\n",
      "Austin Peay\n",
      "Loyola-Marymount\n",
      "Niagara\n",
      "New Mexico State\n",
      "UIC\n",
      "Kennesaw State\n",
      "UTSA\n",
      "Saint Louis\n",
      "Saint Joseph's\n",
      "South Florida\n",
      "BYU\n",
      "Memphis\n",
      "VMI\n",
      "Delaware\n",
      "Presbyterian College\n",
      "Oral Roberts\n",
      "Nevada\n",
      "Stony Brook\n",
      "Abilene Christian\n",
      "Rice\n",
      "Illinois State\n",
      "New Mexico\n",
      "Northwestern State\n",
      "Army\n",
      "UNLV\n",
      "Jacksonville State\n",
      "Lipscomb\n",
      "Dayton\n",
      "UC San Diego\n",
      "New Orleans\n",
      "Missouri State\n",
      "Hofstra\n",
      "Elon\n",
      "Jackson State\n",
      "Winthrop\n",
      "Southern Illinois\n",
      "UNC Asheville\n",
      "Rider\n",
      "Utah Valley\n",
      "Tennessee Tech\n",
      "Charleston Southern\n",
      "UMBC\n",
      "Rhode Island\n",
      "William & Mary\n",
      "Air Force\n",
      "North Carolina A&T\n",
      "Central Arkansas\n",
      "Southern Indiana\n",
      "Fresno State\n",
      "Miami (OH)\n",
      "Penn\n",
      "Kent State\n",
      "Western Michigan\n",
      "Northwestern\n",
      "Northern Kentucky\n",
      "UMass\n",
      "UTA\n",
      "Bucknell\n",
      "Monmouth\n",
      "Sacred Heart\n",
      "San Diego State\n",
      "Gonzaga\n",
      "Incarnate Word\n",
      "Houston Christian\n",
      "Grambling State\n",
      "George Washington\n",
      "Gardner-Webb\n",
      "Seton Hall\n",
      "Long Beach State\n",
      "Holy Cross\n",
      "Mount Saint Mary's\n",
      "Tennessee-Martin\n",
      "Merrimack\n",
      "West Georgia\n",
      "The Citadel\n",
      "Toledo\n",
      "Saint Thomas\n",
      "UMass-Lowell\n",
      "Jacksonville\n",
      "Northern Illinois\n",
      "Villanova\n",
      "Saint Bonaventure\n",
      "Yale\n",
      "Sacramento State\n",
      "Longwood\n",
      "Princeton\n",
      "Washington State\n",
      "SIUE\n",
      "Cornell\n",
      "North Florida\n",
      "Davidson\n",
      "Middle Tennessee\n",
      "Oakland\n",
      "North Alabama\n",
      "NJIT\n",
      "Alabama State\n",
      "Manhattan\n",
      "Navy\n",
      "UC Riverside\n",
      "Bethune-Cookman\n",
      "Wagner\n",
      "Arkansas State\n",
      "Eastern Illinois\n",
      "Butler\n",
      "Cal State Bakersfield\n",
      "Quinnipiac\n",
      "Central Connecticut\n",
      "Towson\n",
      "Prairie View A&M\n",
      "Marshall\n",
      "San Francisco\n",
      "Queens\n",
      "Akron\n",
      "George Mason\n",
      "Pacific\n",
      "Harvard\n",
      "Texas Southern\n",
      "Northern Colorado\n",
      "Texas A&M-Corpus Christi\n",
      "Ohio\n",
      "Belmont\n",
      "Eastern Kentucky\n",
      "Southern\n",
      "Florida A&M\n",
      "Omaha\n",
      "Lehigh\n",
      "Utah Tech\n",
      "Milwaukee\n",
      "Mercyhurst\n",
      "Fairleigh Dickinson\n",
      "Albany\n",
      "Cal State Fullerton\n",
      "South Dakota State\n",
      "Delaware State\n",
      "Seattle University\n",
      "Dartmouth\n",
      "Canisius\n",
      "Binghamton\n",
      "Brown\n",
      "Purdue Fort Wayne\n",
      "Fordham\n",
      "Pepperdine\n",
      "North Dakota State\n",
      "Radford\n",
      "Youngstown State\n",
      "Iona\n",
      "Mississippi Valley State\n",
      "Valparaiso\n",
      "Central Michigan\n",
      "Coppin State\n",
      "Bradley\n",
      "Lafayette\n",
      "Western Illinois\n",
      "Marist\n",
      "Alabama A&M\n",
      "Bellarmine\n",
      "Siena\n",
      "Saint Peter's\n",
      "Maine\n",
      "Eastern Michigan\n",
      "Alcorn State\n",
      "Stonehill\n",
      "Le Moyne\n",
      "Stephen F. Austin\n",
      "Lindenwood\n",
      "Arkansas-Pine Bluff\n",
      "Norfolk State\n",
      "Maryland Eastern Shore\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Base URL for Warren Nolan\n",
    "BASE_URL = \"https://www.warrennolan.com\"\n",
    "\n",
    "# Initialize storage for schedule data\n",
    "schedule_data = []\n",
    "\n",
    "# Iterate over each team's schedule link\n",
    "for _, row in elo_data.iterrows():\n",
    "    team_name = row[\"Team\"]\n",
    "    print(team_name)\n",
    "    team_schedule_url = BASE_URL + row[\"Team Link\"]\n",
    "    \n",
    "    response = requests.get(team_schedule_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the team name\n",
    "    # team_name = soup.find(\"h1\").text.strip() if soup.find(\"h1\") else \"Unknown\"\n",
    "\n",
    "    # Find the team schedule list\n",
    "    schedule_lists = soup.find_all(\"ul\", class_=\"team-schedule\")\n",
    "    if not schedule_lists:\n",
    "        continue  # Skip if no schedule is found\n",
    "\n",
    "    schedule_list = schedule_lists[0]\n",
    "\n",
    "    # Iterate over each game row in the schedule\n",
    "    for game in schedule_list.find_all('li', class_='team-schedule'):\n",
    "        # Extract Date\n",
    "        date_month = game.find('span', class_='team-schedule__game-date--month').text.strip()\n",
    "        date_day = game.find('span', class_='team-schedule__game-date--day').text.strip()\n",
    "        date_dow = game.find('span', class_='team-schedule__game-date--dow').text.strip()\n",
    "        game_date = f\"{date_month} {date_day} ({date_dow})\"\n",
    "\n",
    "        # Extract Opponent Name (Handle missing cases)\n",
    "        opponent_info = game.find('div', class_='team-schedule__opp')\n",
    "        if opponent_info:\n",
    "            opponent_link_element = opponent_info.find('a', class_='team-schedule__opp-line-link')\n",
    "            opponent_name = opponent_link_element.text.strip() if opponent_link_element else \"\"\n",
    "        else:\n",
    "            opponent_name = \"\"\n",
    "\n",
    "        # Extract Location\n",
    "        location_info = game.find('div', class_='team-schedule__info')\n",
    "        location = location_info.text.strip() if location_info else \"Unknown\"\n",
    "\n",
    "        # Extract Game Result\n",
    "        result_info = game.find('div', class_='team-schedule__result')\n",
    "        result_text = result_info.text.strip() if result_info else \"N/A\"\n",
    "\n",
    "        # Extract Home/Away Teams from Box Score and scores\n",
    "        home_score, away_score = \"\", \"\"  # Initialize scores as empty strings\n",
    "\n",
    "        box_score_table = game.find('table', class_='team-schedule-bottom__box-score')\n",
    "        if box_score_table:\n",
    "            rows = box_score_table.find_all('tr')\n",
    "            if len(rows) > 2:\n",
    "                away_team = rows[1].find_all('td')[0].text.strip()\n",
    "                home_team = rows[2].find_all('td')[0].text.strip()\n",
    "\n",
    "                # Extracting Runs\n",
    "                away_score = rows[1].find_all('td')[-3].text.strip()  # Away runs\n",
    "                home_score = rows[2].find_all('td')[-3].text.strip()  # Home runs\n",
    "            else:\n",
    "                home_team, away_team = \"N/A\", \"N/A\"\n",
    "        else:\n",
    "            home_team, away_team = \"N/A\", \"N/A\"\n",
    "\n",
    "        # Append to schedule data\n",
    "        schedule_data.append([team_name, game_date, opponent_name, location, result_text, home_team, away_team, home_score, away_score])\n",
    "\n",
    "# Convert to DataFrame\n",
    "columns = [\"Team\", \"Date\", \"Opponent\", \"Location\", \"Result\", \"home_team\", \"away_team\", \"home_score\", \"away_score\"]\n",
    "schedule_df = pd.DataFrame(schedule_data, columns=columns)\n",
    "schedule_df = schedule_df.astype({col: 'str' for col in schedule_df.columns if col not in ['home_score', 'away_score']})\n",
    "schedule_df['home_score'] = schedule_df['home_score'].astype(int, errors='ignore')\n",
    "schedule_df['away_score'] = schedule_df['away_score'].astype(int, errors='ignore')\n",
    "schedule_df = schedule_df.merge(elo_data[['Team', 'ELO']], left_on='home_team', right_on='Team', how='left')\n",
    "schedule_df.rename(columns={'ELO': 'home_elo'}, inplace=True)\n",
    "schedule_df = schedule_df.merge(elo_data[['Team', 'ELO']], left_on='away_team', right_on='Team', how='left')\n",
    "schedule_df.rename(columns={'ELO': 'away_elo'}, inplace=True)\n",
    "schedule_df.drop(columns=['Team', 'Team_y'], inplace=True)\n",
    "schedule_df.rename(columns={'Team_x':'Team'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the page to scrape\n",
    "url = 'https://www.warrennolan.com/baseball/2025/elo'\n",
    "\n",
    "# Fetch the webpage content\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the table with the specified class\n",
    "table = soup.find('table', class_='normal-grid alternating-rows stats-table')\n",
    "\n",
    "if table:\n",
    "    # Extract table headers\n",
    "    headers = [th.text.strip() for th in table.find('thead').find_all('th')]\n",
    "    headers.insert(1, \"Team Link\")  # Adding extra column for team link\n",
    "\n",
    "    # Extract table rows\n",
    "    data = []\n",
    "    for row in table.find('tbody').find_all('tr'):\n",
    "        cells = row.find_all('td')\n",
    "        row_data = []\n",
    "        for i, cell in enumerate(cells):\n",
    "            # If it's the first cell, extract team name and link from 'name-subcontainer'\n",
    "            if i == 0:\n",
    "                name_container = cell.find('div', class_='name-subcontainer')\n",
    "                if name_container:\n",
    "                    team_name = name_container.text.strip()\n",
    "                    team_link_tag = name_container.find('a')\n",
    "                    team_link = team_link_tag['href'] if team_link_tag else ''\n",
    "                else:\n",
    "                    team_name = cell.text.strip()\n",
    "                    team_link = ''\n",
    "                row_data.append(team_name)\n",
    "                row_data.append(team_link)  # Add team link separately\n",
    "            else:\n",
    "                row_data.append(cell.text.strip())\n",
    "        data.append(row_data)\n",
    "\n",
    "\n",
    "    elo_data = pd.DataFrame(data, columns=[headers])\n",
    "    elo_data.columns = elo_data.columns.get_level_values(0)\n",
    "    elo_data = elo_data.drop_duplicates(subset='Team', keep='first')\n",
    "    elo_data = elo_data.astype({col: 'str' for col in elo_data.columns if col not in ['ELO', 'Rank']})\n",
    "    elo_data['ELO'] = elo_data['ELO'].astype(float, errors='ignore')\n",
    "    elo_data['Rank'] = elo_data['Rank'].astype(int, errors='ignore')\n",
    "\n",
    "else:\n",
    "    print(\"Table not found on the page.\")\n",
    "\n",
    "elo_data['Team'] = elo_data['Team'].str.replace('State', 'St.', regex=False)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'NC State' if x == 'North Carolina St.' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Southern Miss.' if x == 'Southern Miss' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Southern California' if x == 'USC' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'DBU' if x == 'Dallas Baptist' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Col. of Charleston' if x == 'Charleston' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Ga. Southern' if x == 'Georgia Southern' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'UNC Greensboro' if x == 'UNCG' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'ETSU' if x == 'East Tennessee St.' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Lamar University' if x == 'Lamar' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: \"Saint Mary's (CA)\" if x == \"Saint Mary's College\" else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Western Ky.' if x == 'Western Kentucky' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Fla. Atlantic' if x == 'FAU' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'UConn' if x == 'Connecticut' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Southeast Mo. St.' if x == 'Southeast Missouri' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Alcorn' if x == 'Alcorn St.' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'App State' if x == 'Appalachian St.' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Ark.-Pine Bluff' if x == 'Arkansas-Pine Bluff' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Army West Point' if x == 'Army' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'CSU Bakersfield' if x == 'Cal St. Bakersfield' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'CSUN' if x == 'Cal St. Northridge' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Central Ark.' if x == 'Central Arkansas' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Central Mich.' if x == 'Central Michigan' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Charleston So.' if x == 'Charleston Southern' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Eastern Ill.' if x == 'Eastern Illinois' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Eastern Ky.' if x == 'Eastern Kentucky' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Eastern Mich.' if x == 'Eastern Michigan' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'FDU' if x == 'Fairleigh Dickinson' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Grambling' if x == 'Grambling St.' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'UIW' if x == 'Incarnate Word' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'LIU' if x == 'Long Island' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'UMES' if x == 'Maryland Eastern Shore' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Middle Tenn.' if x == 'Middle Tennessee' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Mississippi Val.' if x == 'Mississippi Valley St.' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: \"Mount St. Mary's\" if x == \"Mount Saint Mary's\" else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'North Ala.' if x == 'North Alabama' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'N.C. A&T' if x == 'North Carolina A&T' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Northern Colo.' if x == 'Northern Colorado' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Northern Ky.' if x == 'Northern Kentucky' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Prairie View' if x == 'Prairie View A&M' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Presbyterian' if x == 'Presbyterian College' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'St. Bonaventure' if x == 'Saint Bonaventure' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: \"St. John's (NY)\" if x == \"Saint John's\" else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Sam Houston' if x == 'Sam Houston St.' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Seattle U' if x == 'Seattle University' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'USC Upstate' if x == 'South Carolina Upstate' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'South Fla.' if x == 'South Florida' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Southeastern La.' if x == 'Southeastern Louisiana' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Southern U.' if x == 'Southern' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Southern Ill.' if x == 'Southern Illinois' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'SFA' if x == 'Stephen F. Austin' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'UT Martin' if x == 'Tennessee-Martin' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'A&M-Corpus Christi' if x == 'Texas A&M-Corpus Christi' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'UMass Lowell' if x == 'UMass-Lowell' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'UT Arlington' if x == 'UTA' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Western Caro.' if x == 'Western Carolina' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Western Ill.' if x == 'Western Illinois' else x)\n",
    "elo_data['Team'] = elo_data['Team'].apply(lambda x: 'Western Mich.' if x == 'Western Michigan' else x)\n",
    "\n",
    "schedule_df['Team'] = schedule_df['Team'].str.replace('State', 'St.', regex=False)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'NC State' if x == 'North Carolina St.' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Southern Miss.' if x == 'Southern Miss' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Southern California' if x == 'USC' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'DBU' if x == 'Dallas Baptist' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Col. of Charleston' if x == 'Charleston' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Ga. Southern' if x == 'Georgia Southern' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'UNC Greensboro' if x == 'UNCG' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'ETSU' if x == 'East Tennessee St.' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Lamar University' if x == 'Lamar' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: \"Saint Mary's (CA)\" if x == \"Saint Mary's College\" else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Western Ky.' if x == 'Western Kentucky' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Fla. Atlantic' if x == 'FAU' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'UConn' if x == 'Connecticut' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Southeast Mo. St.' if x == 'Southeast Missouri' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Alcorn' if x == 'Alcorn St.' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'App State' if x == 'Appalachian St.' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Ark.-Pine Bluff' if x == 'Arkansas-Pine Bluff' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Army West Point' if x == 'Army' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'CSU Bakersfield' if x == 'Cal St. Bakersfield' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'CSUN' if x == 'Cal St. Northridge' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Central Ark.' if x == 'Central Arkansas' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Central Mich.' if x == 'Central Michigan' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Charleston So.' if x == 'Charleston Southern' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Eastern Ill.' if x == 'Eastern Illinois' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Eastern Ky.' if x == 'Eastern Kentucky' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Eastern Mich.' if x == 'Eastern Michigan' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'FDU' if x == 'Fairleigh Dickinson' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Grambling' if x == 'Grambling St.' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'UIW' if x == 'Incarnate Word' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'LIU' if x == 'Long Island' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'UMES' if x == 'Maryland Eastern Shore' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Middle Tenn.' if x == 'Middle Tennessee' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Mississippi Val.' if x == 'Mississippi Valley St.' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: \"Mount St. Mary's\" if x == \"Mount Saint Mary's\" else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'North Ala.' if x == 'North Alabama' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'N.C. A&T' if x == 'North Carolina A&T' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Northern Colo.' if x == 'Northern Colorado' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Northern Ky.' if x == 'Northern Kentucky' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Prairie View' if x == 'Prairie View A&M' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Presbyterian' if x == 'Presbyterian College' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'St. Bonaventure' if x == 'Saint Bonaventure' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: \"St. John's (NY)\" if x == \"Saint John's\" else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Sam Houston' if x == 'Sam Houston St.' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Seattle U' if x == 'Seattle University' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'USC Upstate' if x == 'South Carolina Upstate' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'South Fla.' if x == 'South Florida' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Southeastern La.' if x == 'Southeastern Louisiana' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Southern U.' if x == 'Southern' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Southern Ill.' if x == 'Southern Illinois' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'SFA' if x == 'Stephen F. Austin' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'UT Martin' if x == 'Tennessee-Martin' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'A&M-Corpus Christi' if x == 'Texas A&M-Corpus Christi' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'UMass Lowell' if x == 'UMass-Lowell' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'UT Arlington' if x == 'UTA' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Western Caro.' if x == 'Western Carolina' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Western Ill.' if x == 'Western Illinois' else x)\n",
    "schedule_df['Team'] = schedule_df['Team'].apply(lambda x: 'Western Mich.' if x == 'Western Michigan' else x)\n",
    "\n",
    "schedule_df['home_team'] = schedule_df['home_team'].str.replace('State', 'St.', regex=False)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'NC State' if x == 'North Carolina St.' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Southern Miss.' if x == 'Southern Miss' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Southern California' if x == 'USC' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'DBU' if x == 'Dallas Baptist' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Col. of Charleston' if x == 'Charleston' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Ga. Southern' if x == 'Georgia Southern' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'UNC Greensboro' if x == 'UNCG' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'ETSU' if x == 'East Tennessee St.' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Lamar University' if x == 'Lamar' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: \"Saint Mary's (CA)\" if x == \"Saint Mary's College\" else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Western Ky.' if x == 'Western Kentucky' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Fla. Atlantic' if x == 'FAU' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'UConn' if x == 'Connecticut' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Southeast Mo. St.' if x == 'Southeast Missouri' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Alcorn' if x == 'Alcorn St.' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'App State' if x == 'Appalachian St.' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Ark.-Pine Bluff' if x == 'Arkansas-Pine Bluff' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Army West Point' if x == 'Army' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'CSU Bakersfield' if x == 'Cal St. Bakersfield' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'CSUN' if x == 'Cal St. Northridge' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Central Ark.' if x == 'Central Arkansas' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Central Mich.' if x == 'Central Michigan' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Charleston So.' if x == 'Charleston Southern' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Eastern Ill.' if x == 'Eastern Illinois' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Eastern Ky.' if x == 'Eastern Kentucky' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Eastern Mich.' if x == 'Eastern Michigan' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'FDU' if x == 'Fairleigh Dickinson' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Grambling' if x == 'Grambling St.' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'UIW' if x == 'Incarnate Word' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'LIU' if x == 'Long Island' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'UMES' if x == 'Maryland Eastern Shore' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Middle Tenn.' if x == 'Middle Tennessee' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Mississippi Val.' if x == 'Mississippi Valley St.' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: \"Mount St. Mary's\" if x == \"Mount Saint Mary's\" else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'North Ala.' if x == 'North Alabama' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'N.C. A&T' if x == 'North Carolina A&T' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Northern Colo.' if x == 'Northern Colorado' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Northern Ky.' if x == 'Northern Kentucky' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Prairie View' if x == 'Prairie View A&M' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Presbyterian' if x == 'Presbyterian College' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'St. Bonaventure' if x == 'Saint Bonaventure' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: \"St. John's (NY)\" if x == \"Saint John's\" else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Sam Houston' if x == 'Sam Houston St.' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Seattle U' if x == 'Seattle University' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'USC Upstate' if x == 'South Carolina Upstate' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'South Fla.' if x == 'South Florida' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Southeastern La.' if x == 'Southeastern Louisiana' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Southern U.' if x == 'Southern' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Southern Ill.' if x == 'Southern Illinois' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'SFA' if x == 'Stephen F. Austin' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'UT Martin' if x == 'Tennessee-Martin' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'A&M-Corpus Christi' if x == 'Texas A&M-Corpus Christi' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'UMass Lowell' if x == 'UMass-Lowell' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'UT Arlington' if x == 'UTA' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Western Caro.' if x == 'Western Carolina' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Western Ill.' if x == 'Western Illinois' else x)\n",
    "schedule_df['home_team'] = schedule_df['home_team'].apply(lambda x: 'Western Mich.' if x == 'Western Michigan' else x)\n",
    "\n",
    "schedule_df['away_team'] = schedule_df['away_team'].str.replace('State', 'St.', regex=False)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'NC State' if x == 'North Carolina St.' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Southern Miss.' if x == 'Southern Miss' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Southern California' if x == 'USC' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'DBU' if x == 'Dallas Baptist' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Col. of Charleston' if x == 'Charleston' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Ga. Southern' if x == 'Georgia Southern' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'UNC Greensboro' if x == 'UNCG' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'ETSU' if x == 'East Tennessee St.' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Lamar University' if x == 'Lamar' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: \"Saint Mary's (CA)\" if x == \"Saint Mary's College\" else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Western Ky.' if x == 'Western Kentucky' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Fla. Atlantic' if x == 'FAU' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'UConn' if x == 'Connecticut' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Southeast Mo. St.' if x == 'Southeast Missouri' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Alcorn' if x == 'Alcorn St.' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'App State' if x == 'Appalachian St.' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Ark.-Pine Bluff' if x == 'Arkansas-Pine Bluff' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Army West Point' if x == 'Army' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'CSU Bakersfield' if x == 'Cal St. Bakersfield' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'CSUN' if x == 'Cal St. Northridge' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Central Ark.' if x == 'Central Arkansas' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Central Mich.' if x == 'Central Michigan' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Charleston So.' if x == 'Charleston Southern' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Eastern Ill.' if x == 'Eastern Illinois' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Eastern Ky.' if x == 'Eastern Kentucky' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Eastern Mich.' if x == 'Eastern Michigan' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'FDU' if x == 'Fairleigh Dickinson' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Grambling' if x == 'Grambling St.' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'UIW' if x == 'Incarnate Word' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'LIU' if x == 'Long Island' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'UMES' if x == 'Maryland Eastern Shore' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Middle Tenn.' if x == 'Middle Tennessee' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Mississippi Val.' if x == 'Mississippi Valley St.' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: \"Mount St. Mary's\" if x == \"Mount Saint Mary's\" else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'North Ala.' if x == 'North Alabama' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'N.C. A&T' if x == 'North Carolina A&T' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Northern Colo.' if x == 'Northern Colorado' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Northern Ky.' if x == 'Northern Kentucky' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Prairie View' if x == 'Prairie View A&M' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Presbyterian' if x == 'Presbyterian College' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'St. Bonaventure' if x == 'Saint Bonaventure' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: \"St. John's (NY)\" if x == \"Saint John's\" else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Sam Houston' if x == 'Sam Houston St.' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Seattle U' if x == 'Seattle University' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'USC Upstate' if x == 'South Carolina Upstate' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'South Fla.' if x == 'South Florida' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Southeastern La.' if x == 'Southeastern Louisiana' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Southern U.' if x == 'Southern' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Southern Ill.' if x == 'Southern Illinois' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'SFA' if x == 'Stephen F. Austin' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'UT Martin' if x == 'Tennessee-Martin' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'A&M-Corpus Christi' if x == 'Texas A&M-Corpus Christi' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'UMass Lowell' if x == 'UMass-Lowell' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'UT Arlington' if x == 'UTA' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Western Caro.' if x == 'Western Carolina' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Western Ill.' if x == 'Western Illinois' else x)\n",
    "schedule_df['away_team'] = schedule_df['away_team'].apply(lambda x: 'Western Mich.' if x == 'Western Michigan' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOS, MD, Rem SOS, SOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Mapping months to numerical values\n",
    "month_mapping = {\n",
    "    \"JAN\": \"01\", \"FEB\": \"02\", \"MAR\": \"03\", \"APR\": \"04\",\n",
    "    \"MAY\": \"05\", \"JUN\": \"06\", \"JUL\": \"07\", \"AUG\": \"08\",\n",
    "    \"SEP\": \"09\", \"OCT\": \"10\", \"NOV\": \"11\", \"DEC\": \"12\"\n",
    "}\n",
    "\n",
    "current_season = 2025  # Set the current season\n",
    "\n",
    "# Function to convert \"FEB 14 (FRI)\" format to \"mm-dd-yyyy\"\n",
    "def convert_date(date_str):\n",
    "    # Ensure date is a string before splitting\n",
    "    if isinstance(date_str, pd.Timestamp):\n",
    "        date_str = date_str.strftime(\"%b %d (%a)\").upper()  # Convert to same format\n",
    "    \n",
    "    parts = date_str.split()  # [\"FEB\", \"14\", \"(FRI)\"]\n",
    "    month = month_mapping[parts[0].upper()]  # Convert month to number\n",
    "    day = parts[1]  # Extract day\n",
    "    return f\"{month}-{day}-{current_season}\"\n",
    "\n",
    "# Apply function to convert date format\n",
    "schedule_df[\"Date\"] = schedule_df[\"Date\"].astype(str).apply(convert_date)\n",
    "schedule_df[\"Date\"] = pd.to_datetime(schedule_df[\"Date\"], format=\"%m-%d-%Y\")\n",
    "comparison_date = pd.to_datetime(formatted_date, format=\"%m_%d_%Y\")\n",
    "\n",
    "missing_rating = round(ending_data['Rating'].mean() - 1.5*ending_data['Rating'].std(),2)\n",
    "schedule_df = schedule_df.merge(ending_data[['Team', 'Rating']], left_on='home_team', right_on='Team', how='left')\n",
    "schedule_df.rename(columns={'Rating': 'home_rating'}, inplace=True)\n",
    "schedule_df = schedule_df.merge(ending_data[['Team', 'Rating']], left_on='away_team', right_on='Team', how='left')\n",
    "schedule_df.rename(columns={'Rating': 'away_rating'}, inplace=True)\n",
    "schedule_df.drop(columns=['Team', 'Team_y'], inplace=True)\n",
    "schedule_df.rename(columns={'Team_x':'Team'}, inplace=True)\n",
    "schedule_df['home_rating'].fillna(missing_rating, inplace=True)\n",
    "schedule_df['away_rating'].fillna(missing_rating, inplace=True)\n",
    "schedule_df['home_win_prob'] = schedule_df.apply(\n",
    "    lambda row: PEAR_Win_Prob(row['home_rating'], row['away_rating']) / 100, axis=1\n",
    ")\n",
    "completed_schedule = schedule_df[\n",
    "    (schedule_df[\"Date\"] < comparison_date) & (schedule_df[\"home_score\"] != schedule_df[\"away_score\"])\n",
    "].reset_index(drop=True)\n",
    "remaining_games = schedule_df[schedule_df[\"Date\"] > comparison_date].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_expected_wins(group):\n",
    "    # Initialize a variable to accumulate expected wins\n",
    "    expected_wins = 0\n",
    "    schedule_wins = 0\n",
    "    schedule_losses = 0\n",
    "    \n",
    "    # Iterate over the rows of the group\n",
    "    for _, row in group.iterrows():\n",
    "        if row['Team'] == row['home_team']:\n",
    "            expected_wins += row['home_win_prob']\n",
    "            if row['home_score'] > row['away_score']:\n",
    "                schedule_wins += 1\n",
    "            else:\n",
    "                schedule_losses += 1\n",
    "        else:\n",
    "            expected_wins += 1 - row['home_win_prob']\n",
    "            if row['away_score'] > row['home_score']:\n",
    "                schedule_wins += 1\n",
    "            else:\n",
    "                schedule_losses += 1\n",
    "    \n",
    "    # Return the total expected_wins for this group\n",
    "    return pd.Series({'Team': group['Team'].iloc[0], 'expected_wins': expected_wins, 'Wins':schedule_wins, 'Losses':schedule_losses})\n",
    "\n",
    "# Group by 'Team' and apply the calculation\n",
    "team_expected_wins = completed_schedule.groupby('Team').apply(calculate_expected_wins).reset_index(drop=True)\n",
    "team_expected_wins['wins_above_expected'] = round(team_expected_wins['Wins'] - team_expected_wins['expected_wins'],2)\n",
    "team_expected_wins['SOR'] = team_expected_wins['wins_above_expected'].rank(method='min', ascending=False)\n",
    "max_SOR = team_expected_wins['SOR'].max()\n",
    "team_expected_wins['SOR'].fillna(max_SOR + 1, inplace=True)\n",
    "team_expected_wins['SOR'] = team_expected_wins['SOR'].astype(int)\n",
    "team_expected_wins = team_expected_wins.sort_values('SOR').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>rem_avg_expected_wins</th>\n",
       "      <th>RemSOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Auburn</td>\n",
       "      <td>13.9666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stanford</td>\n",
       "      <td>14.0731</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>14.1532</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Virginia Tech</td>\n",
       "      <td>14.9928</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vanderbilt</td>\n",
       "      <td>15.4954</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>15.5626</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texas A&amp;M</td>\n",
       "      <td>15.6339</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Miami (FL)</td>\n",
       "      <td>15.7147</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BYU</td>\n",
       "      <td>15.7474</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>15.8339</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NC State</td>\n",
       "      <td>15.9520</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>15.9520</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>16.1847</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Florida</td>\n",
       "      <td>16.4852</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>16.5057</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>16.5808</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kansas St.</td>\n",
       "      <td>16.6128</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mississippi St.</td>\n",
       "      <td>16.6171</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Texas</td>\n",
       "      <td>16.6462</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ole Miss</td>\n",
       "      <td>16.7654</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wake Forest</td>\n",
       "      <td>16.7923</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>16.9027</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TCU</td>\n",
       "      <td>17.0285</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Coastal Carolina</td>\n",
       "      <td>17.1355</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Louisville</td>\n",
       "      <td>17.2195</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Team  rem_avg_expected_wins  RemSOS\n",
       "0             Auburn                13.9666       1\n",
       "1           Stanford                14.0731       2\n",
       "2           Oklahoma                14.1532       3\n",
       "3      Virginia Tech                14.9928       4\n",
       "4         Vanderbilt                15.4954       5\n",
       "5            Alabama                15.5626       6\n",
       "6          Texas A&M                15.6339       7\n",
       "7         Miami (FL)                15.7147       8\n",
       "8                BYU                15.7474       9\n",
       "9            Georgia                15.8339      10\n",
       "10          NC State                15.9520      11\n",
       "11          Kentucky                15.9520      12\n",
       "12          Arkansas                16.1847      13\n",
       "13           Florida                16.4852      14\n",
       "14    North Carolina                16.5057      15\n",
       "15          Missouri                16.5808      16\n",
       "16        Kansas St.                16.6128      17\n",
       "17   Mississippi St.                16.6171      18\n",
       "18             Texas                16.6462      19\n",
       "19          Ole Miss                16.7654      20\n",
       "20       Wake Forest                16.7923      21\n",
       "21    South Carolina                16.9027      22\n",
       "22               TCU                17.0285      23\n",
       "23  Coastal Carolina                17.1355      24\n",
       "24        Louisville                17.2195      25"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_average_expected_wins(group, average_team):\n",
    "    avg_expected_wins = 0\n",
    "\n",
    "    for _, row in group.iterrows():\n",
    "        if row['Team'] == row['home_team']:\n",
    "            avg_expected_wins += PEAR_Win_Prob(average_team, row['away_rating']) / 100\n",
    "        else:\n",
    "            avg_expected_wins += 1 - PEAR_Win_Prob(row['home_rating'], average_team) / 100\n",
    "\n",
    "    return pd.Series({'Team': group['Team'].iloc[0], 'avg_expected_wins': avg_expected_wins})\n",
    "\n",
    "average_team = ending_data['Rating'].mean()\n",
    "avg_team_expected_wins = completed_schedule.groupby('Team').apply(calculate_average_expected_wins, average_team).reset_index(drop=True)\n",
    "avg_team_expected_wins['SOS'] = avg_team_expected_wins['avg_expected_wins'].rank(method='min', ascending=True)\n",
    "avg_team_expected_wins['SOS'] = avg_team_expected_wins['SOS'].astype(int)\n",
    "avg_team_expected_wins = avg_team_expected_wins.sort_values('SOS').reset_index(drop=True)\n",
    "\n",
    "rem_avg_expected_wins = remaining_games.groupby('Team').apply(calculate_average_expected_wins, average_team).reset_index(drop=True)\n",
    "rem_avg_expected_wins.rename(columns={\"avg_expected_wins\": \"rem_avg_expected_wins\"}, inplace=True)\n",
    "rem_avg_expected_wins['RemSOS'] = rem_avg_expected_wins['rem_avg_expected_wins'].rank(method='min', ascending=True)\n",
    "rem_avg_expected_wins['RemSOS'] = rem_avg_expected_wins['RemSOS'].astype(int)\n",
    "rem_avg_expected_wins = rem_avg_expected_wins.sort_values('RemSOS').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadrant_records = {}\n",
    "\n",
    "for team, group in completed_schedule.groupby('Team'):\n",
    "    Q1_win, Q1_loss = 0, 0  # Initialize counters\n",
    "    Q2_win, Q2_loss = 0, 0\n",
    "    Q3_win, Q3_loss = 0, 0\n",
    "    Q4_win, Q4_loss = 0, 0\n",
    "\n",
    "    for _, row in group.iterrows():\n",
    "        opponent = row['Opponent']\n",
    "        \n",
    "        if len(ending_data[ending_data['Team'] == opponent]) > 0:\n",
    "            opponent_index = ending_data[ending_data['Team'] == opponent].index.values[0]\n",
    "        else:\n",
    "            opponent_index = 300\n",
    "\n",
    "        team_is_home = row['Team'] == row['home_team']\n",
    "        team_won = (row['home_score'] > row['away_score'] and team_is_home) or \\\n",
    "                    (row['away_score'] > row['home_score'] and not team_is_home)\n",
    "\n",
    "        # Apply quadrant logic\n",
    "        if team_is_home and opponent_index <= 25:\n",
    "            if team_won:\n",
    "                Q1_win += 1\n",
    "            else:\n",
    "                Q1_loss += 1\n",
    "        elif team_is_home and opponent_index <= 50:\n",
    "            if team_won:\n",
    "                Q2_win += 1\n",
    "            else:\n",
    "                Q2_loss += 1\n",
    "        elif team_is_home and opponent_index <= 100:\n",
    "            if team_won:\n",
    "                Q3_win += 1\n",
    "            else:\n",
    "                Q3_loss += 1\n",
    "        elif team_is_home:\n",
    "            if team_won:\n",
    "                Q4_win += 1\n",
    "            else:\n",
    "                Q4_loss += 1            \n",
    "        elif not team_is_home and opponent_index <= 60:\n",
    "            if team_won:\n",
    "                Q1_win += 1\n",
    "            else:\n",
    "                Q1_loss += 1\n",
    "        elif not team_is_home and opponent_index <= 120:\n",
    "            if team_won:\n",
    "                Q2_win += 1\n",
    "            else:\n",
    "                Q2_loss += 1\n",
    "        elif not team_is_home and opponent_index <= 240:\n",
    "            if team_won:\n",
    "                Q3_win += 1\n",
    "            else:\n",
    "                Q3_loss += 1\n",
    "        elif not team_is_home:\n",
    "            if team_won:\n",
    "                Q4_win += 1\n",
    "            else:\n",
    "                Q4_loss += 1\n",
    "            \n",
    "\n",
    "    # Store results for the team\n",
    "    quadrant_records[team] = {'Team': team, 'Q1': f\"{Q1_win}-{Q1_loss}\", 'Q2': f\"{Q2_win}-{Q2_loss}\", 'Q3': f\"{Q3_win}-{Q3_loss}\", 'Q4': f\"{Q4_win}-{Q4_loss}\"}\n",
    "quadrant_record_df = pd.DataFrame.from_dict(quadrant_records, orient='index').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.merge(ending_data, team_expected_wins[['Team', 'expected_wins', 'wins_above_expected', 'SOR']], on='Team', how='left')\n",
    "df_2 = pd.merge(df_1, avg_team_expected_wins[['Team', 'avg_expected_wins', 'SOS']], on='Team', how='left')\n",
    "df_3 = pd.merge(df_2, rem_avg_expected_wins[['Team', 'rem_avg_expected_wins', 'RemSOS']], on='Team', how='left')\n",
    "stats_and_metrics = pd.merge(df_3, quadrant_record_df, on='Team', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Dictionary\n",
    "\n",
    "- G: Games\n",
    "- AB: At Bats\n",
    "- H: Hits\n",
    "- BA: Batting Average\n",
    "- HPG: Hits Per Game\n",
    "- ABPG: At Bats Per Game\n",
    "- HPAB: Hits Per At Bat\n",
    "- BB: Walks\n",
    "- BBPG: Walks Per Game\n",
    "- DP: Double Plays\n",
    "- DPPG: Double Plays Per Game\n",
    "- IP: Innings Pitched\n",
    "- RA: Runs Allowed\n",
    "- ER: Earned Runs\n",
    "- ERA: Earned Runs Allowed\n",
    "- PO: Put Outs\n",
    "- A: Assists\n",
    "- E: Errors\n",
    "- PCT: Fielding Percentage\n",
    "- APG: Assists Per Game\n",
    "- EPG: Errors Per Game\n",
    "- HA: Hits Allowed\n",
    "- HAPG: Hits Allowed Per Game\n",
    "- HR: Home Runs Hit\n",
    "- HRPG: Home Runs Hit Per Game\n",
    "- HBP: Hit By Pitch\n",
    "- OBP: On Base Percentage\n",
    "- HBPPG: Hit By Pitch Per Game\n",
    "- RS: Runs Scored\n",
    "- RPG: Runs Scored Per Game\n",
    "- SB: Sacrifice Bunts\n",
    "- SBPG: Sacrifice Bunts Per Game\n",
    "- SF: Sacrifice Flies\n",
    "- SFPG: Sacrifice Flies Per Game\n",
    "- TB: Total Bases\n",
    "- SLG: Slugging Percentage\n",
    "- STL: Stolen Bases\n",
    "- CS: Caught Stealing\n",
    "- STLP: Stolen Bases Success Percentage\n",
    "- STLPG: Stolen Bases Per Game\n",
    "- CSPG: Caught Stealing Per Game\n",
    "- SAPG: Stealing Attempts Per Game\n",
    "- SO: Pitching Strike Outs\n",
    "- PBB: Pitching Walks\n",
    "- KBB: Strikeouts to Walk Ratio\n",
    "- KP9: Strikeouts Per Nine\n",
    "- WP9: Walks Allowed Per Nine\n",
    "- WHIP: Walks Hits Over Innings Pitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scrape all stats at once\n",
    "# for stat_name, url in stat_links.items():\n",
    "#     print(f\"Scraping: {stat_name} ({url})\")\n",
    "    \n",
    "#     # Get stats page content\n",
    "#     soup = get_soup(url)\n",
    "    \n",
    "#     # Locate table\n",
    "#     table = soup.find(\"table\")\n",
    "#     if not table:\n",
    "#         print(f\"No table found for {stat_name}\")\n",
    "#         continue\n",
    "\n",
    "#     # Extract table headers\n",
    "#     headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "\n",
    "#     # Extract table rows\n",
    "#     data = []\n",
    "#     for row in table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "#         cols = row.find_all(\"td\")\n",
    "#         data.append([col.text.strip() for col in cols])\n",
    "\n",
    "#     # Convert to DataFrame and save\n",
    "#     df = pd.DataFrame(data, columns=headers)\n",
    "#     # df.to_csv(f\"{stat_name}.csv\", index=False)\n",
    "#     print(f\"Saved {stat_name}.csv\")\n",
    "\n",
    "# print(\"Scraping completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power_ratings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
